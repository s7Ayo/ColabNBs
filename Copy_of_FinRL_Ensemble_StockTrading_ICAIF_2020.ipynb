{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb9q2_QZgdNk"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/2-Advance/FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXaoZs2lh1hi"
      },
      "source": [
        "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
        "\n",
        "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
        "\n",
        "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
        "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
        "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
        "* **Pytorch Version**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGunVt8oLCVS"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOzAKQ-SLGX6"
      },
      "source": [
        "* [1. Problem Definition](#0)\n",
        "* [2. Getting Started - Load Python packages](#1)\n",
        "    * [2.1. Install Packages](#1.1)    \n",
        "    * [2.2. Check Additional Packages](#1.2)\n",
        "    * [2.3. Import Packages](#1.3)\n",
        "    * [2.4. Create Folders](#1.4)\n",
        "* [3. Download Data](#2)\n",
        "* [4. Preprocess Data](#3)        \n",
        "    * [4.1. Technical Indicators](#3.1)\n",
        "    * [4.2. Perform Feature Engineering](#3.2)\n",
        "* [5.Build Environment](#4)  \n",
        "    * [5.1. Training & Trade Data Split](#4.1)\n",
        "    * [5.2. User-defined Environment](#4.2)   \n",
        "    * [5.3. Initialize Environment](#4.3)    \n",
        "* [6.Implement DRL Algorithms](#5)  \n",
        "* [7.Backtesting Performance](#6)  \n",
        "    * [7.1. BackTestStats](#6.1)\n",
        "    * [7.2. BackTestPlot](#6.2)   \n",
        "    * [7.3. Baseline Stats](#6.3)   \n",
        "    * [7.3. Compare to Stock Market Index](#6.4)             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sApkDlD9LIZv"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Part 1. Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjLD2TZSLKZ-"
      },
      "source": [
        "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
        "\n",
        "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
        "\n",
        "\n",
        "* Action: The action space describes the allowed actions that the agent interacts with the\n",
        "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
        "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
        "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
        "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
        "\n",
        "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
        "values at state s′ and s, respectively\n",
        "\n",
        "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
        "our trading agent observes many different features to better learn in an interactive environment.\n",
        "\n",
        "* Environment: Dow 30 consituents\n",
        "\n",
        "\n",
        "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffsre789LY08"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Part 2. Getting Started- Load Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy5_PTmOh1hj"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install all the packages through FinRL library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mPT0ipYE28wL",
        "outputId": "a0e4fc2e-0063-40e0-aaf8-32cc91efad31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: wrds in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (3.1.6)\n",
            "Requirement already satisfied: numpy in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from wrds) (1.26.3)\n",
            "Requirement already satisfied: pandas in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from wrds) (2.2.0)\n",
            "Requirement already satisfied: psycopg2-binary in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from wrds) (2.9.9)\n",
            "Requirement already satisfied: scipy in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from wrds) (1.12.0)\n",
            "Requirement already satisfied: sqlalchemy<2 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from wrds) (1.4.51)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from sqlalchemy<2->wrds) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from pandas->wrds) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from pandas->wrds) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from pandas->wrds) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->wrds) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: swig in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (4.1.1.post1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'apt-get' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Collecting git+https://github.com/s7Ayo/FinRL_disso_final.git@old_version\n",
            "  Cloning https://github.com/s7Ayo/FinRL_disso_final.git (to revision old_version) to c:\\users\\simon\\appdata\\local\\temp\\pip-req-build-qpq0z01p\n",
            "  Resolved https://github.com/s7Ayo/FinRL_disso_final.git to commit e4ca1e76abd519ee670267d6c212dd62abf2d627\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl (from finrl==0.3.6)\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to c:\\users\\simon\\appdata\\local\\temp\\pip-install-2u2h1mq0\\elegantrl_5328e944830343a5916ba6ddfe970fb6\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit 155f07fcfe2d0f0a0318f820e8e2f2401ff30eca\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: alpaca-trade-api<4,>=3 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from finrl==0.3.6) (3.2.0)\n",
            "Requirement already satisfied: ccxt<4,>=3 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from finrl==0.3.6) (3.1.60)\n",
            "Requirement already satisfied: exchange-calendars<5,>=4 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from finrl==0.3.6) (4.5.1)\n",
            "Requirement already satisfied: jqdatasdk<2,>=1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from finrl==0.3.6) (1.9.2)\n",
            "Requirement already satisfied: pyfolio<0.10,>=0.9 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from finrl==0.3.6) (0.9.2)\n",
            "Requirement already satisfied: pyportfolioopt<2,>=1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from finrl==0.3.6) (1.5.5)\n",
            "Requirement already satisfied: ray<3,>=2 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2.9.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from finrl==0.3.6) (1.4.0)\n",
            "Requirement already satisfied: stable-baselines3>=2.0.0a5 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.2.1)\n",
            "Requirement already satisfied: stockstats<0.6,>=0.5 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from finrl==0.3.6) (0.5.4)\n",
            "Requirement already satisfied: wrds<4,>=3 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from finrl==0.3.6) (3.1.6)\n",
            "Requirement already satisfied: yfinance<0.3,>=0.2 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from finrl==0.3.6) (0.2.36)\n",
            "Requirement already satisfied: pandas>=0.18.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.2.0)\n",
            "Requirement already satisfied: numpy>=1.11.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.26.3)\n",
            "Requirement already satisfied: requests<3,>2 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.31.0)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.26.18)\n",
            "Requirement already satisfied: websocket-client<2,>=0.56.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.7.0)\n",
            "Requirement already satisfied: websockets<11,>=9.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (10.4)\n",
            "Requirement already satisfied: msgpack==1.0.3 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.0.3)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.3 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (3.9.3)\n",
            "Requirement already satisfied: PyYAML==6.0.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (6.0.1)\n",
            "Requirement already satisfied: deprecation==2.1.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.1.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from deprecation==2.1.0->alpaca-trade-api<4,>=3->finrl==0.3.6) (23.2)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ccxt<4,>=3->finrl==0.3.6) (69.0.3)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ccxt<4,>=3->finrl==0.3.6) (2023.11.17)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ccxt<4,>=3->finrl==0.3.6) (42.0.1)\n",
            "Requirement already satisfied: aiodns>=1.1.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ccxt<4,>=3->finrl==0.3.6) (3.1.1)\n",
            "Requirement already satisfied: yarl>=1.7.2 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ccxt<4,>=3->finrl==0.3.6) (1.9.4)\n",
            "Requirement already satisfied: pyluach in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (2.2.0)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (2.8.2)\n",
            "Requirement already satisfied: toolz in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (0.12.1)\n",
            "Requirement already satisfied: tzdata in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (2023.4)\n",
            "Requirement already satisfied: korean-lunar-calendar in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (0.3.1)\n",
            "Requirement already satisfied: six in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (1.16.0)\n",
            "Requirement already satisfied: SQLAlchemy>=1.2.8 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (1.4.51)\n",
            "Requirement already satisfied: thriftpy2>=0.3.9 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (0.4.17)\n",
            "Requirement already satisfied: pymysql>=0.7.6 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (1.1.0)\n",
            "Requirement already satisfied: ipython>=3.2.3 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (8.20.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (3.8.2)\n",
            "Requirement already satisfied: pytz>=2014.10 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (2023.4)\n",
            "Requirement already satisfied: scipy>=0.14.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (1.12.0)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (0.13.2)\n",
            "Requirement already satisfied: empyrical>=0.5.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (0.5.5)\n",
            "Requirement already satisfied: cvxpy<2.0.0,>=1.1.19 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from pyportfolioopt<2,>=1->finrl==0.3.6) (1.4.2)\n",
            "Requirement already satisfied: click>=7.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (8.1.7)\n",
            "Requirement already satisfied: filelock in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (3.13.1)\n",
            "Requirement already satisfied: jsonschema in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (4.21.1)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (4.23.4)\n",
            "Requirement already satisfied: aiosignal in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (1.4.1)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2.6.2.2)\n",
            "Requirement already satisfied: pyarrow<7.0.0,>=6.0.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (6.0.1)\n",
            "Requirement already satisfied: fsspec in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2023.12.2)\n",
            "Requirement already satisfied: aiohttp-cors in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.7.0)\n",
            "Requirement already satisfied: colorful in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.5.6)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.3.14)\n",
            "Requirement already satisfied: gpustat>=1.0.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (1.1.1)\n",
            "Requirement already satisfied: opencensus in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.11.4)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2.6.0)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.19.0)\n",
            "Requirement already satisfied: smart-open in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (6.4.0)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (20.25.0)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (1.60.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from scikit-learn<2,>=1->finrl==0.3.6) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from scikit-learn<2,>=1->finrl==0.3.6) (3.2.0)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.29.1)\n",
            "Requirement already satisfied: torch>=1.13 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.2.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.0.0)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.9.0.80)\n",
            "Requirement already satisfied: pygame in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.1.0)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.15.1)\n",
            "Requirement already satisfied: psutil in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (5.9.8)\n",
            "Requirement already satisfied: tqdm in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.66.1)\n",
            "Requirement already satisfied: rich in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (13.7.0)\n",
            "Requirement already satisfied: shimmy~=1.3.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.3.0)\n",
            "Requirement already satisfied: pillow in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (10.2.0)\n",
            "Requirement already satisfied: autorom~=0.6.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.6.1)\n",
            "Requirement already satisfied: psycopg2-binary in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from wrds<4,>=3->finrl==0.3.6) (2.9.9)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (5.1.0)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (1.4.4)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (2.4.0)\n",
            "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (3.17.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (1.1)\n",
            "Requirement already satisfied: gym in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6) (0.26.2)\n",
            "Requirement already satisfied: pycares>=4.0.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from aiodns>=1.1.1->ccxt<4,>=3->finrl==0.3.6) (4.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6) (4.0.3)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.6.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance<0.3,>=0.2->finrl==0.3.6) (2.5)\n",
            "Requirement already satisfied: colorama in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from click>=7.0->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (0.4.6)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (1.16.0)\n",
            "Requirement already satisfied: osqp>=0.6.2 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (0.6.3)\n",
            "Requirement already satisfied: ecos>=2 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (2.0.12)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (0.6.0)\n",
            "Requirement already satisfied: scs>=3.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (3.2.4.post1)\n",
            "Requirement already satisfied: pybind11 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (2.11.1)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from empyrical>=0.5.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.10.0)\n",
            "Requirement already satisfied: nvidia-ml-py>=11.450.129 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from gpustat>=1.0.0->ray[default,tune]<3,>=2->finrl==0.3.6) (12.535.133)\n",
            "Requirement already satisfied: blessed>=1.17.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from gpustat>=1.0.0->ray[default,tune]<3,>=2->finrl==0.3.6) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.9.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.0.4)\n",
            "Requirement already satisfied: webencodings in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from html5lib>=1.1->yfinance<0.3,>=0.2->finrl==0.3.6) (0.5.1)\n",
            "Requirement already satisfied: decorator in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.19.1)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.1.6)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (3.0.42)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.17.2)\n",
            "Requirement already satisfied: stack-data in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.6.2)\n",
            "Requirement already satisfied: traitlets>=5 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (5.14.1)\n",
            "Requirement already satisfied: exceptiongroup in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (3.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default,tune]<3,>=2->finrl==0.3.6) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default,tune]<3,>=2->finrl==0.3.6) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from requests<3,>2->alpaca-trade-api<4,>=3->finrl==0.3.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from requests<3,>2->alpaca-trade-api<4,>=3->finrl==0.3.6) (3.6)\n",
            "Requirement already satisfied: ale-py~=0.8.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.8.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from SQLAlchemy>=1.2.8->jqdatasdk<2,>=1->finrl==0.3.6) (3.0.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.1.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.0.1)\n",
            "Requirement already satisfied: ply<4.0,>=3.4 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from thriftpy2>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.6) (3.11)\n",
            "Requirement already satisfied: sympy in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.1.3)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<3,>=2->finrl==0.3.6) (0.3.8)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<3,>=2->finrl==0.3.6) (4.1.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from gym->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6) (0.0.8)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from gym[box2d]->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6) (2.3.5)\n",
            "Requirement already satisfied: swig==4.* in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from gym[box2d]->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6) (4.1.1.post1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (0.17.1)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (2.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.0.0)\n",
            "Requirement already satisfied: importlib-resources in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (6.1.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default,tune]<3,>=2->finrl==0.3.6) (0.2.13)\n",
            "Requirement already satisfied: jinxed>=1.1.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default,tune]<3,>=2->finrl==0.3.6) (1.2.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (2.21)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (1.62.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.8.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.1.2)\n",
            "Requirement already satisfied: qdldl in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from osqp>=0.6.2->cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (0.1.7.post0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.1.4)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from stack-data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.0.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from stack-data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.4.1)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from stack-data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from sympy->torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.3.0)\n",
            "Requirement already satisfied: ansicon in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from jinxed>=1.1.0->blessed>=1.17.1->gpustat>=1.0.0->ray[default,tune]<3,>=2->finrl==0.3.6) (1.89.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\simon\\anaconda3\\envs\\finrl_env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.2.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  Running command git clone --filter=blob:none --quiet https://github.com/s7Ayo/FinRL_disso_final.git 'C:\\Users\\simon\\AppData\\Local\\Temp\\pip-req-build-qpq0z01p'\n",
            "  Running command git checkout -b old_version --track origin/old_version\n",
            "  branch 'old_version' set up to track 'origin/old_version'.\n",
            "  Switched to a new branch 'old_version'\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git 'C:\\Users\\simon\\AppData\\Local\\Temp\\pip-install-2u2h1mq0\\elegantrl_5328e944830343a5916ba6ddfe970fb6'\n"
          ]
        }
      ],
      "source": [
        "# ## install finrl library\n",
        "!pip install wrds\n",
        "!pip install swig\n",
        "!pip install -q condacolab\n",
        "#import condacolab\n",
        "#condacolab.install()\n",
        "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
        "!pip install git+https://github.com/s7Ayo/FinRL_disso_final.git@old_version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osBHhVysOEzi"
      },
      "source": [
        "\n",
        "<a id='1.2'></a>\n",
        "## 2.2. Check if the additional packages needed are present, if not install them.\n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGv01K8Sh1hn"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EeMK7Uentj1V"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lPqeTTwoh1hn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")\n",
        "\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2owTj985RW4"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4. Create Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w9A8CN5R5PuZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        "    TRAIN_START_DATE,\n",
        "    TRAIN_END_DATE,\n",
        "    TEST_START_DATE,\n",
        "    TEST_END_DATE,\n",
        "    TRADE_START_DATE,\n",
        "    TRADE_END_DATE,\n",
        ")\n",
        "\n",
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A289rQWMh1hq"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPeQ7iS-LoMm"
      },
      "source": [
        "\n",
        "\n",
        "-----\n",
        "class YahooDownloader:\n",
        "    Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzqRRTOX6aFu",
        "outputId": "da9aa907-73db-406a-b2e3-669192419dbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n"
          ]
        }
      ],
      "source": [
        "print(DOW_30_TICKER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCKm4om-s9kE",
        "outputId": "b2a9fb68-b1e9-43f4-ef0b-c5117af8c291"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of DataFrame:  (105983, 8)\n"
          ]
        }
      ],
      "source": [
        "# Define the start and end dates for the training and testing datasets\n",
        "TRAIN_START_DATE = '2010-01-01'\n",
        "TRAIN_END_DATE = '2021-10-01'\n",
        "TEST_START_DATE = '2021-10-01'\n",
        "TEST_END_DATE = '2024-05-08'\n",
        "\n",
        "# Fetching the data for the defined tickers from Yahoo Finance\n",
        "df = YahooDownloader(start_date=TRAIN_START_DATE,\n",
        "                     end_date=TEST_END_DATE,\n",
        "                     ticker_list=DOW_30_TICKER).fetch_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GiRuFOTOtj1Y",
        "outputId": "fede11ab-8c3b-4e71-dc26-249803c4d522"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>7.622500</td>\n",
              "      <td>7.660714</td>\n",
              "      <td>7.585000</td>\n",
              "      <td>6.470741</td>\n",
              "      <td>493729600</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>56.630001</td>\n",
              "      <td>57.869999</td>\n",
              "      <td>56.560001</td>\n",
              "      <td>41.493397</td>\n",
              "      <td>5277400</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>40.810001</td>\n",
              "      <td>41.099998</td>\n",
              "      <td>40.389999</td>\n",
              "      <td>33.090443</td>\n",
              "      <td>6894300</td>\n",
              "      <td>AXP</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>55.720001</td>\n",
              "      <td>56.389999</td>\n",
              "      <td>54.799999</td>\n",
              "      <td>43.777546</td>\n",
              "      <td>6186700</td>\n",
              "      <td>BA</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>57.650002</td>\n",
              "      <td>59.189999</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>40.190220</td>\n",
              "      <td>7325600</td>\n",
              "      <td>CAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date       open       high        low      close     volume   tic  \\\n",
              "0  2010-01-04   7.622500   7.660714   7.585000   6.470741  493729600  AAPL   \n",
              "1  2010-01-04  56.630001  57.869999  56.560001  41.493397    5277400  AMGN   \n",
              "2  2010-01-04  40.810001  41.099998  40.389999  33.090443    6894300   AXP   \n",
              "3  2010-01-04  55.720001  56.389999  54.799999  43.777546    6186700    BA   \n",
              "4  2010-01-04  57.650002  59.189999  57.509998  40.190220    7325600   CAT   \n",
              "\n",
              "   day  \n",
              "0    0  \n",
              "1    0  \n",
              "2    0  \n",
              "3    0  \n",
              "4    0  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DSw4ZEzVtj1Z",
        "outputId": "57df8875-11f5-412d-aee0-b487ff9b8b78"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>105978</th>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>496.000000</td>\n",
              "      <td>501.649994</td>\n",
              "      <td>495.040009</td>\n",
              "      <td>500.959991</td>\n",
              "      <td>3751800</td>\n",
              "      <td>UNH</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105979</th>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>273.720001</td>\n",
              "      <td>277.880005</td>\n",
              "      <td>272.829987</td>\n",
              "      <td>276.459991</td>\n",
              "      <td>6376700</td>\n",
              "      <td>V</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105980</th>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>39.529999</td>\n",
              "      <td>39.580002</td>\n",
              "      <td>39.090000</td>\n",
              "      <td>39.310001</td>\n",
              "      <td>11932800</td>\n",
              "      <td>VZ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105981</th>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>17.280001</td>\n",
              "      <td>17.570000</td>\n",
              "      <td>17.250000</td>\n",
              "      <td>17.350000</td>\n",
              "      <td>8926000</td>\n",
              "      <td>WBA</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105982</th>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>60.169998</td>\n",
              "      <td>60.799999</td>\n",
              "      <td>60.049999</td>\n",
              "      <td>60.619999</td>\n",
              "      <td>14517100</td>\n",
              "      <td>WMT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              date        open        high         low       close    volume  \\\n",
              "105978  2024-05-07  496.000000  501.649994  495.040009  500.959991   3751800   \n",
              "105979  2024-05-07  273.720001  277.880005  272.829987  276.459991   6376700   \n",
              "105980  2024-05-07   39.529999   39.580002   39.090000   39.310001  11932800   \n",
              "105981  2024-05-07   17.280001   17.570000   17.250000   17.350000   8926000   \n",
              "105982  2024-05-07   60.169998   60.799999   60.049999   60.619999  14517100   \n",
              "\n",
              "        tic  day  \n",
              "105978  UNH    1  \n",
              "105979    V    1  \n",
              "105980   VZ    1  \n",
              "105981  WBA    1  \n",
              "105982  WMT    1  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV3HrZHLh1hy",
        "outputId": "44fd4e2f-4039-4a61-ee77-8795b880583c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(105983, 8)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4hYkeaPiICHS",
        "outputId": "614ff8c3-c3a3-4dbf-e0f5-7af5bf3c2926"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>7.622500</td>\n",
              "      <td>7.660714</td>\n",
              "      <td>7.585000</td>\n",
              "      <td>6.470741</td>\n",
              "      <td>493729600</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>56.630001</td>\n",
              "      <td>57.869999</td>\n",
              "      <td>56.560001</td>\n",
              "      <td>41.493397</td>\n",
              "      <td>5277400</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>40.810001</td>\n",
              "      <td>41.099998</td>\n",
              "      <td>40.389999</td>\n",
              "      <td>33.090443</td>\n",
              "      <td>6894300</td>\n",
              "      <td>AXP</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>55.720001</td>\n",
              "      <td>56.389999</td>\n",
              "      <td>54.799999</td>\n",
              "      <td>43.777546</td>\n",
              "      <td>6186700</td>\n",
              "      <td>BA</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>57.650002</td>\n",
              "      <td>59.189999</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>40.190220</td>\n",
              "      <td>7325600</td>\n",
              "      <td>CAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date       open       high        low      close     volume   tic  \\\n",
              "0  2010-01-04   7.622500   7.660714   7.585000   6.470741  493729600  AAPL   \n",
              "1  2010-01-04  56.630001  57.869999  56.560001  41.493397    5277400  AMGN   \n",
              "2  2010-01-04  40.810001  41.099998  40.389999  33.090443    6894300   AXP   \n",
              "3  2010-01-04  55.720001  56.389999  54.799999  43.777546    6186700    BA   \n",
              "4  2010-01-04  57.650002  59.189999  57.509998  40.190220    7325600   CAT   \n",
              "\n",
              "   day  \n",
              "0    0  \n",
              "1    0  \n",
              "2    0  \n",
              "3    0  \n",
              "4    0  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sort_values(['date','tic']).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2vryMsdNL9H",
        "outputId": "771b8864-aeb2-4e72-e512-52af390b2306"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df.tic.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcNyXa7RNPrF",
        "outputId": "a5c07dcf-e648-4507-acb7-7c5f40f65a69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tic\n",
              "AAPL    3610\n",
              "AMGN    3610\n",
              "WMT     3610\n",
              "WBA     3610\n",
              "VZ      3610\n",
              "V       3610\n",
              "UNH     3610\n",
              "TRV     3610\n",
              "PG      3610\n",
              "NKE     3610\n",
              "MSFT    3610\n",
              "MRK     3610\n",
              "MMM     3610\n",
              "MCD     3610\n",
              "KO      3610\n",
              "JPM     3610\n",
              "JNJ     3610\n",
              "INTC    3610\n",
              "IBM     3610\n",
              "HON     3610\n",
              "HD      3610\n",
              "GS      3610\n",
              "DIS     3610\n",
              "CVX     3610\n",
              "CSCO    3610\n",
              "CRM     3610\n",
              "CAT     3610\n",
              "BA      3610\n",
              "AXP     3610\n",
              "DOW     1293\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tic.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqC6c40Zh1iH"
      },
      "source": [
        "# Part 4: Preprocess Data\n",
        "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
        "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
        "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kM5bH9uroCeg"
      },
      "outputs": [],
      "source": [
        "INDICATORS = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgXfBcjxtj1a",
        "outputId": "f8918abd-ab34-438f-da60-31970b872cf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n"
          ]
        }
      ],
      "source": [
        "fe = FeatureEngineer(use_technical_indicator=True,\n",
        "                     tech_indicator_list = INDICATORS,\n",
        "                     use_turbulence=True,\n",
        "                     user_defined_feature = False)\n",
        "\n",
        "processed = fe.preprocess_data(df)\n",
        "processed = processed.copy()\n",
        "processed = processed.fillna(0)\n",
        "processed = processed.replace(np.inf,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "grvhGJJII3Xn",
        "outputId": "dc5b6d6f-00a1-4363-f4d8-a5ab117d6031"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>75563</th>\n",
              "      <td>2020-05-11</td>\n",
              "      <td>123.595322</td>\n",
              "      <td>123.712372</td>\n",
              "      <td>121.730766</td>\n",
              "      <td>98.755051</td>\n",
              "      <td>3629382</td>\n",
              "      <td>MMM</td>\n",
              "      <td>0</td>\n",
              "      <td>31.502884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24816</th>\n",
              "      <td>2013-05-29</td>\n",
              "      <td>31.455000</td>\n",
              "      <td>31.584999</td>\n",
              "      <td>31.200001</td>\n",
              "      <td>27.811028</td>\n",
              "      <td>5521200</td>\n",
              "      <td>NKE</td>\n",
              "      <td>2</td>\n",
              "      <td>45.109987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100534</th>\n",
              "      <td>2023-10-11</td>\n",
              "      <td>331.209991</td>\n",
              "      <td>332.820007</td>\n",
              "      <td>329.140015</td>\n",
              "      <td>331.134338</td>\n",
              "      <td>20063200</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>2</td>\n",
              "      <td>41.360123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57608</th>\n",
              "      <td>2017-11-21</td>\n",
              "      <td>138.449997</td>\n",
              "      <td>139.259995</td>\n",
              "      <td>138.190002</td>\n",
              "      <td>116.040985</td>\n",
              "      <td>5660600</td>\n",
              "      <td>JNJ</td>\n",
              "      <td>1</td>\n",
              "      <td>12.867973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6515</th>\n",
              "      <td>2010-11-22</td>\n",
              "      <td>33.864506</td>\n",
              "      <td>34.007633</td>\n",
              "      <td>33.568703</td>\n",
              "      <td>21.674612</td>\n",
              "      <td>15256050</td>\n",
              "      <td>MRK</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              date        open        high         low       close    volume  \\\n",
              "75563   2020-05-11  123.595322  123.712372  121.730766   98.755051   3629382   \n",
              "24816   2013-05-29   31.455000   31.584999   31.200001   27.811028   5521200   \n",
              "100534  2023-10-11  331.209991  332.820007  329.140015  331.134338  20063200   \n",
              "57608   2017-11-21  138.449997  139.259995  138.190002  116.040985   5660600   \n",
              "6515    2010-11-22   33.864506   34.007633   33.568703   21.674612  15256050   \n",
              "\n",
              "         tic  day  turbulence  \n",
              "75563    MMM    0   31.502884  \n",
              "24816    NKE    2   45.109987  \n",
              "100534  MSFT    2   41.360123  \n",
              "57608    JNJ    1   12.867973  \n",
              "6515     MRK    0    0.000000  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QsYaY0Dh1iw"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Part 5. Design Environment\n",
        "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
        "\n",
        "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
        "\n",
        "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2zqII8rMIqn",
        "outputId": "19f19ad3-e5d3-45b3-c40a-f2b1aa0c69de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock Dimension: 29, State Space: 59\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(processed.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AWyp84Ltto19"
      },
      "outputs": [],
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"buy_cost_pct\": 0.001,\n",
        "    \"sell_cost_pct\": 0.001,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4,\n",
        "    \"print_verbosity\":5\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMNR5nHjh1iz"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Part 6: Implement DRL Algorithms\n",
        "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
        "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
        "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
        "design their own DRL algorithms by adapting these DRL algorithms.\n",
        "\n",
        "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "v-gthCxMtj1d"
      },
      "outputs": [],
      "source": [
        "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
        "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
        "\n",
        "ensemble_agent = DRLEnsembleAgent(df=processed,\n",
        "                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
        "                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
        "                 rebalance_window=rebalance_window,\n",
        "                 validation_window=validation_window,\n",
        "                 **env_kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KsfEHa_Etj1d",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "A2C_model_kwargs = {\n",
        "                    'n_steps': 5,\n",
        "                    'ent_coef': 0.005,\n",
        "                    'learning_rate': 0.0007\n",
        "                    }\n",
        "\n",
        "PPO_model_kwargs = {\n",
        "                    \"ent_coef\":0.01,\n",
        "                    \"n_steps\": 2048,\n",
        "                    \"learning_rate\": 0.00025,\n",
        "                    \"batch_size\": 128\n",
        "                    }\n",
        "\n",
        "DDPG_model_kwargs = {\n",
        "                      #\"action_noise\":\"ornstein_uhlenbeck\",\n",
        "                      \"buffer_size\": 10_000,\n",
        "                      \"learning_rate\": 0.0005,\n",
        "                      \"batch_size\": 64\n",
        "                    }\n",
        "\n",
        "timesteps_dict = {'a2c' : 10_000,\n",
        "                 'ppo' : 10_000,\n",
        "                 'ddpg' : 10_000\n",
        "                 }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1lyCECstj1e",
        "outputId": "e7533b68-133f-4986-d27c-e3e4c8a08f16",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============Start Ensemble Strategy============\n",
            "============================================\n",
            "turbulence_threshold:  201.74083439773815\n",
            "======Model training from:  2010-01-01 to  2021-10-04\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c\\a2c_126_3\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -55.4      |\n",
            "|    reward             | 0.15343033 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 2.37       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 92         |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 10         |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0.0654     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -8.2       |\n",
            "|    reward             | 0.59488475 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 2.11       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 92         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.00239   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | 40.4       |\n",
            "|    reward             | -2.3820539 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 4.74       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 21        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 76.4      |\n",
            "|    reward             | 0.6525116 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 4.92      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 93         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 26         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 99.1       |\n",
            "|    reward             | -0.6508464 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 9.41       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 32        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -9.74     |\n",
            "|    reward             | 0.6677118 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.073     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 37        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 35.5      |\n",
            "|    reward             | 0.6000379 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 1.07      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 93          |\n",
            "|    iterations         | 800         |\n",
            "|    time_elapsed       | 42          |\n",
            "|    total_timesteps    | 4000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 799         |\n",
            "|    policy_loss        | 54.8        |\n",
            "|    reward             | 0.009824852 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 2.42        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 93          |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 48          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | -77.7       |\n",
            "|    reward             | -0.85522115 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 8.92        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 93          |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 53          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0.009       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | -509        |\n",
            "|    reward             | -0.37354362 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 221         |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 93       |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 59       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | -55.7    |\n",
            "|    reward             | 2.009143 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 5.79     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 93         |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 64         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | -1.44      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -32.7      |\n",
            "|    reward             | -0.5326045 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 2.04       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 69        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | -0.00623  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -13.2     |\n",
            "|    reward             | 1.2111777 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.721     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 93         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 74         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 72.1       |\n",
            "|    reward             | 0.12463365 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 5.33       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 93          |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 80          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | -55.5       |\n",
            "|    reward             | -0.23431118 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 2.1         |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 93       |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 85       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | -16.8    |\n",
            "|    reward             | 0.164122 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 16.9     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 91        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 2.38e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -275      |\n",
            "|    reward             | 13.214293 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 125       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 93         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 96         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | -0.0257    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -86.8      |\n",
            "|    reward             | 0.14927088 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 6.57       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 92         |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 102        |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0.271      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | 76.3       |\n",
            "|    reward             | 0.51453066 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 4.81       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 92        |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 107       |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0.27      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 58.4      |\n",
            "|    reward             | 0.9055865 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 2.36      |\n",
            "-------------------------------------\n",
            "======A2C Validation from:  2021-10-04 to  2022-01-03\n",
            "A2C Sharpe Ratio:  0.49462285143299844\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo\\ppo_126_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 104       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 19        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 1.6523136 |\n",
            "----------------------------------\n",
            "day: 2957, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3351766.92\n",
            "total_reward: 2351766.92\n",
            "total_cost: 388078.49\n",
            "total_trades: 82378\n",
            "Sharpe: 0.719\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 103         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 39          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012863273 |\n",
            "|    clip_fraction        | 0.199       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0182     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.89        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0272     |\n",
            "|    reward               | 1.0184733   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 10.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 103         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 59          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015795637 |\n",
            "|    clip_fraction        | 0.179       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00697    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 16.4        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0204     |\n",
            "|    reward               | 0.101595655 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 31.4        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 103          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 79           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0145232435 |\n",
            "|    clip_fraction        | 0.151        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -41.3        |\n",
            "|    explained_variance   | 0.0046       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 17.5         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.0242      |\n",
            "|    reward               | 3.505877     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 37.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 103          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 98           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.013786883  |\n",
            "|    clip_fraction        | 0.134        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -41.3        |\n",
            "|    explained_variance   | -0.0172      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 7.27         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.0223      |\n",
            "|    reward               | -0.022832824 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 15.6         |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2021-10-04 to  2022-01-03\n",
            "PPO Sharpe Ratio:  0.22233916878978055\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg\\ddpg_126_1\n",
            "day: 2957, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4926306.04\n",
            "total_reward: 3926306.04\n",
            "total_cost: 1076.75\n",
            "total_trades: 54943\n",
            "Sharpe: 0.825\n",
            "=================================\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 146      |\n",
            "|    total_timesteps | 11832    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33      |\n",
            "|    critic_loss     | 697      |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 8874     |\n",
            "|    reward          | 9.416629 |\n",
            "---------------------------------\n",
            "======DDPG Validation from:  2021-10-04 to  2022-01-03\n",
            "======Best Model Retraining from:  2010-01-01 to  2022-01-03\n",
            "======Trading from:  2022-01-03 to  2022-04-04\n",
            "============================================\n",
            "turbulence_threshold:  201.74083439773815\n",
            "======Model training from:  2010-01-01 to  2022-01-03\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c\\a2c_189_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.107     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -81.2      |\n",
            "|    reward             | -0.4225677 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 3.4        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 10         |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -20.6      |\n",
            "|    reward             | 0.31703055 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.16       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.0528    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -93.8      |\n",
            "|    reward             | -3.1962457 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 8.9        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 21        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -0.161    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -63.6     |\n",
            "|    reward             | 1.5626101 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 2.59      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 91          |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 27          |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | -45         |\n",
            "|    reward             | -0.42232475 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 1.57        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 32         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | -5.42      |\n",
            "|    reward             | 0.16343325 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.996      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 38         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | -138       |\n",
            "|    reward             | 0.25410935 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 11.8       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 43         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 31.7       |\n",
            "|    reward             | 0.82723457 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.05       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 49        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | -115      |\n",
            "|    reward             | 0.6402822 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 8.96      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 54         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | 21.5       |\n",
            "|    reward             | -1.3933451 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.07       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 59        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 202       |\n",
            "|    reward             | 1.4414024 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 35.1      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 91       |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 65       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 148      |\n",
            "|    reward             | 4.826495 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 12.9     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 70        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -33.2     |\n",
            "|    reward             | 1.2026678 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 1.14      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 76         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0.141      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 169        |\n",
            "|    reward             | -0.7079433 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 21.5       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 81        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 145       |\n",
            "|    reward             | 0.4018369 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 15.9      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 91          |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 87          |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | 75.4        |\n",
            "|    reward             | -0.53048044 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 5.86        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 92         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 109        |\n",
            "|    reward             | -4.2493577 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 10         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 98         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -99.4      |\n",
            "|    reward             | -4.3982215 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 7.68       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 103       |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 35.9      |\n",
            "|    reward             | 1.8684932 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 2.43      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 109        |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 2.38e-06   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 37         |\n",
            "|    reward             | -1.3241539 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.87       |\n",
            "--------------------------------------\n",
            "======A2C Validation from:  2022-01-03 to  2022-04-04\n",
            "A2C Sharpe Ratio:  -0.24942573162760653\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo\\ppo_189_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 104       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 19        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 1.0176039 |\n",
            "----------------------------------\n",
            "day: 3020, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 5238059.75\n",
            "total_reward: 4238059.75\n",
            "total_cost: 409359.97\n",
            "total_trades: 84463\n",
            "Sharpe: 0.904\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 102         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 39          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017282804 |\n",
            "|    clip_fraction        | 0.245       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | 0.0054      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 8.66        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0217     |\n",
            "|    reward               | -1.9984013  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 13.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 102         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 60          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012703261 |\n",
            "|    clip_fraction        | 0.127       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00955    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 27.4        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0208     |\n",
            "|    reward               | -0.45300925 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 76          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 102         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 80          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018048363 |\n",
            "|    clip_fraction        | 0.176       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.00158    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 33.7        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.019      |\n",
            "|    reward               | -0.9156067  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 54.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 102         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 100         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015029843 |\n",
            "|    clip_fraction        | 0.175       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0755     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.44        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0233     |\n",
            "|    reward               | -0.17893295 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 8.79        |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2022-01-03 to  2022-04-04\n",
            "PPO Sharpe Ratio:  -0.18622197073465957\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg\\ddpg_189_1\n",
            "day: 3020, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 5900017.32\n",
            "total_reward: 4900017.32\n",
            "total_cost: 1253.35\n",
            "total_trades: 48340\n",
            "Sharpe: 0.879\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 80         |\n",
            "|    time_elapsed    | 150        |\n",
            "|    total_timesteps | 12084      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -67.1      |\n",
            "|    critic_loss     | 96.8       |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 9063       |\n",
            "|    reward          | -0.5323431 |\n",
            "-----------------------------------\n",
            "======DDPG Validation from:  2022-01-03 to  2022-04-04\n",
            "======Best Model Retraining from:  2010-01-01 to  2022-04-04\n",
            "======Trading from:  2022-04-04 to  2022-07-06\n",
            "============================================\n",
            "turbulence_threshold:  201.74083439773815\n",
            "======Model training from:  2010-01-01 to  2022-04-04\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c\\a2c_252_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 92          |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -29.9       |\n",
            "|    reward             | -0.13549392 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 1.11        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 10         |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -123       |\n",
            "|    reward             | -0.5332428 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 11.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | -0.0275    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | 13.4       |\n",
            "|    reward             | -1.4715425 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 3.05       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 91          |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 21          |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | 103         |\n",
            "|    reward             | -0.71163493 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 8.86        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 27        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 121       |\n",
            "|    reward             | 1.3030665 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 10.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 32        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 82.6      |\n",
            "|    reward             | 1.9835455 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 8.44      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 38         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | -80.5      |\n",
            "|    reward             | 0.68270963 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 5.36       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 43        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -174      |\n",
            "|    reward             | 0.8429217 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 18.7      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 91           |\n",
            "|    iterations         | 900          |\n",
            "|    time_elapsed       | 48           |\n",
            "|    total_timesteps    | 4500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.4        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 899          |\n",
            "|    policy_loss        | -90.9        |\n",
            "|    reward             | -0.024105154 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 6.98         |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 54        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -0.458    |\n",
            "|    reward             | 1.3875396 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.619     |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 91           |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 60           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.4        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | -166         |\n",
            "|    reward             | -0.018345973 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 25.4         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 65         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 101        |\n",
            "|    reward             | -1.9610506 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 15.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 71        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 148       |\n",
            "|    reward             | 0.4857627 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 13.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 76         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 5.94       |\n",
            "|    reward             | 0.96696436 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.951      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 82        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | -22.6     |\n",
            "|    reward             | 0.2603565 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 1.71      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 87         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 2.67       |\n",
            "|    reward             | -0.8348165 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.0569     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 92         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | -3.77e-05  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | -119       |\n",
            "|    reward             | 0.21970606 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 9.86       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 98         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | 362        |\n",
            "|    reward             | 0.48299813 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 84.1       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 103        |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 1.54e-05   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | 2.51       |\n",
            "|    reward             | 0.11492139 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.161      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 91          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 109         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | -64         |\n",
            "|    reward             | -0.21962184 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 2.52        |\n",
            "---------------------------------------\n",
            "======A2C Validation from:  2022-04-04 to  2022-07-06\n",
            "A2C Sharpe Ratio:  -0.22474036748391532\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo\\ppo_252_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 105       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 19        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 1.1213197 |\n",
            "----------------------------------\n",
            "day: 3083, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3490925.39\n",
            "total_reward: 2490925.39\n",
            "total_cost: 422073.19\n",
            "total_trades: 86031\n",
            "Sharpe: 0.687\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 103          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 39           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0149507355 |\n",
            "|    clip_fraction        | 0.2          |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -41.2        |\n",
            "|    explained_variance   | -0.00446     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.57         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.0183      |\n",
            "|    reward               | -0.54827034  |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 9.96         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 102         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 59          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015459456 |\n",
            "|    clip_fraction        | 0.15        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00904    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 43.9        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0204     |\n",
            "|    reward               | -0.89208597 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 54.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 101         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 80          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013787061 |\n",
            "|    clip_fraction        | 0.154       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0217     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 14.7        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0202     |\n",
            "|    reward               | -0.12751773 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 37.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 101         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 100         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019391645 |\n",
            "|    clip_fraction        | 0.223       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0841     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 6.16        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0229     |\n",
            "|    reward               | -0.7721376  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 13          |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2022-04-04 to  2022-07-06\n",
            "PPO Sharpe Ratio:  -0.21956560226093524\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg\\ddpg_252_1\n",
            "day: 3083, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 5504618.80\n",
            "total_reward: 4504618.80\n",
            "total_cost: 1512.40\n",
            "total_trades: 64283\n",
            "Sharpe: 0.879\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 79        |\n",
            "|    time_elapsed    | 155       |\n",
            "|    total_timesteps | 12336     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 7.57      |\n",
            "|    critic_loss     | 123       |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 9252      |\n",
            "|    reward          | 2.6042688 |\n",
            "----------------------------------\n",
            "======DDPG Validation from:  2022-04-04 to  2022-07-06\n",
            "======Best Model Retraining from:  2010-01-01 to  2022-07-06\n",
            "======Trading from:  2022-07-06 to  2022-10-04\n",
            "============================================\n",
            "turbulence_threshold:  201.74083439773815\n",
            "======Model training from:  2010-01-01 to  2022-07-06\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c\\a2c_315_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 92          |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -92.3       |\n",
            "|    reward             | -0.38629052 |\n",
            "|    std                | 0.998       |\n",
            "|    value_loss         | 5.73        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -7.15     |\n",
            "|    reward             | 1.6655227 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 5.34      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -29.5      |\n",
            "|    reward             | -2.7711353 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 2.02       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 153       |\n",
            "|    reward             | 0.8963048 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 19.1      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 90          |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 27          |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | -279        |\n",
            "|    reward             | -0.36549014 |\n",
            "|    std                | 0.999       |\n",
            "|    value_loss         | 51.1        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -289      |\n",
            "|    reward             | 16.972912 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 115       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 38        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 11.5      |\n",
            "|    reward             | 0.8247164 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 0.82      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 44        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 259       |\n",
            "|    reward             | 1.0356469 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 44.9      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 49         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | 113        |\n",
            "|    reward             | -0.6797975 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 10.7       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 55        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -0.102    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -84.3     |\n",
            "|    reward             | 2.0148902 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 4.74      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 60        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 150       |\n",
            "|    reward             | 5.1362457 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 20.1      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 66        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 140       |\n",
            "|    reward             | 2.9513705 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 36.1      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 71        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0.001     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 7.51      |\n",
            "|    reward             | 0.3578857 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 0.575     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 77         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | -67.6      |\n",
            "|    reward             | -2.7898223 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 4.47       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 90       |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 82       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.1    |\n",
            "|    explained_variance | -0.0102  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | -183     |\n",
            "|    reward             | 3.601234 |\n",
            "|    std                | 0.998    |\n",
            "|    value_loss         | 26.1     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 88         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -0.188     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 62.2       |\n",
            "|    reward             | -1.4769127 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 2.58       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 93         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -0.189     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 12.3       |\n",
            "|    reward             | -1.2143531 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 1.36       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 99         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -80        |\n",
            "|    reward             | -1.7030269 |\n",
            "|    std                | 0.995      |\n",
            "|    value_loss         | 19.2       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 90          |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 104         |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41         |\n",
            "|    explained_variance | -0.985      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | 61.5        |\n",
            "|    reward             | -0.09811853 |\n",
            "|    std                | 0.996       |\n",
            "|    value_loss         | 2.56        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 110        |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 122        |\n",
            "|    reward             | -0.4492046 |\n",
            "|    std                | 0.996      |\n",
            "|    value_loss         | 10.6       |\n",
            "--------------------------------------\n",
            "======A2C Validation from:  2022-07-06 to  2022-10-04\n",
            "A2C Sharpe Ratio:  -0.18239902395851326\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo\\ppo_315_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    fps             | 104      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 19       |\n",
            "|    total_timesteps | 2048     |\n",
            "| train/             |          |\n",
            "|    reward          | 2.363934 |\n",
            "---------------------------------\n",
            "day: 3146, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3265618.30\n",
            "total_reward: 2265618.30\n",
            "total_cost: 438852.64\n",
            "total_trades: 87815\n",
            "Sharpe: 0.612\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 102         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 39          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013685908 |\n",
            "|    clip_fraction        | 0.19        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | 0.00624     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 7.52        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0232     |\n",
            "|    reward               | 3.8007479   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 13.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 101         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 60          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015338118 |\n",
            "|    clip_fraction        | 0.159       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00474    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 40.5        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0124     |\n",
            "|    reward               | 5.2829356   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 81.6        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 100        |\n",
            "|    iterations           | 4          |\n",
            "|    time_elapsed         | 81         |\n",
            "|    total_timesteps      | 8192       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01751656 |\n",
            "|    clip_fraction        | 0.203      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.3      |\n",
            "|    explained_variance   | -0.00416   |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 33.6       |\n",
            "|    n_updates            | 30         |\n",
            "|    policy_gradient_loss | -0.0173    |\n",
            "|    reward               | 0.7551067  |\n",
            "|    std                  | 1.01       |\n",
            "|    value_loss           | 66         |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 100         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 102         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020653144 |\n",
            "|    clip_fraction        | 0.24        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0157     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 16          |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.023      |\n",
            "|    reward               | 1.2732291   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 27.3        |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2022-07-06 to  2022-10-04\n",
            "PPO Sharpe Ratio:  -0.19266685667048464\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg\\ddpg_315_1\n",
            "day: 3146, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 5669395.17\n",
            "total_reward: 4669395.17\n",
            "total_cost: 999.00\n",
            "total_trades: 58461\n",
            "Sharpe: 0.877\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 78         |\n",
            "|    time_elapsed    | 160        |\n",
            "|    total_timesteps | 12588      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -29.5      |\n",
            "|    critic_loss     | 702        |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 9441       |\n",
            "|    reward          | 0.23952857 |\n",
            "-----------------------------------\n",
            "======DDPG Validation from:  2022-07-06 to  2022-10-04\n",
            "======Best Model Retraining from:  2010-01-01 to  2022-10-04\n",
            "======Trading from:  2022-10-04 to  2023-01-04\n",
            "============================================\n",
            "turbulence_threshold:  201.74083439773815\n",
            "======Model training from:  2010-01-01 to  2022-10-04\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c\\a2c_378_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0.61       |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -52.8      |\n",
            "|    reward             | -0.4647513 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.78       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 88         |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 11         |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | -0.156     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -23.4      |\n",
            "|    reward             | 0.04916978 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.996      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 88         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0.146      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -79.4      |\n",
            "|    reward             | -4.0536613 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 10.8       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 88        |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 127       |\n",
            "|    reward             | 3.5725493 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 22.7      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 88         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 28         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -20        |\n",
            "|    reward             | -1.4437479 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.47       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 89       |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 33       |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 228      |\n",
            "|    reward             | 8.12436  |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 62.9     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 89          |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 39          |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | -5.08       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | 38.3        |\n",
            "|    reward             | -0.28368995 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 1.49        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 44         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | -0.0906    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | -13        |\n",
            "|    reward             | -2.5126407 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.318      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 89          |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 50          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | 98.4        |\n",
            "|    reward             | -0.06896265 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 8.68        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 56        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 219       |\n",
            "|    reward             | 3.4997585 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 43.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 61         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | 69.5       |\n",
            "|    reward             | -2.5656483 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 3.5        |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 89       |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 67       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | -991     |\n",
            "|    reward             | 6.5323   |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 618      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 88        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 73        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0.358     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 33.1      |\n",
            "|    reward             | 1.7167236 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.843     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 78         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 2.38e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 50.6       |\n",
            "|    reward             | -0.8691711 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 4.03       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 84        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | -0.00753  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | -299      |\n",
            "|    reward             | 1.5592991 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 68.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 89        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | -116      |\n",
            "|    reward             | 1.4385003 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 10.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 95        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -244      |\n",
            "|    reward             | 3.2500687 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 55.9      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 100        |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | 1.34e+03   |\n",
            "|    reward             | -7.0652514 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 2.45e+03   |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 89       |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 106      |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -146     |\n",
            "|    reward             | 2.147273 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 77.1     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 112       |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -0.00176  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | -93.7     |\n",
            "|    reward             | -1.099435 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 6.29      |\n",
            "-------------------------------------\n",
            "======A2C Validation from:  2022-10-04 to  2023-01-04\n",
            "A2C Sharpe Ratio:  0.2709388012156662\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo\\ppo_378_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 100       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 20        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 1.0776305 |\n",
            "----------------------------------\n",
            "day: 3209, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3873382.72\n",
            "total_reward: 2873382.72\n",
            "total_cost: 459376.14\n",
            "total_trades: 89668\n",
            "Sharpe: 0.714\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 98         |\n",
            "|    iterations           | 2          |\n",
            "|    time_elapsed         | 41         |\n",
            "|    total_timesteps      | 4096       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01065842 |\n",
            "|    clip_fraction        | 0.168      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.2      |\n",
            "|    explained_variance   | -0.053     |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 5.02       |\n",
            "|    n_updates            | 10         |\n",
            "|    policy_gradient_loss | -0.0224    |\n",
            "|    reward               | 0.505212   |\n",
            "|    std                  | 1          |\n",
            "|    value_loss           | 11.8       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 98          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 62          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016933005 |\n",
            "|    clip_fraction        | 0.229       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0136     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 46.7        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0158     |\n",
            "|    reward               | 0.77576184  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 69.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 97          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 83          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014026482 |\n",
            "|    clip_fraction        | 0.126       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0311     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 34.7        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0239     |\n",
            "|    reward               | -1.272313   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 57.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 97          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 104         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021196125 |\n",
            "|    clip_fraction        | 0.217       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0198     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 21.9        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0204     |\n",
            "|    reward               | 0.4049905   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 36          |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2022-10-04 to  2023-01-04\n",
            "PPO Sharpe Ratio:  0.2780172482788244\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg\\ddpg_378_1\n",
            "day: 3209, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 5915028.64\n",
            "total_reward: 4915028.64\n",
            "total_cost: 1002.96\n",
            "total_trades: 41858\n",
            "Sharpe: 0.880\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 78        |\n",
            "|    time_elapsed    | 164       |\n",
            "|    total_timesteps | 12840     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 37.3      |\n",
            "|    critic_loss     | 151       |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 9630      |\n",
            "|    reward          | 14.706126 |\n",
            "----------------------------------\n",
            "======DDPG Validation from:  2022-10-04 to  2023-01-04\n",
            "======Best Model Retraining from:  2010-01-01 to  2023-01-04\n",
            "======Trading from:  2023-01-04 to  2023-04-05\n",
            "============================================\n",
            "turbulence_threshold:  201.74083439773815\n",
            "======Model training from:  2010-01-01 to  2023-01-04\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c\\a2c_441_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 90          |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41         |\n",
            "|    explained_variance | 0.0108      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -11.5       |\n",
            "|    reward             | -0.19008511 |\n",
            "|    std                | 0.996       |\n",
            "|    value_loss         | 0.536       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -69.3     |\n",
            "|    reward             | 1.0829397 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 9.51      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -48.9      |\n",
            "|    reward             | -3.6834123 |\n",
            "|    std                | 0.995      |\n",
            "|    value_loss         | 6.37       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0.0671    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 82.9      |\n",
            "|    reward             | 1.7236397 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 11.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 27         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -62.2      |\n",
            "|    reward             | 0.64758897 |\n",
            "|    std                | 0.997      |\n",
            "|    value_loss         | 4.12       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | -0.00165  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -36.3     |\n",
            "|    reward             | 7.9658737 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 35.4      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 89          |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 39          |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | -16.9       |\n",
            "|    reward             | -0.90622103 |\n",
            "|    std                | 0.996       |\n",
            "|    value_loss         | 1.32        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 44        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -85       |\n",
            "|    reward             | 0.5046412 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 5.14      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 50         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | 50.8       |\n",
            "|    reward             | -0.6599653 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 1.89       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 55        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -66.6     |\n",
            "|    reward             | -3.037865 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 3.28      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 61         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0.0317     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | 13.9       |\n",
            "|    reward             | 0.66463965 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 9.02       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 89       |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 67       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.1    |\n",
            "|    explained_variance | -0.0162  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | -326     |\n",
            "|    reward             | 4.496167 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 77.7     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 89          |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 72          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | 0.076       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | 178         |\n",
            "|    reward             | -0.46002513 |\n",
            "|    std                | 0.999       |\n",
            "|    value_loss         | 28.6        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 78         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0.279      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 31.6       |\n",
            "|    reward             | 0.80528504 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 1.78       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 84         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0.00534    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 95.5       |\n",
            "|    reward             | -1.6600767 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 7.09       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 89         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0.16       |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 142        |\n",
            "|    reward             | -1.1693246 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 17.5       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 89          |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 95          |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | 0.182       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | -32.5       |\n",
            "|    reward             | -0.08587763 |\n",
            "|    std                | 0.999       |\n",
            "|    value_loss         | 0.894       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 100       |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 61.4      |\n",
            "|    reward             | 0.5642335 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 3.2       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 106        |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.065     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | -268       |\n",
            "|    reward             | -5.8673387 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 55.5       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 89          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 112         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | 0.146       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | 53.6        |\n",
            "|    reward             | -0.14106959 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 1.9         |\n",
            "---------------------------------------\n",
            "======A2C Validation from:  2023-01-04 to  2023-04-05\n",
            "A2C Sharpe Ratio:  -0.16010355626579495\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo\\ppo_441_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 102       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 20        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 1.9537107 |\n",
            "----------------------------------\n",
            "day: 3272, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3563033.66\n",
            "total_reward: 2563033.66\n",
            "total_cost: 470143.35\n",
            "total_trades: 91282\n",
            "Sharpe: 0.664\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 100         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 40          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018948495 |\n",
            "|    clip_fraction        | 0.224       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | 0.0265      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.65        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0288     |\n",
            "|    reward               | 0.46118492  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 12.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 99          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 61          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015478967 |\n",
            "|    clip_fraction        | 0.163       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0326     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 29.7        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.021      |\n",
            "|    reward               | -0.5641253  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 66.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 99          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 82          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015207135 |\n",
            "|    clip_fraction        | 0.153       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0114     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 79.2        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0162     |\n",
            "|    reward               | 0.043458182 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 132         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 99          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 103         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019639973 |\n",
            "|    clip_fraction        | 0.193       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.00426    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 47.6        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.023      |\n",
            "|    reward               | -2.5394967  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 69.9        |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2023-01-04 to  2023-04-05\n",
            "PPO Sharpe Ratio:  -0.10466164557120752\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg\\ddpg_441_1\n",
            "day: 3272, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 5359596.34\n",
            "total_reward: 4359596.34\n",
            "total_cost: 1364.84\n",
            "total_trades: 39350\n",
            "Sharpe: 0.813\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 77         |\n",
            "|    time_elapsed    | 167        |\n",
            "|    total_timesteps | 13092      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 123        |\n",
            "|    critic_loss     | 3e+03      |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 9819       |\n",
            "|    reward          | -2.5730212 |\n",
            "-----------------------------------\n",
            "======DDPG Validation from:  2023-01-04 to  2023-04-05\n",
            "======Best Model Retraining from:  2010-01-01 to  2023-04-05\n",
            "======Trading from:  2023-04-05 to  2023-07-07\n",
            "============================================\n",
            "turbulence_threshold:  201.74083439773815\n",
            "======Model training from:  2010-01-01 to  2023-04-05\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c\\a2c_504_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 92           |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 5            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.1        |\n",
            "|    explained_variance | -0.0122      |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -72.6        |\n",
            "|    reward             | -0.070190944 |\n",
            "|    std                | 0.999        |\n",
            "|    value_loss         | 3.36         |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -38.1     |\n",
            "|    reward             | 0.7340021 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 5.08      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 88       |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41      |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -31.6    |\n",
            "|    reward             | -1.50441 |\n",
            "|    std                | 0.995    |\n",
            "|    value_loss         | 7.52     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 88         |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 22         |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | 127        |\n",
            "|    reward             | -0.7524859 |\n",
            "|    std                | 0.997      |\n",
            "|    value_loss         | 11.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 88        |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 28        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 142       |\n",
            "|    reward             | -1.669522 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 19.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 88        |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 34        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 141       |\n",
            "|    reward             | 13.376159 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 17.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 39        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 12.2      |\n",
            "|    reward             | 1.3792284 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 0.515     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 87          |\n",
            "|    iterations         | 800         |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 4000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 799         |\n",
            "|    policy_loss        | -2.9        |\n",
            "|    reward             | -0.04831867 |\n",
            "|    std                | 0.994       |\n",
            "|    value_loss         | 0.538       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 51        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | -3.34     |\n",
            "|    reward             | 0.5352697 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 0.13      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 87          |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 56          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41         |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | 128         |\n",
            "|    reward             | -0.23509687 |\n",
            "|    std                | 0.995       |\n",
            "|    value_loss         | 9.59        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 87       |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 62       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41      |\n",
            "|    explained_variance | -0.0212  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | -34.9    |\n",
            "|    reward             | 3.871213 |\n",
            "|    std                | 0.994    |\n",
            "|    value_loss         | 2.05     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 87       |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 68       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -40.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | -256     |\n",
            "|    reward             | 5.426841 |\n",
            "|    std                | 0.993    |\n",
            "|    value_loss         | 49.9     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 73        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 65.9      |\n",
            "|    reward             | 4.5342264 |\n",
            "|    std                | 0.993     |\n",
            "|    value_loss         | 45.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 79         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -40.9      |\n",
            "|    explained_variance | -0.307     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 26         |\n",
            "|    reward             | -0.9929136 |\n",
            "|    std                | 0.992      |\n",
            "|    value_loss         | 0.378      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 87          |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 85          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -40.9       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | 93.9        |\n",
            "|    reward             | -0.61839664 |\n",
            "|    std                | 0.993       |\n",
            "|    value_loss         | 5.88        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 90         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 63.5       |\n",
            "|    reward             | -0.6436812 |\n",
            "|    std                | 0.995      |\n",
            "|    value_loss         | 3.12       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 87          |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 96          |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | -42.1       |\n",
            "|    reward             | 0.080703534 |\n",
            "|    std                | 0.994       |\n",
            "|    value_loss         | 1.27        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 87       |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 102      |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41      |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 99.4     |\n",
            "|    reward             | 1.69348  |\n",
            "|    std                | 0.995    |\n",
            "|    value_loss         | 14.9     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 88         |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 107        |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | -193       |\n",
            "|    reward             | -3.5009205 |\n",
            "|    std                | 0.994      |\n",
            "|    value_loss         | 35.8       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 88        |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 113       |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0.00434   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 166       |\n",
            "|    reward             | 2.4941056 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 31.2      |\n",
            "-------------------------------------\n",
            "======A2C Validation from:  2023-04-05 to  2023-07-07\n",
            "A2C Sharpe Ratio:  0.027653783713635506\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo\\ppo_504_1\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 100         |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 20          |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | 0.124347955 |\n",
            "------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 98          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012974718 |\n",
            "|    clip_fraction        | 0.198       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00206    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.27        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.022      |\n",
            "|    reward               | 0.77147645  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 10.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 97          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 62          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014393873 |\n",
            "|    clip_fraction        | 0.138       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | 0.00086     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 56.5        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0136     |\n",
            "|    reward               | -1.2043198  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 67.9        |\n",
            "-----------------------------------------\n",
            "day: 3335, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3712070.09\n",
            "total_reward: 2712070.09\n",
            "total_cost: 475847.52\n",
            "total_trades: 92514\n",
            "Sharpe: 0.673\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 97           |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 84           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.014671238  |\n",
            "|    clip_fraction        | 0.148        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -41.3        |\n",
            "|    explained_variance   | -0.00337     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 14.8         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.0174      |\n",
            "|    reward               | -0.031617034 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 39.5         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 97          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 105         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015882943 |\n",
            "|    clip_fraction        | 0.138       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0403     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 14.1        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0196     |\n",
            "|    reward               | 0.033566944 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 27.9        |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2023-04-05 to  2023-07-07\n",
            "PPO Sharpe Ratio:  0.026987225511722092\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg\\ddpg_504_1\n",
            "day: 3335, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 5260693.78\n",
            "total_reward: 4260693.78\n",
            "total_cost: 1084.38\n",
            "total_trades: 60010\n",
            "Sharpe: 0.785\n",
            "=================================\n",
            "======DDPG Validation from:  2023-04-05 to  2023-07-07\n",
            "======Best Model Retraining from:  2010-01-01 to  2023-07-07\n",
            "======Trading from:  2023-07-07 to  2023-10-05\n",
            "============================================\n",
            "turbulence_threshold:  201.74083439773815\n",
            "======Model training from:  2010-01-01 to  2023-07-07\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c\\a2c_567_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 88         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0.31       |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -75.6      |\n",
            "|    reward             | 0.43616065 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 5.15       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -0.139    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -25.4     |\n",
            "|    reward             | 0.8033448 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 5.24      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 17         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -89.7      |\n",
            "|    reward             | -3.4577527 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 10.8       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0.131     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 17.6      |\n",
            "|    reward             | 1.7889403 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 0.861     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 28         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -66.2      |\n",
            "|    reward             | -0.4598025 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 2.97       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 86       |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.2    |\n",
            "|    explained_variance | -0.12    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 0.723    |\n",
            "|    reward             | 3.050113 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 8.54     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 40         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.0501    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | -90.9      |\n",
            "|    reward             | -1.0983027 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 11.8       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 46         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | -0.0647    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | -105       |\n",
            "|    reward             | 0.40426335 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 12.6       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 52        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 132       |\n",
            "|    reward             | -1.620201 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 16.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 57         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | -82.7      |\n",
            "|    reward             | 0.65329486 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 12.8       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 63        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 204       |\n",
            "|    reward             | 3.0198982 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 41.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 69        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 131       |\n",
            "|    reward             | 5.7635794 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 64.1      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 75        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -1.41e+03 |\n",
            "|    reward             | 35.078983 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 1.17e+03  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 81        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 63.2      |\n",
            "|    reward             | 0.5102086 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 3.16      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 87        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | -60.1     |\n",
            "|    reward             | 1.0334821 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 2.33      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 92        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0.00585   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | -24.8     |\n",
            "|    reward             | -4.081671 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 3.02      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 98         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.00192   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | -322       |\n",
            "|    reward             | -0.6900059 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 62         |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 104       |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -29.8     |\n",
            "|    reward             | -3.299752 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 3.94      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 110       |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -808      |\n",
            "|    reward             | 5.8567667 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 373       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 115        |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | -827       |\n",
            "|    reward             | -3.4508355 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 482        |\n",
            "--------------------------------------\n",
            "======A2C Validation from:  2023-07-07 to  2023-10-05\n",
            "A2C Sharpe Ratio:  -0.2652602351384045\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo\\ppo_567_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 98        |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 20        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 0.8106158 |\n",
            "----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 96          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 42          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017022885 |\n",
            "|    clip_fraction        | 0.214       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0303     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.89        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0295     |\n",
            "|    reward               | -0.41964298 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 14.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 96          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 63          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014938578 |\n",
            "|    clip_fraction        | 0.199       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | 0.00211     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 47.6        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0119     |\n",
            "|    reward               | 1.8215965   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 110         |\n",
            "-----------------------------------------\n",
            "day: 3398, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 5133497.08\n",
            "total_reward: 4133497.08\n",
            "total_cost: 493514.90\n",
            "total_trades: 94372\n",
            "Sharpe: 0.816\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 95          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 85          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016530443 |\n",
            "|    clip_fraction        | 0.162       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.00383    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 32.4        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0187     |\n",
            "|    reward               | 0.15820846  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 65.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 95          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 107         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019085696 |\n",
            "|    clip_fraction        | 0.222       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.4       |\n",
            "|    explained_variance   | -0.00536    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 36.3        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0138     |\n",
            "|    reward               | 0.13722612  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 74.6        |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2023-07-07 to  2023-10-05\n",
            "PPO Sharpe Ratio:  -0.44515315430293906\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg\\ddpg_567_1\n",
            "day: 3398, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4576267.74\n",
            "total_reward: 3576267.74\n",
            "total_cost: 999.00\n",
            "total_trades: 57766\n",
            "Sharpe: 0.751\n",
            "=================================\n",
            "======DDPG Validation from:  2023-07-07 to  2023-10-05\n",
            "======Best Model Retraining from:  2010-01-01 to  2023-10-05\n",
            "======Trading from:  2023-10-05 to  2024-01-05\n",
            "============================================\n",
            "turbulence_threshold:  201.74083439773815\n",
            "======Model training from:  2010-01-01 to  2023-10-05\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c\\a2c_630_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 88         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -39        |\n",
            "|    reward             | -0.5361342 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 3.32       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -22.5     |\n",
            "|    reward             | 2.0183175 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 1.11      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 17        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -54.6     |\n",
            "|    reward             | -4.017096 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 8.15      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 5.7       |\n",
            "|    reward             | 2.1557136 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 4.93      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 28        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | -60.4     |\n",
            "|    reward             | -4.699327 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 9.75      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 34         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | 610        |\n",
            "|    reward             | 0.77131027 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 378        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 40        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 18.8      |\n",
            "|    reward             | 0.541837  |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 0.493     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 86          |\n",
            "|    iterations         | 800         |\n",
            "|    time_elapsed       | 46          |\n",
            "|    total_timesteps    | 4000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 799         |\n",
            "|    policy_loss        | 58.3        |\n",
            "|    reward             | -0.63372284 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 2.62        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 52        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 149       |\n",
            "|    reward             | -1.465877 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 17.1      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 58        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -0.377    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -87.4     |\n",
            "|    reward             | 2.5749543 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 7.05      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 85         |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 64         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0.0618     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | -303       |\n",
            "|    reward             | 0.15686445 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 66.1       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 85       |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 69       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.1    |\n",
            "|    explained_variance | -0.00617 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | -217     |\n",
            "|    reward             | 8.48054  |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 67.1     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 85        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 75        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0.0303    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -1.53e+03 |\n",
            "|    reward             | -6.230367 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 1.76e+03  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 85        |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 81        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -0.224    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | -38.6     |\n",
            "|    reward             | 1.3341554 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 2.09      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 85        |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 87        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | -228      |\n",
            "|    reward             | 1.8726388 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 31.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 85        |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 93        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -0.0302   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | -177      |\n",
            "|    reward             | 1.3220756 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 21.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 85         |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 98         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0.164      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 172        |\n",
            "|    reward             | -0.7799363 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 20.9       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 85        |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 104       |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -269      |\n",
            "|    reward             | 5.7851753 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 74.7      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 85        |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 110       |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0.00887   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -794      |\n",
            "|    reward             | 11.365333 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 435       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 85         |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 116        |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 227        |\n",
            "|    reward             | -3.1705618 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 39         |\n",
            "--------------------------------------\n",
            "======A2C Validation from:  2023-10-05 to  2024-01-05\n",
            "A2C Sharpe Ratio:  0.28962888891580213\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo\\ppo_630_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 96        |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 21        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 1.4932735 |\n",
            "----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 94          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 43          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017108992 |\n",
            "|    clip_fraction        | 0.209       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0364     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 6.3         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.027      |\n",
            "|    reward               | -1.1597546  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 13.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 93          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 65          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014212993 |\n",
            "|    clip_fraction        | 0.169       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0183     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 38.8        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0165     |\n",
            "|    reward               | 1.9963493   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 77.3        |\n",
            "-----------------------------------------\n",
            "day: 3461, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4033957.54\n",
            "total_reward: 3033957.54\n",
            "total_cost: 514129.70\n",
            "total_trades: 95983\n",
            "Sharpe: 0.699\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 93          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 87          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015892997 |\n",
            "|    clip_fraction        | 0.186       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.00754    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 25.5        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0207     |\n",
            "|    reward               | 2.8381994   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 37          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 93          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 109         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019450031 |\n",
            "|    clip_fraction        | 0.241       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.00476    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 18.7        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0183     |\n",
            "|    reward               | -2.0146744  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 37.2        |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2023-10-05 to  2024-01-05\n",
            "PPO Sharpe Ratio:  0.35999375144244566\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg\\ddpg_630_1\n",
            "======DDPG Validation from:  2023-10-05 to  2024-01-05\n",
            "======Best Model Retraining from:  2010-01-01 to  2024-01-05\n",
            "======Trading from:  2024-01-05 to  2024-04-08\n",
            "Ensemble Strategy took:  58.14963819980621  minutes\n"
          ]
        }
      ],
      "source": [
        "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
        "                                                 PPO_model_kwargs,\n",
        "                                                 DDPG_model_kwargs,\n",
        "                                                 timesteps_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "-0qd8acMtj1f",
        "outputId": "dead85ce-b60d-4de9-ea79-c32d08505fd3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iter</th>\n",
              "      <th>Val Start</th>\n",
              "      <th>Val End</th>\n",
              "      <th>Model Used</th>\n",
              "      <th>A2C Sharpe</th>\n",
              "      <th>PPO Sharpe</th>\n",
              "      <th>DDPG Sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>126</td>\n",
              "      <td>2021-10-04</td>\n",
              "      <td>2022-01-03</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.494623</td>\n",
              "      <td>0.222339</td>\n",
              "      <td>0.124578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>189</td>\n",
              "      <td>2022-01-03</td>\n",
              "      <td>2022-04-04</td>\n",
              "      <td>PPO</td>\n",
              "      <td>-0.249426</td>\n",
              "      <td>-0.186222</td>\n",
              "      <td>-0.295094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>252</td>\n",
              "      <td>2022-04-04</td>\n",
              "      <td>2022-07-06</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.22474</td>\n",
              "      <td>-0.219566</td>\n",
              "      <td>-0.212933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>315</td>\n",
              "      <td>2022-07-06</td>\n",
              "      <td>2022-10-04</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.182399</td>\n",
              "      <td>-0.192667</td>\n",
              "      <td>-0.146105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>378</td>\n",
              "      <td>2022-10-04</td>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.270939</td>\n",
              "      <td>0.278017</td>\n",
              "      <td>0.289953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>441</td>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>2023-04-05</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.160104</td>\n",
              "      <td>-0.104662</td>\n",
              "      <td>-0.012727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>504</td>\n",
              "      <td>2023-04-05</td>\n",
              "      <td>2023-07-07</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.027654</td>\n",
              "      <td>0.026987</td>\n",
              "      <td>0.089874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>567</td>\n",
              "      <td>2023-07-07</td>\n",
              "      <td>2023-10-05</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.26526</td>\n",
              "      <td>-0.445153</td>\n",
              "      <td>0.007087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>630</td>\n",
              "      <td>2023-10-05</td>\n",
              "      <td>2024-01-05</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.289629</td>\n",
              "      <td>0.359994</td>\n",
              "      <td>0.479748</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
              "0  126  2021-10-04  2022-01-03        A2C   0.494623   0.222339    0.124578\n",
              "1  189  2022-01-03  2022-04-04        PPO  -0.249426  -0.186222   -0.295094\n",
              "2  252  2022-04-04  2022-07-06       DDPG   -0.22474  -0.219566   -0.212933\n",
              "3  315  2022-07-06  2022-10-04       DDPG  -0.182399  -0.192667   -0.146105\n",
              "4  378  2022-10-04  2023-01-04       DDPG   0.270939   0.278017    0.289953\n",
              "5  441  2023-01-04  2023-04-05       DDPG  -0.160104  -0.104662   -0.012727\n",
              "6  504  2023-04-05  2023-07-07       DDPG   0.027654   0.026987    0.089874\n",
              "7  567  2023-07-07  2023-10-05       DDPG   -0.26526  -0.445153    0.007087\n",
              "8  630  2023-10-05  2024-01-05       DDPG   0.289629   0.359994    0.479748"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6vvNSC6h1jZ"
      },
      "source": [
        "<a id='6'></a>\n",
        "# Part 7: Backtest Our Strategy\n",
        "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "X4JKB--8tj1g"
      },
      "outputs": [],
      "source": [
        "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_pG0iRDT47f",
        "outputId": "aa97d83d-4d6e-426f-b3a1-3c1d9da18278"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sharpe Ratio: 0.3071200133916769\n",
            "     account_value        date  daily_return    datadate\n",
            "0     1.000000e+06  2022-01-03           NaN  2022-01-03\n",
            "1     1.000926e+06  2022-01-04      0.000926  2022-01-04\n",
            "2     1.000072e+06  2022-01-05     -0.000854  2022-01-05\n",
            "3     9.979610e+05  2022-01-06     -0.002111  2022-01-06\n",
            "4     9.990834e+05  2022-01-07      0.001125  2022-01-07\n",
            "..             ...         ...           ...         ...\n",
            "562   1.095309e+06  2024-04-01     -0.008244  2024-04-01\n",
            "563   1.084390e+06  2024-04-02     -0.009969  2024-04-02\n",
            "564   1.089781e+06  2024-04-03      0.004972  2024-04-03\n",
            "565   1.074142e+06  2024-04-04     -0.014350  2024-04-04\n",
            "566   1.085783e+06  2024-04-05      0.010837  2024-04-05\n",
            "\n",
            "[567 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create DataFrame for unique trade dates\n",
        "df_trade_date = pd.DataFrame({'datadate': unique_trade_date})\n",
        "\n",
        "# Initialize an empty DataFrame for account values\n",
        "df_account_value = pd.DataFrame()\n",
        "\n",
        "# Iterate through unique trade dates and append account values from CSV files\n",
        "for i in range(rebalance_window + validation_window, len(unique_trade_date) + 1, rebalance_window):\n",
        "    temp = pd.read_csv(f'results/account_value_trade_ensemble_{i}.csv')\n",
        "    df_account_value = pd.concat([df_account_value, temp], ignore_index=True)\n",
        "\n",
        "# Calculate Sharpe Ratio\n",
        "sharpe = (252 ** 0.5) * df_account_value['account_value'].pct_change(1).mean() / df_account_value['account_value'].pct_change(1).std()\n",
        "print('Sharpe Ratio:', sharpe)\n",
        "\n",
        "# Join trade date DataFrame with account value DataFrame\n",
        "df_account_value = df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(df_account_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "q9mKF7GGtj1g",
        "outputId": "73d42350-1fdc-45f4-9190-abc19c4a751d",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
        "\n",
        "# df_account_value=pd.DataFrame()\n",
        "# for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
        "#     temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
        "#     df_account_value = df_account_value.append(temp,ignore_index=True)\n",
        "# sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
        "# print('Sharpe Ratio: ',sharpe)\n",
        "# df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oyosyW7_tj1g",
        "outputId": "4c1584c5-37e7-41ab-8ce4-20641f48bab6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_value</th>\n",
              "      <th>date</th>\n",
              "      <th>daily_return</th>\n",
              "      <th>datadate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>2022-01-03</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-01-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000926e+06</td>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>0.000926</td>\n",
              "      <td>2022-01-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.000072e+06</td>\n",
              "      <td>2022-01-05</td>\n",
              "      <td>-0.000854</td>\n",
              "      <td>2022-01-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.979610e+05</td>\n",
              "      <td>2022-01-06</td>\n",
              "      <td>-0.002111</td>\n",
              "      <td>2022-01-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.990834e+05</td>\n",
              "      <td>2022-01-07</td>\n",
              "      <td>0.001125</td>\n",
              "      <td>2022-01-07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   account_value        date  daily_return    datadate\n",
              "0   1.000000e+06  2022-01-03           NaN  2022-01-03\n",
              "1   1.000926e+06  2022-01-04      0.000926  2022-01-04\n",
              "2   1.000072e+06  2022-01-05     -0.000854  2022-01-05\n",
              "3   9.979610e+05  2022-01-06     -0.002111  2022-01-06\n",
              "4   9.990834e+05  2022-01-07      0.001125  2022-01-07"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_account_value.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "wLsRdw2Ctj1h",
        "outputId": "ecefb7a8-cdc3-4aad-9f5d-a7918b1be6eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "df_account_value.account_value.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr2zX7ZxNyFQ"
      },
      "source": [
        "<a id='6.1'></a>\n",
        "## 7.1 BackTestStats\n",
        "pass in df_account_value, this information is stored in env class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nzkr9yv-AdV_",
        "outputId": "5fbaeb47-b8f1-4e88-982a-916ea1574a9b",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============Get Backtest Results===========\n",
            "Annual return          0.037256\n",
            "Cumulative returns     0.085783\n",
            "Annual volatility      0.161972\n",
            "Sharpe ratio           0.307120\n",
            "Calmar ratio           0.173070\n",
            "Stability              0.108503\n",
            "Max drawdown          -0.215263\n",
            "Omega ratio            1.054040\n",
            "Sortino ratio          0.438091\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.944153\n",
            "Daily value at risk   -0.020209\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiHhM1YkoCel",
        "outputId": "039af493-0ae0-4539-e4c4-547574cff27e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============Get Baseline Stats===========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of DataFrame:  (566, 8)\n",
            "Annual return          0.024121\n",
            "Cumulative returns     0.054993\n",
            "Annual volatility      0.155363\n",
            "Sharpe ratio           0.231301\n",
            "Calmar ratio           0.109938\n",
            "Stability              0.332939\n",
            "Max drawdown          -0.219408\n",
            "Omega ratio            1.040148\n",
            "Sortino ratio          0.327705\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.024998\n",
            "Daily value at risk   -0.019431\n",
            "dtype: float64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#baseline stats\n",
        "print(\"==============Get Baseline Stats===========\")\n",
        "df_dji_ = get_baseline(\n",
        "        ticker=\"^DJI\",\n",
        "        start = df_account_value.loc[0,'date'],\n",
        "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(df_dji_, value_col_name = 'close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhJ9whD75WTs",
        "outputId": "b3ed8985-9e84-4e7f-b7bc-b78223ffd587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df_dji:             date           dji\n",
            "0    2022-01-03  1.000000e+06\n",
            "1    2022-01-04  1.005866e+06\n",
            "2    2022-01-05  9.951360e+05\n",
            "3    2022-01-06  9.904718e+05\n",
            "4    2022-01-07  9.903404e+05\n",
            "..          ...           ...\n",
            "562  2024-04-01  1.081503e+06\n",
            "563  2024-04-02  1.070662e+06\n",
            "564  2024-04-03  1.069484e+06\n",
            "565  2024-04-04  1.054993e+06\n",
            "566  2024-04-05           NaN\n",
            "\n",
            "[567 rows x 2 columns]\n",
            "df_dji:                       dji\n",
            "date                    \n",
            "2022-01-03  1.000000e+06\n",
            "2022-01-04  1.005866e+06\n",
            "2022-01-05  9.951360e+05\n",
            "2022-01-06  9.904718e+05\n",
            "2022-01-07  9.903404e+05\n",
            "...                  ...\n",
            "2024-04-01  1.081503e+06\n",
            "2024-04-02  1.070662e+06\n",
            "2024-04-03  1.069484e+06\n",
            "2024-04-04  1.054993e+06\n",
            "2024-04-05           NaN\n",
            "\n",
            "[567 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "df_dji = pd.DataFrame()\n",
        "df_dji['date'] = df_account_value['date']\n",
        "df_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\n",
        "print(\"df_dji: \", df_dji)\n",
        "df_dji.to_csv(\"df_dji.csv\")\n",
        "df_dji = df_dji.set_index(df_dji.columns[0])\n",
        "print(\"df_dji: \", df_dji)\n",
        "df_dji.to_csv(\"df_dji+.csv\")\n",
        "\n",
        "df_account_value.to_csv('df_account_value.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U6Suru3h1jc"
      },
      "source": [
        "<a id='6.2'></a>\n",
        "## 7.2 BackTestPlot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HggausPRoCem",
        "outputId": "d01dd767-59e9-4046-af84-9ff048c61c3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df_result_ensemble.columns:  Index(['ensemble'], dtype='object')\n",
            "df_trade_date:         datadate\n",
            "0    2021-10-04\n",
            "1    2021-10-05\n",
            "2    2021-10-06\n",
            "3    2021-10-07\n",
            "4    2021-10-08\n",
            "..          ...\n",
            "647  2024-05-01\n",
            "648  2024-05-02\n",
            "649  2024-05-03\n",
            "650  2024-05-06\n",
            "651  2024-05-07\n",
            "\n",
            "[652 rows x 1 columns]\n",
            "df_result_ensemble:                  ensemble\n",
            "date                    \n",
            "2022-01-03  1.000000e+06\n",
            "2022-01-04  1.000926e+06\n",
            "2022-01-05  1.000072e+06\n",
            "2022-01-06  9.979610e+05\n",
            "2022-01-07  9.990834e+05\n",
            "...                  ...\n",
            "2024-04-01  1.095309e+06\n",
            "2024-04-02  1.084390e+06\n",
            "2024-04-03  1.089781e+06\n",
            "2024-04-04  1.074142e+06\n",
            "2024-04-05  1.085783e+06\n",
            "\n",
            "[567 rows x 1 columns]\n",
            "==============Compare to DJIA===========\n",
            "result:                  ensemble           dji\n",
            "date                                  \n",
            "2022-01-03  1.000000e+06  1.000000e+06\n",
            "2022-01-04  1.000926e+06  1.005866e+06\n",
            "2022-01-05  1.000072e+06  9.951360e+05\n",
            "2022-01-06  9.979610e+05  9.904718e+05\n",
            "2022-01-07  9.990834e+05  9.903404e+05\n",
            "...                  ...           ...\n",
            "2024-04-01  1.095309e+06  1.081503e+06\n",
            "2024-04-02  1.084390e+06  1.070662e+06\n",
            "2024-04-03  1.089781e+06  1.069484e+06\n",
            "2024-04-04  1.074142e+06  1.054993e+06\n",
            "2024-04-05  1.085783e+06           NaN\n",
            "\n",
            "[567 rows x 2 columns]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABMcAAAHPCAYAAABX+L2dAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdZ3gc5fX38e/uqvdqFVuy3Hu3MQYMNhiMKaEaAiR0/iGJEwgBEiAJJCEheQIBkpAAoZjeCb0ZAzYuGNx7kyWrWL33srvPi3uLZEm2JEtW+32uS9fMzszO3CvL0u6Zc85tcTqdTkRERERERERERAYga08PQEREREREREREpKcoOCYiIiIiIiIiIgOWgmMiIiIiIiIiIjJgKTgmIiIiIiIiIiIDloJjIiIiIiIiIiIyYCk4JiIiIiIiIiIiA5aCYyIiIiIiIiIiMmApOCYiIiIiIiIiIgOWgmMiIiIiIiIiIjJgKTgmIiIiIiIiIiIDVr8Ljq1cuZLzzz+fxMRELBYL77zzTofP4XQ6efDBBxk9ejT+/v4MHjyYP/3pT10/WBERERERERER6VE+PT2ArlZVVcWUKVO4/vrrufjiizt1jltuuYXPPvuMBx98kEmTJlFcXExxcXEXj1RERERERERERHqaxel0Ont6EN3FYrHwv//9jwsvvNCzra6ujnvuuYdXXnmF0tJSJk6cyF//+lfmzZsHwK5du5g8eTLbt29nzJgxPTNwERERERERERE5LvpdWeXRLFmyhLVr1/Lqq6+ydetWFi9ezNlnn82+ffsAeP/99xk+fDgffPABw4YNIyUlhRtvvFGZYyIiIiIiIiIi/dCACo5lZGTw7LPP8sYbbzB37lxGjBjB7bffzimnnMKzzz4LwIEDBzh48CBvvPEGzz//PEuXLmXDhg1ceumlPTx6ERERERERERHpav2u59iRbNu2DbvdzujRo5ttr6urIzo6GgCHw0FdXR3PP/+857inn36aGTNmsGfPHpVaioiIiIiIiIj0IwMqOFZZWYnNZmPDhg3YbLZm+0JCQgBISEjAx8enWQBt3LhxgMk8U3BMRERERERERKT/GFDBsWnTpmG328nPz2fu3LmtHnPyySfT2NhIamoqI0aMAGDv3r0ADB069LiNVUREREREREREul+/m62ysrKS/fv3AyYY9ve//5358+cTFRVFcnIyP/jBD1i9ejUPPfQQ06ZNo6CggOXLlzN58mTOPfdcHA4Hs2bNIiQkhEceeQSHw8FPf/pTwsLC+Oyzz3r41YmIiIiIiIiISFfqd8Gxr776ivnz57fYfs0117B06VIaGhq4//77ef7558nOziYmJoYTTzyR3//+90yaNAmAQ4cO8bOf/YzPPvuM4OBgFi1axEMPPURUVNTxfjkiIiIiIiIiItKN+l1wTEREREREREREpL2sPT0AERERERERERGRnqLgmIiIiIiIiIiIDFj9ZrZKh8PBoUOHCA0NxWKx9PRwRERERERERESkhzidTioqKkhMTMRqPXJuWL8Jjh06dIikpKSeHoaIiIiIiIiIiPQSmZmZDBky5IjH9JvgWGhoKGBedFhYWA+PRkREREREREREekp5eTlJSUmeeNGR9JvgmLuUMiwsTMExERERERERERFpV+stNeQXEREREREREZEBS8ExEREREREREREZsBQcExERERERERGRAavf9BxrD7vdTkNDQ08PQ46RzWbDx8enXXXDIiIiIiIiIiJHMmCCY5WVlWRlZeF0Ont6KNIFgoKCSEhIwM/Pr6eHIiIiIiIiIiJ92IAIjtntdrKysggKCiI2NlYZR32Y0+mkvr6egoIC0tLSGDVqFFarqoNFREREREREpHMGRHCsoaEBp9NJbGwsgYGBPT0cOUaBgYH4+vpy8OBB6uvrCQgI6OkhiYiIiIiIiEgfNaBSbpQx1n8oW0xEREREREREuoIiDCIiIiIiIiIiMmApOCYiIiIiIiIiIgOWgmPS5ZYuXUpERMQRj7nvvvuYOnXqcRmPiIiIiIiIiEhbFBwTEREREREREZEBS8ExEREREREREREZsAZkcMzpdFJd39gjX06ns0NjdTgcPPDAAwwbNozAwECmTJnCm2++CcBXX32FxWJh+fLlzJw5k6CgIE466ST27Nnjef6WLVuYP38+oaGhhIWFMWPGDNavX+/Zv2rVKubOnUtgYCBJSUn8/Oc/p6qqyrM/JSWF+++/n6uvvpqQkBCGDh3Ke++9R0FBARdccAEhISFMnjy52Tnd3nnnHUaNGkVAQAALFy4kMzPziK/1qaeeYty4cQQEBDB27Fj+/e9/d+h7JSIiIiIiIiJejXYH9/xvG499ub+nh9Kr+fT0AHpCTYOd8b/7tEeuvfMPCwnya/+3/YEHHuDFF1/k8ccfZ9SoUaxcuZIf/OAHxMbGeo655557eOihh4iNjeXmm2/m+uuvZ/Xq1QBcddVVTJs2jf/85z/YbDY2b96Mr68vAKmpqZx99tncf//9PPPMMxQUFLBkyRKWLFnCs88+6zn/ww8/zJ///Gd++9vf8vDDD/PDH/6Qk046ieuvv56//e1v/OpXv+Lqq69mx44dWCwWAKqrq/nTn/7E888/j5+fHz/5yU/4/ve/7xnX4V566SV+97vf8a9//Ytp06axadMmbrrpJoKDg7nmmms6/H0WERERERERGehW7ivgpXUZWCxw3ckpHYpHDCQdzhxbuXIl559/PomJiVgsFt55550jHp+Tk8OVV17J6NGjsVqt3Hrrra0e98YbbzB27FgCAgKYNGkSH330UUeH1u/U1dXx5z//mWeeeYaFCxcyfPhwrr32Wn7wgx/wxBNPeI7705/+xGmnncb48eP59a9/zZo1a6itrQUgIyODBQsWMHbsWEaNGsXixYuZMmUKYAJvV111FbfeeiujRo3ipJNO4h//+AfPP/+85/kA55xzDj/60Y8YNWoUv/vd7ygvL2fWrFksXryY0aNH86tf/Ypdu3aRl5fneU5DQwP/+te/mDNnDjNmzOC5555jzZo1fPvtt62+1nvvvZeHHnqIiy++mGHDhnHxxRfzi1/8otnrFBEREREREZH2e3tjNgBOJ+zOrejh0fReHQ4ZVlVVMWXKFK6//nouvvjiox5fV1dHbGwsv/nNb3j44YdbPWbNmjVcccUVPPDAA5x33nm8/PLLXHjhhWzcuJGJEyd2dIhHFehrY+cfFnb5edt77fbav38/1dXVnHnmmc2219fXM23aNM/jyZMne9YTEhIAyM/PJzk5mdtuu40bb7yRF154gQULFrB48WJGjBgBmJLLrVu38tJLL3me73Q6cTgcpKWlMW7cuBbnj4uLA2DSpEkttuXn5xMfHw+Aj48Ps2bN8hwzduxYIiIi2LVrFyeccEKz11NVVUVqaio33HADN910k2d7Y2Mj4eHh7f5+iYiIiIiIiIhRXtvAZzu9SSw7D5UzPTmyB0fUe3U4OLZo0SIWLVrU7uNTUlJ49NFHAXjmmWdaPebRRx/l7LPP5o477gDgj3/8I8uWLeNf//oXjz/+eEeHeFQWi6VPpBJWVlYC8OGHHzJ48OBm+/z9/UlNTQXwlEkCnrJGh8MBwH333ceVV17Jhx9+yMcff8y9997Lq6++ykUXXURlZSU/+tGP+PnPf97i2snJyZ711s5/pGt29nX+97//Zfbs2c322WztDyaKiIiIiIiIiPHxthzqG72f03fllPfgaHq3XhEhWrt2LbfddluzbQsXLjxiyWZdXR11dXWex+Xl/e8fefz48fj7+5ORkcFpp53WYr87OHY0o0ePZvTo0fziF7/giiuu4Nlnn+Wiiy5i+vTp7Ny5k5EjR3b10GlsbGT9+vWeLLE9e/ZQWlrqyUZrKi4ujsTERA4cOMBVV13V5WMRERERERERGWjcJZUTEsPYcaicnQqOtalXBMdyc3M9pXlucXFx5ObmtvmcBx54gN///vfdPbQeFRoayu23384vfvELHA4Hp5xyCmVlZaxevZqwsDCGDh16xOfX1NRwxx13cOmllzJs2DCysrL47rvvuOSSSwD41a9+xYknnsiSJUu48cYbCQ4OZufOnZ6svWPh6+vLz372M/7xj3/g4+PDkiVLOPHEE1uUVLr9/ve/5+c//znh4eGcffbZ1NXVsX79ekpKSloETkVERERERESkbfWNDr5NLwbgjoVjuPbZ79idU4Hd4cRmtfTw6HqfXhEc64y77rqrWdCkvLycpKSkHhxR9/jjH/9IbGwsDzzwAAcOHCAiIoLp06dz9913H7WM0WazUVRUxNVXX01eXh4xMTFcfPHFnqDi5MmTWbFiBffccw9z587F6XQyYsQILr/88mMed1BQEL/61a+48soryc7OZu7cuTz99NNtHn/jjTcSFBTE3/72N+644w6Cg4OZNGlSmxM4iIiIiIiIiEjr8itqcTrBz2bllJExBPraqGmwk15UxYjYkJ4eXq/TK4Jj8fHxzWY6BMjLy/M0d2+Nv78//v7+3T20HmexWLjlllu45ZZbWt3vdDqbPZ46dWqzba+88soRzz9r1iw+++yzNvenp6cf9ZopKSnNtl177bVce+21AG1O2nDfffdx3333Ndt25ZVXcuWVVx5xvCIiIiIiIiJyZLlltQDEhfvjY7MyNiGUTRml7DxUruBYK6w9PQCAOXPmsHz58mbbli1bxpw5c3poRCIiIiIiIiIivVtWSTUOh7PF9txyExyLDwsAYHxCGID6jrWhw5ljlZWV7N+/3/M4LS2NzZs3ExUVRXJyMnfddRfZ2dk8//zznmM2b97seW5BQQGbN2/Gz8+P8ePHA3DLLbdw2mmn8dBDD3Huuefy6quvsn79ep588sljfHkiIiIiIiIiIv3PR9ty+MlLG7l1wShuXTC62T5P5pgrODbOFRzTjJWt63BwbP369cyfP9/z2N3365prrmHp0qXk5OSQkZHR7DnTpk3zrG/YsIGXX36ZoUOHekr2TjrpJF5++WV+85vfcPfddzNq1CjeeecdJk6c2JnXJCIiIiIiIiLSr23JLAVgw8GSFvvyDsscG5cQCsCe3IrjM7g+psPBsXnz5rXoOdXU0qVLW2w70vFuixcvZvHixR0djoiIiIiIiIjIgOMOgGUUV7fYl+PKHIsPN8Exd5+xnLJaquoaCfbvFS3oe41e0XNMRERERERERETaz91XLLukhka7o9k+T+aYKzgWEeRHTIgfAGmFVcdxlH2DgmMiIiIiIiIiIn1MXnkdAI0OpydTzO3whvwAw13ZY6kFlcdphH2HgmMiIiIiIiIiIn2I0+n0ZIdB89JKp9NJXpkJnLkzx8BbWpmar+DY4RQcExERERERERHpQyrqGqmut3seNw2OFVfVU+8qsxwU2jQ4FgxAakEVaYVV/PSljezNU4N+UHBMRERERERERKRPyS9vXkbZNDjmLqmMCfHDz8cb9hkxyFtW+fCyvXy4LYfn1qR3/2D7AAXH+qB58+Zx6623tlgHSElJ4ZFHHumRcYmIiIiIiIhI98t1lU360QA4ySjyBsfc5ZZxYQFQuA+ePRfev4WRrrLKA4VVfLk7H6BFr7KBSnN39nFvv/02vr6+nsffffcdwcHBPTgiEREREREREelOueW1nGLdxvO+f+H3jVezsfgyzz53wOscn/Xw5INQXwkHV5F42l34+Vipb3RQ3+hoduxAp8yxPi4qKorQ0FDP49jYWIKCgnpwRCIiIiIiIiLSnfLKa7nQthqrxcl5trXNyirzymqxYeeGwr+ZwJiLLf1rhsc0T6bJLasB4KNtOby5IYtDpTXH5wX0MgMzOOZ0Qn1Vz3w5nR0aalVVFVdffTUhISEkJCTw0EMPNduvskoRERERERGRgSWvvJYZlj0ATLSkU1lTS1l1A2CyyhIsxQQ4qsDmB7N/bJ6UtsIzY6VbSXUDtQ12/vv1AW5/YwubM0uP58voNQZmWWVDNfw5sWeuffch8Gt/2eMdd9zBihUrePfddxk0aBB33303GzduZOrUqd03RhERERERERHptaqLDzHMmgdAoKWekZZsMoqrmRQUTk5ZLUkW01OM8CQYeQas+w+krWTE+J8BEOrvQ4PDQW2Dg7zyWtIKqwBIiR6YbZoGZuZYH1FZWcnTTz/Ngw8+yBlnnMGkSZN47rnnaGxs7OmhiYiIiIiIiEgPiS7Z0uzxZOsBMoqrcTqdZBZXe4NjkSmQfCJYfaD0IKfHmx5jl84cQmJ4IAC7csopdWWdpcQMzDZNAzNzzDfIZHD11LXbKTU1lfr6embPnu3ZFhUVxZgxY7pjZCIiIiIiIiLSBwytNMExJxYsOJlkSWP7oTISIwJIL6rmMr9Cc2DkUPAPhcEzIHMdUxu38O3dlxEV7Mee3AoOFFaxNrUIgPiwAIL8BmaYaGC+aoulQ6WNIiIiIiIiIiK9gd3hZFzjLrBC3bAFBKQtY7I1lb99c5D9+aYB/+yICijHZI4BDDsNMtdB2koGTb8agPjwAADWHjDBsWExAzdOorLKXmzEiBH4+vqybt06z7aSkhL27t3bg6MSERERERERkZ5SVFLKBEsaAL4n/QSA8dYMamtrWbbT9CEb428CXkQMNcuUk80y81vPeRJcwbG9eSaglqLgmPRGISEh3HDDDdxxxx188cUXbN++nWuvvRarVf9sIiIiIiIiIgNRxYFv8bPYKSAS28j5EBCOH42MtmQCMD4hjODqbHOwO3Ns0ASzLM2AhhrAlFE2NVzBMemt/va3vzF37lzOP/98FixYwCmnnMKMGTN6elgiIiIiIiIi0gPqD20H4IDfKNM2KnEaAOdFmd7q188ehKXK3ZDflTkWHAMBEYATilIBiHc15HcbyJljA7PnWB8SEhLCCy+8wAsvvODZdscdd3jW6+rqCAkJ8TxOT08/nsMTERERERERkePIXrAHgLLg4WbD0JPhwFfcEL2VYYt+zsLYYrPdPxwCI826xQIxoyHrWyjcC/ETPWWVbsMG6EyVoMyxPquuro7169ezY8cOJkyY0NPDEREREREREZHjwL/UZH45o0aZDZMvByz4ZXzN2YPrsJRmmO3urDG3mNFmWbgP8DbkB7BaIClKwTHpYz7++GNOP/10vve973HppZf29HBERERERERE5DiIrD4IQEDiONeGoTD8NLO++SUoSfdubyrGFUwrNJP8RQX54WczYaHBkYH4+9i6c9i9msoq+6gLL7yQ8vLynh6GiIiIiIiIiBwvdZXEOAoAiBnapIps2g/hwFew6SUYd57Z5m7G7xY7xiwLTVmm1WohLtyfzOIahsWEMJApc0xEREREREREpA+ozNkNQKEzjOQhg707xp4HAeFQnmUCZAARbZVV7geHA4CEMNOUf1j0wC2phAEWHHM6nT09BOki+rcUERERERGRgaYw3cxUmWkdTGiAr3eHbwCceqdZr68wy8MzxyKGgtUXGmtMEA0YHmtmqByXENadw+71BkRZpc1m6mbr6+sJDAw8ytHSF1RXVwPg6+t7lCNFRERERERE+oeaQ7sAKA5MabnzpCUwbC6sfBAqciH5xOb7bT4QPQIKdpu+YxHJ3L5wDCcOj2bRpPjuH3wvNiCCYz4+PgQFBVFQUICvry9W64BKmOtXnE4n1dXV5OfnExER4Ql8ioiIiIiIiPR3lqL9ANRGjGj9gIQpcPkLbZ8gZrQrOLYPRi4gJsSfC6cNbvv4AWJABMcsFgsJCQmkpaVx8ODBnh6OdIGIiAji4wd2ZFtEREREREQGlpCKAwD4xI7u3AncfccOroYT/g+sSjiBARIcA/Dz82PUqFHU19f39FDkGPn6+ipjTERERERERI6/za9AWRaccivYjnObH4ed2HrTKyxsyPjOnSPlZPj6Qdj1Piw9Dy5/EYKju3CQfdOACY4BWK1WAgICenoYIiIiIiIiItLXrPgbfHm/Wc/ZDIuXth4ga6yDjG8gZS50YVsnR0kG/tRT5/QhMWVM504y4nT43j/hk7sgYw2s+Qec+fsuG2NfpeZbIiIiIiIiIiJHsu5Jb2DMYoPdH8BbN4LT2fw4p9Nsf/578Pm9XTqEogObADjAYIZEh3b+RNOvhjNcY3P1MBvoFBwTERERERERETmS7/5rlqf9Gq58HWx+sPMd2PJK8+O2vga73jPra/8Fhza1/xrlh+DNG+DBMZD5XcvdaesByPAfhc1q6cSLaCIi2SzLMo/tPP2EgmMiIiIiIiIiIm1x2KEk3axPvRJGLYD5d5vHn9wFlflmvSgVPrrTrIcmgNMB7/0M7A1Hv0bWevjXLNj+JlTmwhd/aHlMzhYAqqMmHNvrAQgfYpZlWcd+rn5AwTERERERERERkbaUHwJ7PVh9vUGlOT+D+MlQWwovXwarHoH/zoe6Mhg8E276EgIjIXcb7Pn46Nf45t9QXwnxk0zZZtpKTzDMLbJ8NwABydOO/TVFJJlldRHUVx/7+fo4BcdERERERERERNpSkmaWEclgtZl1m49pbO8TaEonP78Xal2BsctfgLAEGHueOTZ/55HP73DAgRVmfdH/g4kXm/U1//Ic4qzII8peiMNpIXHMrGN/TQHh4B9m1suzj/18fZyCYyIiIiIiIiIibSl2BceihjXfnjgVfrIWTr0DYsfBST+D6z6GsESzP2aUWRbuPfL583dAdSH4Bpvg2pwlZvv2tzxlj8Wppt/YARIYk5zQBS8KbxZcaUbXnK8PU3BMRERERERERKQt7syxyGEt90UNg9N/Az/9Bs66H3z8vPui3cGxfUc+/4GvzHLoSeb5iVNh6MngtJsAGVC03zToz/QfRYCvrfOvpSn1HfNQcExEREREREREpC1tZY4dTcxosyzab0on2+IuqRw+j0a7g5yyGm9p5U7XzJeHTP+xqq5oxu+m4JiHgmMiIiIiIiIiMnDsWwarHgans33HHylz7Egih4LVBxqqoeJQk+t/DpkmE4zGeji42qwPP40HP9vLnAe+YKX1RMAC2euhNJPw8l0A+Cd1QTN+NwXHPBQcExEREREREZGBobIAXvshfH4fZG/wbq8phWfONkGzppxOKE436x3NHLP5egNq7tLK7A3w0iXw7CLYvxz2fmKCZ0ExOGLH8+aGTABe2FELyXPMED6+g7jGHBxOCwljZndsDEcS7pqxsiyz687ZRyk4JiIiIiIiIiL9V2kGrHsSqothzT+gscZsd5dLAuz7DDLWwhd/goo87/aaEqgrM+uRKR2/tru00h0c+/rvZulogFevgjeuNY/HnsOmrHIKK+sBWLm3gPrRZrZLy56PAXjVuYCRQ4d0fAxtUeaYh4JjIiIiIiIiItI/7f0MHj8FPr4DnloA3z3l3dc0Yypvu1k6GmDDs97t7gBaaAL4Bnb8+jEjzbJoH+TthN0fABYYPMME6Zx2mLQYFj7A57u8Qbm6Rgdr/E7yPF7nGEvOnHu7rhk/eINj5dlH7ok2ACg4JiIiIiIiIiJ9W8FeKEptvm3vp/DyZVBbBhYbFKeaEka3ZsGxHd719c+YXmDQ+X5jbk0zx1a5ssbGnQ9XvwtzlsBFT8LF/wX/ED7faYJjyVFBALyXZmFn0hWstY/nHt87+NHp4zo3hraEJoDFCvZ6qMrv2nP3MQqOiYiIiIiIiEjfVZoJT5wKT58JjXXe7aseAZwmM+uWzZAwFay+MOEis79pOWHeTrO0+kBlHuz4n3nc2Zkq3aJHmWXGWtj2hlmf+0vwD4WFf4Ipl4PFQnphFfvyK/GxWrj3/PEAfLA1h3P3n88VDb/h2jNnEeLv07kxtMXmawJkMOBLKxUcExEREREREZG+65t/mxLF6iLI2Wq2FeyBjDUmM+rMP0BEMtz0Jdy2C6b90BxT6socqy72ziY556dm+fEdkPY17PvUPO5Av7EDBZU89uV+lq5OY01ZpNnYWGuWJ/4EEqe2eM4yV9bY7OFRzBsziOhgP+rtDpxOuHj6YL4/K6nd1+8QT9+xgd2Uv4vDjiIiIiIiIiIix0l1MWx4zvs4cx0kzfJuG302hCWadasVQmKbz9LodHpLKiOS4bRfwcG1kPUtPGca4mPzhzHnHHUolXWN/POLfTyzKo0Gu9OzfW94JH51JTB8Ppz5x1af++6WbADOnhCPzWrhDxdM5JMduVw9ZyizUqLa//3oqPAk8z0b4JljCo6JiIiIiIiISN/03VPQUOV9nLkOGm6ELS+bxzOua/kcd7ZUfaXpR5bvKqmMmwh+wfCDN+H5C+DQJghPhsufh/iJOBxO/vTRLjZmlJAYHsiMoZFccUIyPjYLH27N4YGPd5FXbso6TxoRTW55LQcKqliZdDMLAvbBuQ+CrWUYZl9eBduzy/GxWjh3sgnknTs5gXMnJ3TZt6lNkxbD4OmQMrf7r9WLdbiscuXKlZx//vkkJiZisVh45513jvqcr776iunTp+Pv78/IkSNZunRps/333XcfFoul2dfYsWM7OjQRERERERERGSicTtM8H2DWjWaZuc70C6spgbAhMPKMls/zC4KgaLNelumdqTJuglkGhMPV78ElT8OPVkDiNJxOJ/e+t4OnV6WxKaOUD7fl8IcPdjL3/33J7D8v59bXNpNXXsfQ6CCevmYmL990IlfMSgbgf9az4NKnITCy1Zfxv00ma2zemEFEBft1ybem3cacbUpJEyYf3+v2Mh0OjlVVVTFlyhQee+yxdh2flpbGueeey/z589m8eTO33norN954I59++mmz4yZMmEBOTo7na9WqVR0dmoiIiIiIiIj0ZwfXwFs3QlURVBVARQ5ggfn3mGb7lXnwxf3m2JnXgdXW+nk8vbayvGWV7uAYQEAYTLoUgkxJ4xMrD/DCNwexWODOs8fw60VjGRIZSGFlHcVV9cSE+HPHwjF8euupnDEuDoCRcSEA7M+rbPPlOBxO3t1s+p1dNG1w574ncsw6XFa5aNEiFi1a1O7jH3/8cYYNG8ZDDz0EwLhx41i1ahUPP/wwCxcu9A7Ex4f4+PiODkdEREREREREBgJ7I/zvR1CaYQJZidPN9qhhJoiVMAWy10N5FvgEwszr2z5XeBLkbIGSg5C/y2yLm9jm4a9/ZxrW33POOG6cOxyA608exhe78wnys3HSiGh8bM3zj0bGmuDYgcJKGu2OFvsBVqcWkl1aQ6i/D2eMG9Te74R0sW6frXLt2rUsWLCg2baFCxeydu3aZtv27dtHYmIiw4cP56qrriIjI+OI562rq6O8vLzZl4iIiIiIiIj0UzvfMYExgEObvUGt2HFmmTTbe+yU73uyvlrlbsq/50NoqDbBtKjhrR7aaHeQWVINwDmTvH3A/HysnD0xnlNHx7Ya+BocEUigr40Gu5ODxdWe7btyyjlQUEl1fSO/fceUdF40fTABvm1kuUm36/bgWG5uLnFxcc22xcXFUV5eTk1NDQCzZ89m6dKlfPLJJ/znP/8hLS2NuXPnUlFR0eZ5H3jgAcLDwz1fSUndNK2piIiIiIiIiPQspxNWPeJ9nLMZClzBsUGunuXJTYJjJ/7kyOeLcMUQ0laa5dhz2izBzCmrpcHuxM/HSnxYQLuHbLVaGDnIZI/tc5VWbs8u47x/rmLB31dw6X/Wkl5UTXxYAL88a0y7zytdr9uDY+2xaNEiFi9ezOTJk1m4cCEfffQRpaWlvP76620+56677qKsrMzzlZmZeRxHLCIiIiIiIiLHTepyyNsGvkHmcUk6ZKwz6+7MsRGnQ9KJMGcJxI4+8vncPcfc3A39W3GwyGR9JUcFYbVaOjTsUa7g2P78CpxOJ3/+aBd2hxOHE3bmmAq4/3fpZMIDfTt0XulaHe451lHx8fHk5eU125aXl0dYWBiBgYGtPiciIoLRo0ezf//+Ns/r7++Pv79/l45VRERERERERHqhLa+Z5fSrYc9Hprzy8Mwx/1C44dPWn3+4psGx2HGQPKfNQ9OLqgAYGhXU0VF7mvLvy6/kqz0FrEktws9m5U8XTeT19ZnMGzOIU0fHdvi80rW6PTg2Z84cPvroo2bbli1bxpw5bf/gVVZWkpqayg9/+MPuHp6IiIiIiIiI9GYOB6R+YdbHnQ/l2d7eYxYrRI/q+DnDk73rs24AS9sZYRmufmHJ0R0Pjo0aFArAtuwytmWXAXDtySksnpnE4plqD9VbdLissrKyks2bN7N582YA0tLS2Lx5s6eB/l133cXVV1/tOf7mm2/mwIED3HnnnezevZt///vfvP766/ziF7/wHHP77bezYsUK0tPTWbNmDRdddBE2m40rrrjiGF+eiIiIiIiIiPRpuVuhuhD8QmDICZAw1bsvagT4tr8PmEdwDAyaYIJkky8/4qHphSZzLCU6uMOXcZdVHiio4kBBFTEh/vx03siOj1e6VYczx9avX8/8+fM9j2+77TYArrnmGpYuXUpOTk6zmSaHDRvGhx9+yC9+8QseffRRhgwZwlNPPcXChQs9x2RlZXHFFVdQVFREbGwsp5xyCt988w2xsUotFBERERERERnQ9n9ulsNOBR+/5sExd0llR1ks8KMVYG8AvyDsDicPfbaHE4dHtyhzPJbMsaSoIPx8rNQ3Ogjx92HpdbMID1J/sd6mw8GxefPm4XQ629y/dOnSVp+zadOmNp/z6quvdnQYIiIiIiIiIjIQuEsqR5xulglTvPvczfg7w+ZrvoBV+wv591epPL/2IF/fOZ/IYD8AnE6npyF/ZzLHbFYLc0fGsCa1iCd/OIOJg8M7P17pNt3ec0xEREREREREpFNqyyHTNSvlyDPMMiQWwgab3mOdzRw7TFaJCYBV1jXy+MpU7lpkgm4FFXXUNNixWmBwROuTCh7Nk1fPpLq+kdAAZYz1Vh3uOSYiIiIiIiIiclxsfQ0cjRA13Hy5nf5bmHARjF7UJZfJKa31rD+3Jp38cvP4oKukcnBkIH4+nQuh2KwWBcZ6OQXHRERERERERKT32fgCfHSHWZ9y2IR9U6+AxUvBr+N9wFpzqKzGs17b4OCJlQcAbzP+oVEdL6mUvkPBMRERERERERHpXXK3wXtLACfMvAHm3t5lp96eXca7m7ObX67MZIqdOykBgI+35eB0Oo+pGb/0HQqOiYiIiIiIiEjP+eY/8NaNUFfh3bbnE7McuQDOfQisXRe++MlLG7nl1c3syin3bMtxBccunTkEfx8rh8pq2ZNXwa4cM6YUBcf6NQXHRERERERERKRnlGbCp/fAtjfgi/u929NWmOWYc8Bi6bLL5VfUerLBDhaZkkmn00mOq6xyeEwwJ42IBuCN9Vl8tScfgLmjYrtsDNL7KDgmIiIiIiIiIj1j3ePgtLvWn4Cs9dBQA5nfmm3DTu3Sy23NLPOsu0spS6sbqG1wABAXFsDpYwcB8MzqNBodTqYlRzAuIaxLxyG9i4JjIiIiIiIiInL81ZbBhufM+qAJgBPe+zkcXA32OghNgOiRx3yZoso6Xlp3kNoGO1uzSj3bc1wzUrqb8UcH+xHga2PeGBMcczrNcVeekHzMY5DezaenByAiIiIiIiIiA9CG56C+AmLHwjXvwWMnQP4OEyADkzV2jCWV9Y0Orlv6HVuzyjhUWsP2bG+fsTxX5pg7gywhIgCApKggRg0KYV9+JaEBPpw3OfGYxiC9nzLHREREREREROT42/WeWc6+GYJjYOED5nG5aybJlLnHfImHPtvD1ixTSvnWhuxmmWO5nswxV3AsPNCzb9HEeAAum5lEoJ/tmMchvZsyx0RERERERETk+HI6oWCPWU+abZaTL4Otr0HqcvP4GPuNrTtQxBMrDwDg72P1BMPccj2ZY6asMiE8wLPvp6ePZOLgcE4bo0b8A4Eyx0RERERERETk+KrMg7pysFgharjZZrHAeX+H4FgTMIscekyXeGNDFgCXTB/CZTOTPNujgv0AkznmdDrJKW2ZOebvY+OsCfH4+yhrbCBQcExEREREREREvJxOcNi9j6sKob6qY+dorAeHo+39hXvNMmIo+HoztohMgVu2wnUfd+x6h3E6nazYWwDARdMGc8mMIZ59Z7hmo6xtcFBe0+hpyN80c0wGFpVVioiIiIiIiIhRkQevXQW522HUAqirhANfwuCZcNPylsc31pkeYe7sry2vwYZnIWs9xI6Bm74AH/+Wz3OXVMaOabnPL+iYX8aunAoKKuoI9LUxMyUSfx8rIweFsD+/ktnDo/l8Vx4l1Q3klNd4G/IrODZgKXNMRERERERERCB/Nzx1BmR9B401sOt9ExgDyF4P5Tktn/PZb+Af08yxVUXw7k8hYy04GiBvO2xY2vq1CveZZcyobnkp7qyxOSOiCfC1YbFY+Mf3p3H7WaO5YGoi8a4SypyyWnJcwbHEiMA2zyf9m4JjIiIiIiIiIgOdvQFe+wGUZULUCLjqTTj1Tph3F0SPNMdkr2/+HIcdtr1p1tf+G3a8bYJig8bD/HvM9hX/z2SfHc5dVhnTSuZYF1jpCo6dNtrbUH98YhhLTh+Fr81KfJjJZtuVU05doyn/HBTWSoabDAgqqxQREREREREZ6NY/C0X7ICgablgGwdEw6kyzryIXivabjLJx53ufk70RaorNesYaKDcN8Jn2Azjh/2Dzy1CSBt/8B067o/n1PMGx0V3+UirrGll/0IyraXCsKXfm2HubDwEwNDpIzfcHMGWOiYiIiIiIiPR3B1ZA5ret76spha8eMOvz7jKBsaaGzDTLrMMyx/Yva/64NAMsNph4Kdh8vdlj3/3XNPl3q6swfcqgW8oqv0ktosHuZGh0ECkxwa0eEx9m+ovtzq0A4MxxcV0+Duk7FBwTERERERER6c/KsuHFi+HFS8He2HL/mn+aDLCYMTDjupb7h8wyy+yNzZ+/7zOzbJpNNvIMCHUFmsZ/D3yDoDIP8nd6jynab5bBsRAU1fnX1YZ1aUUAnDQius1jDm++v3BifJePQ/oOBcdERERERERE+rP0VeBohLoyb8aWm70BNj5n1uffDbZWui9FjwL/cNOkP3+H2VaZD4c2mfWz/wqhiWZ9yve9z/Pxh6EnmfXUL73bC7qvpBLg2zRTUjl7WNvBsbgmwbGYED+mJ0d2y1ikb1BwTERERERERKQ/S//au16S3nzf3k+gqgCCB8HYc1t/vtUKQ2aY9azvoLYMVj1iHidMgfDB8P2X4JwHYfxFzZ87fL5ZHvjKu60b+o1tyypjd245lXWNbD9UDsAJw9rOSnOXVQKcOT4Om9XSZWORvkcN+UVERERERET6s4Orvesl6cBp3scbnzfLqVeaPmFtGTILUr+A5X+AT+4Ge53ZPsEVDBs83Xwdbvg87xga60w2WcZasy1uQideTEul1fUsfmINAPdfOAm7w0lSVCCJEYFtPie+SebYWRNUUjnQKTgmIiIiIiIi0l+VH4LiA97HpQehPAde+wEERkLqcrN9+tVHPs+wU2HFX03WGEDsOJh1A8y84cjPi5tgstKq8s2EAHETvMGxUWd17jUdZnNmKbUNDgB+/54p+zwhpe2SSoCwAB/OGDuI0pqGI/Ymk4FBwTERERERERGR/ip9dfPHJemw/S3IbjLzZMpciB5x5POknAJXvWl6lMWOgajhYGlHKaLFYrLHtr0OB76EsixwOiBuIkQO7eiradXWrDLPekWdmTBg9hFKKs2wLDx97awuub70fQqOiYiIiIiIiPRXB1eZZcRQkzVWchCsrlBAylwIioa5t7XvXKPO7NwYRp5hgmMbn4dB48y2Med07lytcAfHLBZwOs22I/UbEzmcGvKLiIiIiIiI9Cf2Bvjwl/DXFNj4gtk29SqzLEmHnC1m/aSfwWXPmab63WnCRRA71jT+T1tpto3tyuBYKQD/N3c4AIMjAhkaHdRl55f+T5ljIiIiIiIiIv1FfRW8fg3sX+bdFhwL066Cr/4M1YVQU2y2d3dQzM3HHy74Nzy9wJRUhg2GhKldcurcslryK+qwWS3cumA0k4aEkxIdjKU9JZ8iLsocExEREREREekvPrrTBMZ8AmHxUvjZRrhlK4QPMQ34wQSoggdB6HGcpXHIDDj5FrM+8ZL29StrRVphFf/6Yh+1DXYAtriyxkYNCiHQz8Z5kxOZODi8K0YsA4gyx0RERERERET6g+pi2PaGWb/iFRgxv/n+iKFQU2LWj1fWWFNn3Atjz4P4SZ0+xR/e38GXewoI8LVx49zhnpLKKUMiumaMMiApc0xERERERESkP9j6GtjrTPBp+LyW+yNTvOsJk4/XqLwsFhgy05RZdoLD4WTDQRPc+y7dlIa6m/FPGqJsMek8BcdERERERERE+jqnEzY8Z9anX9N62WLkUO96T2SOHaMDhZWU1zYCsOFgCQ12B5szSwFljsmxUXBMREREREREpK/L+g4KdpleY5MWt35M08yx+B7IHDtGGzNKPeuFlfW8sT6LitpGooP9GJ8Y1nMDkz5PwTERERERERGRvm7nu2Y5/gIIjGj9GHdwzD+8eaCsj9iUUdLs8cOf7wVgwbg4bFbNTimdp4b8IiIiIiIiIn1dSbpZDp7R9jHJJ8GohTDs1E7PFtmTNrkyx4bHBHOgsIqCijoAFk6M68FRSX+gzDERERERERGRvq40wywjkts+xjcArnodTlpyfMbUhSrrGtmTVwHADXOHebaH+Ptw0oiYnhqW9BMKjomIiIiIiIj0dWWZZhmR1LPj6CZbMktxOmFIZCBnT4j3bJ83JpYAX1sPjkz6AwXHRERERERERPqyugqocfXjCu+fwTF3v7FpyZFEh/gzalAIAIsmJvTksKSfUM8xERERERERkb6s1JU1FhAOAf1z1sbt2eUATBkSDsDfL5vKpswSFk2MP9LTRNpFwTERERERERGRvsxdUhl+hH5jfdzOHBMcG59ogn+ThoQzyRUoEzlWKqsUERERERER6cs8zfj7Z0lleW0DGcXVAIxP6J+ZcdKzFBzr7fYtg7duMjXkIiIiIiIiIofzZI71z+DY7hzzeXhwRCARQX49PBrpjxQc6+0+/hVsex22vdnTIxEREREREZHeyN1zLKJ/llXuPFQGwDhljUk3UXCsNytKheJUs164r2fHIiIiIiIiIr2TO3Osn5ZV7jjUvN+YSFdTcKw327fMu164p+fGISIiIiIiIr1Xad8uq/z7Z3u44slvqKht8GxzOp28/l0mu3PLvc34lTkm3aTDwbGVK1dy/vnnk5iYiMVi4Z133jnqc7766iumT5+Ov78/I0eOZOnSpS2Oeeyxx0hJSSEgIIDZs2fz7bffdnRo/c++z7zrBXt7bhwiIiIiIiLSOzXWQWWuWe+DZZV2h5Mnvz7A2gNFvLflkGf7F7vzufOtrSx+fC1780zPsQnKHJNu0uHgWFVVFVOmTOGxxx5r1/FpaWmce+65zJ8/n82bN3Prrbdy44038umnn3qOee2117jtttu499572bhxI1OmTGHhwoXk5+d3dHj9R30VpK/yPi7LgPrqnhuPiIiIiIiI9D5lWWbpEwhB0T07lk7IKK6mtsEBwLubvcGxz3eZeEBFbSMNdieh/j4MiQzskTFK/9fh4NiiRYu4//77ueiii9p1/OOPP86wYcN46KGHGDduHEuWLOHSSy/l4Ycf9hzz97//nZtuuonrrruO8ePH8/jjjxMUFMQzzzzT0eH1G1V7vgB7HVnOWIqdIQB8vmo1Tqezh0cmIiIiIiIivUZphllGJIHF0i2X+N+mLNakFra6b2NGCXe9vY3iqvpOnXu3q2QS4Nu0YrJLa3A6nXy1xwTH/H1M2GJcYhiWbnp9It3ec2zt2rUsWLCg2baFCxeydu1aAOrr69mwYUOzY6xWKwsWLPAc05q6ujrKy8ubffUnqz56GYDl9qkcYDAA733+FS98cxCAfXkV5JbV9tj4REREREREpBcoSTfLbuo3tiunnF+8toWbnltPbYO9xf77P9jJK99m8PCyzrUC2p1b0ezx+1sOsSevgpyyWgJ8rbx442ymJUdw7UkpnTq/SHt0e3AsNzeXuLi4Ztvi4uIoLy+npqaGwsJC7HZ7q8fk5ua2ed4HHniA8PBwz1dSUt9sPNiW5NHT2GMdyeT5lzF12mwARliz+cP7O7np+fWc+fBKLvnPGhrtjh4eqYiIiIiIiPSYPR+b5eAZ3XL6bw4UAVBVb/esu5VU1bMpsxSA19dnUlRZ1+Hz7841iS6j40zF1P82ZrPcVVJ50ogYZqVE8b+fnMw5kxI6+xJEjqrPzlZ51113UVZW5vnKzMzs6SF1qbEX3sGIe75j2hmX4TNoDACnRpbQ6HCybGceANmlNaxLK+7JYYqIiIiIiEhPqSqE/Z+b9cmXdcslvkv3fub8YnfzvuAr9xXg7vxT1+jg+bUHqW2wU1PfMsOsLXtcmWO3nDEaPx8re/IqPFlo88bEHuPoRdqn24Nj8fHx5OXlNduWl5dHWFgYgYGBxMTEYLPZWj0mPj6+zfP6+/sTFhbW7Ks/sVgs+Nhc/zyxJjg2JSCPU0fHMnlIOCeNMI0WP96e01NDFBERERERkZ60/W1w2iFxOsSM6vLTO51Ovk0r8Txeviuf9enFzP1/X/D82nRW7CkAvFlf/1mRyqT7PmXy7z/lRy+sZ91hmWaHq6pr5GCxmXjuxOFRPHr5VPx8rDQ6TMRt3uhBXf6aRFrT7cGxOXPmsHz58mbbli1bxpw5cwDw8/NjxowZzY5xOBwsX77cc8yA5/olZy1O5flrZ/DeklO4ae5wAD7dkYfDoSb9IiIiIiIiA87WV81y8uXdcvr0omoKK+vws1nx97GSXVrDjc+vJ7O4hj9+sNNT1XTf+RMYFhNMfaODBruTBruTT3fkce2z37Xap8xtb14FTifEhPgTHeLPokkJvHLTicSHBXDq6FiSo4O65XWJHM6no0+orKxk//79nsdpaWls3ryZqKgokpOTueuuu8jOzub5558H4Oabb+Zf//oXd955J9dffz1ffPEFr7/+Oh9++KHnHLfddhvXXHMNM2fO5IQTTuCRRx6hqqqK6667rgteYj8Qnmym5W2sgeI0iBnJSSOjCfX3oaCijo0ZJcxMierpUYqIiIiIiMjxUrgfsjeAxQYTL+mWS3znauMzJSmcEH8fvtxTQGl1A4ArCNZIqL8Ps4ZF8fz1J7Axo4SpSRHUNNj5wVPrKKysZ3NmKScOj271/O6SynEJoZ5tM4ZGsvrXp2PVxJRyHHU4c2z9+vVMmzaNadOmASawNW3aNH73u98BkJOTQ0ZGhuf4YcOG8eGHH7Js2TKmTJnCQw89xFNPPcXChQs9x1x++eU8+OCD/O53v2Pq1Kls3ryZTz75pEWT/gHLaoVE8/1mr2m26O9j44xxJsX0ubUHySiqZunqNH70wnqeXpVGmesXloiIiIiIiPRDm14wy5ELIKR7enN96+o3NislitPHmc/nVgs8+cMZRAb5AnDyyBh8bVaSooK4YOpghkYHMzY+jNmugNh3R+iT7Z6pckxcaLPtNqsFi0XRMTl+Opw5Nm/ePJzOtsv4li5d2upzNm3adMTzLlmyhCVLlnR0OAPH5MWQsQa2vAon/QyAcyYl8M7mQ7y/xXy5fbojj4eX7eX1H81hfGL/6sUmIiIiIiIy4DXWw+aXzPr0q7v89FV1jXy+K4+Ve01PsVkpUcwaFsXa1ELmjR7EWRPiCfC18bdP93DTqcNaPccJKVF8uDXHE2BrjXumyrEJ+twqPavPzlY54Ey4CGx+kLcdcrcBsGBcHPecM45Jg8MBOCmmmv+O28L4aAuVdY08uzqtJ0csIiIiIiIi3WHPR1BVACHxMHrh0Y/vgNoGO5f8Zw23vLqZ/Io6/H2szEiJJMTfh39fNYPLZiUBcOroWN7/2SnMGNp6i59ZrtY/Gw+W0Gh3tNjvdDo9mWNj40Nb7Bc5nhQc6ysCI2H02WZ9i2m6aLVauOnU4by/5GT2LdrLS3U/58y0v/JM4nsAfLYzj4ZWfgmJiIiIiIhIL1WZD0eo1gJgw1KznHYV2Hy79PL//nI/u3MriAzy5UenDufNm08iLKDj1xgTH0pogA9V9XZ25VS02J9fUUdpdQNWC4wcFNIVQxfpNAXH+pIpV5jld0/Dk/Ng1SPm8eaX8f3yPiwNZgrcuMyPiQ+yUFbTwNrUI0+dKyIiIiIiIr3E1tfhwVHw3PlQfKD1Y4pS4cCXZn3aD7v08nvzKvjPilQAHrh4EnedM45JQ8I7dS6b1cLMoZEArZZW7soxJZXDY0MI8LV1csQiXUPBsb5k5AKISDazVh7aBJ/fB2VZsOUVs3/OEghNwFJbyk+SDwLw8fbcnhuviIiIiIiItN/eT8wy/Wv4z8mQ+mXLY1Y9bJajFkJU6/2+Ouv+D3fRYHdy5vg4Fk6IP+bzzRpmSivXHWiZtOGeqXKMSiqlF1BwrC/x8YMfr4EbPochswCn+cWYvsrsP+H/PFP4LnKsBOCzHbmt1neLiIiIiIhIL5O9wSyjhkNDNbx5HZQc9O4vy/K02WHuL7v00umFVazcW4DFAr89d3yXzBZ50ogYwLT8eezL/c0m93P3Gxun4Jj0AgqO9TX+oZA0C2bdaB5/9xTghMEzIXIoTLoUgJhDX5AY2EhRVT3rD5b03HhFRERERETk6KoKoSTdrF//KSROg5oSeP1qaKgx29f8CxwNMPQUSJ7dpZd/9btMAE4dFUtydFCXnHNqUgQ3nzYCgL99usdTsgne4NiYeM1UKT1PwbG+atz3wK9JhH3ixWaZMBWiR2FprOVHcbsB+KaVFFYRERERERHpRbI3mmX0KAgZBJc9D4FRkLMZ3v4/2LcM1j9tjjm1Y1ljjXYHN7+wgbve3tbq/vpGB29uMMGxK2cnd/YVtOrXi8Zy59ljAHhh7UGcTicNdgf78zVTpfQeCo71VX5BMOkS7+PxF5qlxQITLgJgnvNbAL5Na9n8UERERERERHoRd0nlkJlmGZFsAmQ2P9j1Hrx0KdjrTaLE8PkdOvWmzFI+2ZHLK99mUFbT0GL/sp15FFbWMyjUn9PHDjrWV9LC9ScPw8/HSk5ZLakFlRwoqKLB7iTE34chkYFdfj2RjlJwrC+bdSPY/GHMORA+2Lt97DkAJBWtwZ96NmaUUN+ovmMiIiIiIiK9ljs4NniGd9uwuXDR497HY86BS542SREd8PW+Qs96RlF1i/1vuLLGLpuZhK+t68MEAb42Zrua86/YW8juXDNT5Zj40C7pbSZyrBQc68viJ8EvdsClzzbfnjAVwgZjbaxmYdAeahscbMsu65EhioiIiIiIyFE4nU2CY9Ob75t4CVz+Epz+W1j8nJmo7QieW5POvL996ZkNEmDVvgLPenpRVbPjCyrqPMGzS2YMOYYXcWSnjooFYOXeAra7Pp+qpFJ6CwXH+rqQWPANaL7NYoExiwBYHLwVUGmliIiIiIhIr1WSDjXFpoQybmLL/ePOg1NvP2pgbHduOX/8YCfpRdU89NkeAMprG9iS5U2WOOgKjjkcZubI97ccwu5wMjUpgmExwV3zeloxd7SZufKbA0W88I2ZgXP28Ohuu55IRyg41l+NMaWVM+rWYcHBt2lqyi8iIiIiItIrHdpklnETwce/U6ewO5z86q1tNLqCXst25ZFaUMk3qUXYXdsADhZVsye3gsm//4yfvbKJNzdkAXDRtMGtnrerjIkLJS7Mn7pGB7UNDk4eGc15kxK69Zoi7aXgWH+VMhf8wwiqL2SSJY316SXNfiGKiIiIiIhIL1GSbpYxozt9ijfWZ7Ils5RQfx9OSInC6YSnvj7Aqv2mZDImxATdDhZV8/H2HCrrGnl/yyF25pRjs1o4b3L3BqosFgtzXaWVIf4+/PWSyVit6jcmvYOCY/2Vjx8kTgVgvG8uFXWNpBZU9uyYREREREREpKUy0xCfiKROn+LbdNNK57qTU7jz7DEAvPpdJi+tywDg+7PMudOLqtiUUdrsuaeOiiE6pHMZax1xzZwUxsaH8uDiyQyJDOr264m0l4Jj/Vm4+eU3IcQ0YjxQUHWko0VERERERKQnlJnSRvdnuM44VFoDwPDYEGamRHHSiGicTlNuGR8WwJWzkwHIr6hjw8ESAB79/lSunjOUe84dd2zjb6dJQ8L55NZTOXuiyimld/Hp6QFINwozNePDfEuBlrOSiIiIiIiISC9Q6socC+/8bJGHSmsBSIwIBOCZa2eRXlRFsJ8Pg8L88fexERHkS2l1A5V1jQT4WjlnUgIXTO3eXmMifYGCY/1ZuPkll2g1zfjTC49jcMzphHeXgM0Xzn/k+F1XRERERESkL3E6m5RVJnfqFA6Hk5wykzk2ONIExwJ8bYyND2t23NDoYEqrSwGYPCQCX5uKyURAZZX9m+uuQ7S9AIADxzM4VnwANr8IG56F6uLjd10REREREZG+pLYU6l39ocM6l8VVUFlHg92J1QJxoW33DkuJ9vb5mpYc0alrifRHCo71Z2EmOBZSmwsc58yx7I3e9dKM43ddERERERGRvsRdUhkUA36da1Kf7eo3Fh8WgM8RssGGRgd71qcnR3bqWiL9kYJj/ZmrrNJWX04wNeRX1FFV13h8rn1ok3fdnSIsIiIiIiIizXXBTJXZJc1LKtuizDGR1ik41p/5h0JAOABjg8qBLmrKX1sOH90B2RvaPqZpcKxUwTERERER6QPsjfDZb2HVIz09EhlIPDNVHkszfhMcczfjb8u4BNODbOSgEAaFBnT6eiL9jRry93dhQ6C2jKmhFWyojiOtsIoJieHHds5vn4Bvn4SSdLjqjZb7HXbI2eJ9rMwxEREREentnE746JewYal5POMaCFTZmRwH7jY04Z1rxg8dC449e90skqM6V74p0l8pc6y/c5VWjnFnjnVF37H9y82yJL31/YV7oaHJddRzTERERER6u9WPeANjAHk7e2okMtC4M8eOpazSFRwbfJTgGMD8MYMYERvS6WuJ9EcKjvV3rtTcFJ9SANIKq4/tfLVlkPmtWS/LMnfYDucuqbTYXMcpc0xEREREeon6Ktj2JtRVerflbIXlfzTrgVFmmbfj+I9NBib356VjKKvMLq0F2hccE5GWFBzr71xTASdYCoEu6DmWthKcdrPeUA3VxS2PcQXHyhPmmMfqOSYiIiIivYHDAa/9EN66Ab5+yLXNDh/cat7jjr8QZl5vtudt76lRykDj/rwU3vnMsfaWVYpI6xQc6+9cv2AjG/MBSDvWskp3SaVbWSslk67g2EOZo83jmmJzh05EREREpCd9/SCkut7P7ltmluufMRNN+YfB2X+BuAlme2uZY9vfgv83Ag6sOD7jlf6voRaqzGe1zgbHKusaKatpACAxQk32RTpDwbH+ztVzLKg2Dx+rheKqeg52NnvM6fS+mbC65nI4PCvMYYdcc5dtZeMEyp2uOxfuOnoRERERkeOtcB98+Ev48s/ebXnboDIfVj1sHp/+WwhLgLiJ5nH+LpNp1tS2N6G6EFb+7fiMW/q33O3wletn0jcIgqI6dRp31lhYgA+hAb5dNTqRAUXBsf7OVVZpLc9m1lAz287yXfmdO1dRqmmub/ODEaebbYcHvUoPQmMN9RY/DjrjyHbGuLartFJEREREekD+Lnh8Lnz3FOCEGdfBIFd22Fd/gfJs8A83s1MCRA0Hm7+ZYKo0vfm5CveZZfrX5r2xSEfk7YCNz4O9ATLWwZOnwepHzb5B48Fi6dRps1VSKXLMFBzr78ISAQs01nLuSHMXYfnuvM6d6+AqsxwyC2LHmPXDm+3n7wYg1ZGIA6s3ONZa+aWIiIiISHfb9CI01kD8ZLj6PTjvYRh+mtm3/hmzHP898PE36zYfGDTWrDctrbQ3QEma9/HG57t/7NJ/1JbDc+fDez+Dly+HN68HRyMknQhn/xW+/1KnT70vrwJQM36RY6HgWH/n4+8KkMEZg8wvzXUHiimvbej4udyzVCafCOHJZr30sKBXwS4AdjtMxpoyx0RERESkxzgcsON/Zv20O01QzGKBYa7gGK6Z1yctbv48d2ll0+BYSboJZrhtftkEzETaY+1jUF1k1lOXQ3kWRI2AH7wJJ94MofGdOm2j3cEL3xwE4NTRsV01WpEBR8GxgcDVVDShZj8jYoNpdDhZubcAgI0ZJcy8fxnvbs4++nky15ll0myIcDWLbCNzbJ9jCEOjg5pkjg2Q4FhVEXx0p2nqKiIiIiI9K+s7UzbpFwojz/RuH3oSWGxmPTQBUk5p/jxPU/4mM1a6SyoHjYfgQaaJ+r7Pmj8vbwe88xP482D4+Ndd+1qk76osgLX/MutzfwmBkeAbDIuXgn/oMZ36o+25ZBbXEBXsx2UzOz/bpchAp+DYQOC587WdBePiAG/fsTfWZ1JYWc/L645S9lhVCEX7zfqQWRA+xKwfnhHmyhzb6xzCTXOHk+00dy8cJQOkrHLjUvj2CXjuAshSgExERESkR+142yzHngO+TWbxCwiDwTPM+sRLwGpr/jx3cCytSW+xIndwbJw302znu97n5O+CJ+fD5pegvhK2vmYmtBJZ/Yj5mUicZiZ+uHUb3LIZEiYf02mdTiePf2V+Pq+Zk0Kgn+0ozxCRtig4NhDEu4Jjuds5wxUc+2pPPnaHk/XpJQBszSqjwe5o6wzeksqYMWYWFfc0wzXFUO+a/dJhx+m6o7bPOYQLpiZS7GuuZx8owbGcLWZZXwEvXtztjVorahv4eFtO58pkRURERPqrbW/COz+FLa+axxMubnnMgvtg4qVw8i0t9yWfBPGToLYUnr8AyrK9mWPRo0yPMoA9H0NjnQmCfXQH2OtgyAlgsZr3yZWdnAhL+g97owmUApz2a1PW6x8KIYOO+dRrDxSxM6ecQF8bV88ZesznExnIFBwbCOImmWX+TqYPCSU0wIeS6gZW7S9kX34lADUNdnbnVLR9DndJZfJsAGp9QnH6h5lt7hkrS9KxNNZS4/TDNzqF0ABf/GLML2mfqryB0ZMh15V6HxRj3kxteqFbLtNod/DP5fs4+S9f8OOXNrLk5U3dch0RERGRPqcsC966ETa/aN6PBUV7Z1pvKuVkuPTp1oMUPn7wg/9B9EjTHuTdn3qrKGJGmQBYSDzUlcOBFaavWfrX4BMAlzxlZrwEyN/ZbS9T+oiDq6CqwJRSjjyjS0/95gbzOeyi6YOJDPbr0nOLDDQKjg0E0SPAJxAaqvEpO8jJI0wfsEc+39vssI0ZJW2fw505ljSbj7blMOm+Tymwud5IuEsr801J5X5nIpOSogAYFDeEOqcvFhym30N/Vl8FxQfM+rSrzLKbJiJYnVrEQ8v24qgt5y6fl8jet5k1+wu75VoiIiIifcrmVwCnaS1y9l/gmg9MsKujQmLhytdNFtiBL+GQ62Zk9EiwWmHc+ebxmn/Ax78y66f8AiKHmtJL8Lw/lgHGYYd9y8wMle4JIcadDzbfdp+ivtHBlsxSnG2U5lbVNfLJ9lwALpk+5JiHLDLQKTg2EFht3j/Qeds8s5hsyig1uy1mV2vBsU0ZJazYmYXz0EYADgZP4vY3ttBgd7Kj0tU8ssxVMunqN7bPOYSJg8MBGBkXRrYz2uzv7zNW5u0EnOYuYsIUs62bAoLZJTUA3Bu7gh/5fMjtPq/z1092t/nHU0RERGRAcDpNzy+AOUvgxB9D3PjOny96BIxeZNYba13bRprl+AvMMv1r05x/0ARvieYg1zWVOTYwbXwOXroUnj4Ldr5ntrVW2tuG6vpGfvD0Oi54bDUvf9t6e5qPt+dSXW9nWEww05MjumDQIgObgmMDRZO+Y6eOjmm2a9GkBKBlcKzR7uDqp7/lLy+8h6WxllpbKD/8XxHV9XYAMh2u83z5ALx/C2w3DU/3OYYwyR0cGxQycGaszN1qlvETIcx196ase4JjBRV1AEx3mDLO8dZMtmSVsWxnXrdcT0RERKRPOLgGStLM7JTuvmDHatYN3vXQRPAPMetDTzKzVoIp27z+Y/ANNI+VOTawubPFCnaZ3nNB0ZAyt11PrW2wc+Nz6/k2rRiAZ1ent3oD/C1XSeUl0wdjsVi6ZtwiA5iCYwOFu+9Y3naGRAYxIjbYs+uGU4ZhsUBmcY0n6AKQU1ZLRV0jwy05AOxoiCejpIa4MH/+eOFEPrCfSBnB5k7ZhqWeO2M7nClMSDT9yJoGx/r9jJWuqb5LQsfwSZb5r+WsOGTSqrtYQWUt/tQztHoHAEmWPPyp57v04i6/loiIiEifselFs5xwIfgFH/HQdhs+39tDLGakd7vVBt9/Cc59CK58AwLCvfsGuWa7LNgNjiNMeiX9T00JpK8260GuCppx3wObT7ue/vzadNakFhHsZyPQ18b+/EpPoMxt5d4C1h4oAuDCaYO7bOgiA5mCYwNFk8wxgNNGm7tcEUG+TB0SwahB5g5Y0+yxzJJqAKYEmll2HFEjueeccby35BSuPCGZ/KgZzKr9N2+P/hucfCvp42/m7oYbyIk+kWB/88t/cEQgOZgyzprC9G5/mT3K9b29d52Fn76Xg91pweJoPOosRVV1jdz33o4j93w7TGFFPVMtqfg46wGw4mSkJZuymgEw6YGIiIhIa4pSYdsbZn3aD7vuvFYrnPRzsz70lOb7kk6AWTe2DHxEDQebH9RX9v/qCWlu/3Jw2iF2LNy4HE69E+bf3e6nr0k1Qa9fnDmaC6clAvDSOm+Swfr0Yv7vhfWA6TU2JDKoCwcvMnApODZQxLnuXpVnQXUx35uaiI/VwqKJ8VitFmYMjQRg3QHvXYnMYhMcm+hfAMCsGSdw06nDiQsLwGa1cOuC0dTjy21bB/OE39W8HXE9L9vPYNKQSM85fGxWakPML/WGooOe7eu27uaxv9zJ715ewer+0Eje4YA8k8W105mMw2IjD9f34Sh9x179LpOla9J54KP2p90XVNZxorV5D4vRliwFx0RERGTgWvY7cDTAyDM9M6x3mZnXwU+/g7m3te94mw/EjDHrKq3s33Z/aCaBcFeL7PnILMcsgqhhcPo9rc+I2gqHw+npC33CsCiuPGEoAJ9sz2Xp6jTue28HV/z3G2obHMwbE8sDF0/q6lcjMmApODZQBIRD5DCznrOZqUkRfHP3Gfz+eyajbO4ok921cl+B5ykZruDYUKepZydmVLNTXjhtML88czQAD3y8m398Yaa3djfjd7NFJANgLc/ybKtZ/hd+WvsE1+++iXuefoeVewvo00rSoKGKBosfac4ExsaHkeOeiKAs64hP/c6VJr3zUDkOR/sa6hdU1HGi1fVGy9+UsI62KjgmIiIiA9SBFbD7A7DYYOGfuucasaM7NNugt+/Yju4ZzwCQV15LcVV9Tw+jbcVp8OpV8M7N8MJFkPa1maUSYMy5HT7dgcIqymoaCPC1Mi4hjElDwpmaFEG93cF97+9k6Zp0GuxOFowbxH+umoGfjz7Oi3QV/W8aSBKnmuWhzQDEhPh7fqGePDIGm9XC/vxKslzllBnFNYCT2HpXKnh08+AYwM/OGMXtZ432nMfXZuG0MbHNjgmMNUG5oJocT8+FyCoTSEux5vG2370cTE/tqlfZM7a8AkCW3zDs2JgxNMIbHGuaOXZwDez91PPQ6XR6+oRV1dtJL6o66qWcTidlFRVMt+4zG6ZeCbgzxxq74MWIiIiI9DFr/mGWs26A2DE9OxY3d3AsZ2vPjqOPKqioY8HfV3D+P1dR29D1PXy7xOaXAdfN7bQV8Nx5UFcOwbEweEaHT+duszJ5cAS+NvP56t9XTee2M0dz6uhY5o+J5eUbZ/PUNbMI9LN11asQEaB9XQGlf0iYamZOydncYld4oC/TkiJYf7CElXsLuXJ2MhnF1QyiFD97tbkLFzWs1dMuOX0UP5k3kpLqenx9rIQFNL+jFp04FPtWCz40QFU+juA44huywALV1mCiHJWEZS4HTuz613w85GyFVQ8D8HbAxVAG05MjObTeBMdqizIIACjcB899z/QguGULRCSTVlhFUZO7YTsOlTM8NuSIl6uqtzO6cR/+/g04g+OwjDsf1j1ugmPVvfjOmoiIiEh3cQegpny/Z8fRVIqrP9n+z6GhxjuTZWc5nSYrqarA3Bw9lhkKa0rhyXkwZBZc8t9jG1c3+XDrISpqG6mobeT19ZlcPSelp4fUnMPuCo4B8+6CjLVQmmn+nU/8ielV10EbD5rg2PSh3jY1iRGB/PyMlkkKItK1OpU59thjj5GSkkJAQACzZ8/m22+/bfPYhoYG/vCHPzBixAgCAgKYMmUKn3zySbNj7rvvPiwWS7OvsWPHdmZociSHZY4d7rTRJuNrxV7TQD6ruJoR1kNmZ+RQ8PFv89RWq4XoEP8WgTGAlNgIcokyD0ozOZRfSJzF/OLPjz0ZAEtFTgdfTC9hb4R3fwqORhh3Pu81nABAUlQQFX6mt0BtYYZ5M/PRHaYPhtMBGesAWswuueNQ+VEvWVBRx3Cr+X5ZEibDoPHmmtYCGmoquuyliYiIiPQJVUVm9nQwTdB7iyGzIDzZNOVvUjnQKWXZ8OIl8PJiePcnsO+zYzvfwdWmLcj2N6Gu8tjO1U3e23LIs/7EigM02HvZrJ9pK0w/54BwOPkWuPpd+PlG+PFqmHZVp07pzhybnhzRhQMVkfbocHDstdde47bbbuPee+9l48aNTJkyhYULF5Kf3/qMfL/5zW944okn+Oc//8nOnTu5+eabueiii9i0aVOz4yZMmEBOTo7na9WqVZ17RdK2hClmWXoQqotb7HaXQ67eX0RpdT1FVfUMt7iCVq2UVLbXsNhgsp0xADSWHCT3oGkkX2oJw+l6A+NT3Ud7ju35CHK3QkAEnPMQhZUmcysmxB9HmJlW2VGWBTvfhQNfep+XZQLK36WbP4CxoSbwuONQ2VEvWVBRxxCL6/sVORSConAEmX+7xIaDve+Ng4iIiEh3KnD1YY0YCn7BPTuWpiwWmHixWd/+1rGd66PbIXW59/Hml6G2HP57Brx5Q8fPl7vNLJ2OVqtKelpmcTUbM0qxWCAiyJfs0hrebxIs6xU2vWSWkxYfe1YgUFbTwL58E6hsmjkmIsdHh4Njf//737npppu47rrrGD9+PI8//jhBQUE888wzrR7/wgsvcPfdd3POOecwfPhwfvzjH3POOefw0EMPNTvOx8eH+Ph4z1dMTEznXpG0LTASIlPMes6WFrsnJoYTFexHZV0j/9tk+mSN9801O2M6HxyLCw0gD/PvWZ57gIos8wam0D+JoGgTQAqubz242qt89lv4awqUeqdSZr3r537m9dT4x1BVb/ohRIf44RuZBIB/VTZ8fq85Ln6yWWZ9Z57uyhz7wWwzE82OQ+U4nUduyt8sOOaa7MASZ7LHRluzKFdTfhERERlI3LNBurLpe5WJl5jlvs9MMKszHA5IdyUOLPp/ZrnnI/jij5C93mR/Fe7v2DndwTGArPWdG1c3+mCruUE/e1gUN80dDsDTq9J6ckgtuYOVky/vktNtySzF6YSh0UHEhLRdsSMi3aNDwbH6+no2bNjAggULvCewWlmwYAFr165t9Tl1dXUEBAQ02xYYGNgiM2zfvn0kJiYyfPhwrrrqKjIyMpBukDDVLFu5Q2S1WjhjrCkFfHyFaZA/1jfP7Iwe2elLWq0WqgITAajOT8NeYBrJ14SkEBZrAkiRjhIqantZUKe+2gS/astMT4GNz0FNCaS6MsCKUl3ZYBaYcQ2FlXUA+PlYCfX3IXSQCXgF1xdBSTqN/pE4L3b1dMjdRl5RCelF1VgscOXsZGxWC8VV9eSW1x5xWAUVtS2DYzFm1tAUS65mrBQREZGBxRMc60UllW7xk0wFRmOtCWh1RtF+0+TdJxBm3gBxE8FeD98+6T1m9/sdO2duk0kCXDdtexN3ltj3pgzmihPM++Qdh8rJKKru4ZG51JaZzwXQZUHZvXmmPcrExPAuOZ+IdEyHgmOFhYXY7Xbi4uKabY+LiyM3N7fV5yxcuJC///3v7Nu3D4fDwbJly3j77bfJyfH2mJo9ezZLly7lk08+4T//+Q9paWnMnTuXioq2+yfV1dVRXl7e7Evawd13rJXMMYDLZ5lgVV65CfQMxZW+7Aq+dJYjfAgAzpIM/MrMXR9LzEgCo0zmWJylhEOlRw4KHXerH4EPfgHL7oW8HeaPIJj+DAAblprlyAUQmeIJjsWG+GOxWIiJH0K90zuLzL+rTuOGD8uxB8eBo5FX3nkPgMlDIogN9Wd8jC+LbV+x50DzwPD27DI+3ZHrySgrqKxjiKXQ7HQFxwgyzf/DqFZwTERERAaW3pw5ZrHA+AvMeuoXnTtHtiuzK3Eq2HyaTzpgc2UY7f6w/eerKW1eCZG9oXPj6iYFFXXszCnHYoGzJ8YTFezH7GGmf/GnO1r/zHncub9/QdHgf+TJtNorrdDMWp8SE9Ql5xORjulUQ/6OePTRRxk1ahRjx47Fz8+PJUuWcN1112FtMnvHokWLWLx4MZMnT2bhwoV89NFHlJaW8vrrr7d53gceeIDw8HDPV1JSUne/lP7BkznWenBsxtBIRg4yv+B9aCS6wfUH6BgyxwAcgyYCMKhkAwm1JnMsKGEMhCYAEEMZh4p7WTPQtK/NcvcHkP61d3vxAdOIf7Orz8DM6wEocvUbiw7xA2BoTCi5TvOHvM7pwwuNZ/HFngKWV5qMspoDa7FZLdx3vnkj9yvbS/zN90lC1z/abBg/emEDP3phg6fUtaSskjhcd6oizLkIMHeYwi1VlCo4JiIiIgOF0wn5pp9tr2rG31Sya0b2zgah3M8bPMMsJ10GVh+zfuG/zTLrOyhv5wRXedvNMiTOzEhfkWMa/vcSGw6atiNj4kKJCjbvqxdOiAfgk94SHCs5aJbuG9Vd4KArKy4luhf1zRMZQDoUHIuJicFms5GXl9dse15eHvHx8a0+JzY2lnfeeYeqqioOHjzI7t27CQkJYfjw4W1eJyIigtGjR7N/f9u183fddRdlZWWer8zMzI68lIHL/aah5CDYWwZRLBYL33dlj8VRggUn2PwgOPaYLhuQMpuDjkH4O2oY5TR3WmKHjofgGBxYsVmcFOX3nj/KNNbDoY1mvaoAvnncu6/4ABSnQnUR+AbBqLMAPJlj7h4BKdFB5GAyut6zn8QJk8Yxc2gk3zWaQON06z5+fvoopiVHQlURJ5Z9DEBA0U7vparqyS6tAeDe93aQU1aDoywLq8VJoy3QkzFGYARgMsfUc0xEREQGjMo8qC0Fi/WYKx26jTuoVbTfW4rXEYcHx0Lj4PKX4OKnYNKlZlZMgD1tZI9tfhlevhxWPWLex7r7jQ2ZBa6+tZ7stF7APWHVjCZN6c+aYCqXNmaUkH+UFiTHhTtzzH2jugt4M8cUHBPpCR0Kjvn5+TFjxgyWL/fOlOJwOFi+fDlz5sw54nMDAgIYPHgwjY2NvPXWW1xwwQVtHltZWUlqaioJCQltHuPv709YWFizL2mH0HjTr8Bpb55O3cTF04fgZ7MSb3HNaBmaANZjSzKcP3YQn9pOaz6UxNFgtVHpa7KrKgt7UYAzd5vpDeFW1uR7VZzuveM2aLxJb6dpcMzc4YoI8uM16zmssY/nUfsl3LFwDG/cPIcFZ50HwBy/VH56Woo5z/qn8XGY60XXZnhKKPfne7PpKmob+fVb27CVm+9TXXCiSdUHT+ZYmKVKZZUiIiIycLizxqKGg2/AkY/tKUFRZnzQ8eyxhlrIdb3vdAfHAMacDZMXm/Wx5r0luz5o+fys9fDuEtj7iZkg6rHZ3lkW4yfB4Jlmfd2T8Ok9HW/s3w3cE1bNSonybEsID2RKUgROJ3y2M6+tpx4/pV2bOVbbYOdQmbkhrswxkZ7R4YjHbbfdxn//+1+ee+45du3axY9//GOqqqq47rrrALj66qu56667PMevW7eOt99+mwMHDvD1119z9tln43A4uPPOOz3H3H777axYsYL09HTWrFnDRRddhM1m44orruiClyjNWCzeGStLWp/xJSrYj9+eN44LhrlmTXT1CzsW0SH+TD7n/zyPC60xnqm2awPMJAD1Jb1oeubMdWbp16SHgE8gYIH6CjiwwmyLm+DZXegpq/TOLrM/5gyubPgNo8dMICUmGIvFwuyTF0BgJGH2EnxSPzNvetY94XlOPEWk5ZiG+/vyTd+90XEh+PlYWbG3AHux+WPsCGvyx9gdHKOasmoFx0TkONq/HPZ+2tOjEJGBKn+3WQ4a17PjOBp3ECqrg8Gx3G3gaDBVHG0FYsadb5bpXzfPTKurgLduMDfFU+aaTDF7PeS5MsfiJ0HSCWb94CpY+y9481ozEVUPqa5vZMch00t6Zkpks30LXdljX+3pBbPcu5MMIrsmcyyrpBqnE0L8fTw32kXk+OpwcOzyyy/nwQcf5He/+x1Tp05l8+bNfPLJJ54m/RkZGc2a7dfW1vKb3/yG8ePHc9FFFzF48GBWrVpFRESE55isrCyuuOIKxowZw2WXXUZ0dDTffPMNsbHHVsonbXDfuSpuezrkH85J4eoJvuZBWGKXXPbEWSeQHWJ6j1WFeP+QOILNz46jvX0Sjgd3cOyE/wOr6/uQdAKEmQkEPLMNxU30POXwskqAs8bHEehr46fzm/Rs8/GH6deY9XWPw5p/QHUhhCdRYQkFYP8u0xNuX14lP7R9xv/z/S9LTjb/DoNdM1Xaopr8MW7Sc0yZYyJy3DTWwatXwSvfbzMbWUSk2zTUwNbXzHpvbMbf1BBXcKyj5Yvu4wfP8FYMHC56hGmd4miEvZ+ZbU4nvH8LlKRDeBJc/iJc+yEMPcX7vPhJMOEi8353+tXm/WTuNjNDew/ZnFlKo8NJQngAgyMCm+2bkWyCZbty2p607bjx9BzrmuBYWqHpNzY0OghLW//OItKtfDrzpCVLlrBkyZJW93311VfNHp922mns3Lmz1WPdXn311c4MQzoraphZHiE4BkC5K5Ori4JjAIln3QJv30Ti1LM823zCEyAXfKt7QYo0mDcT7uDYyAVm8oLU5ZByCjgdUJ5l+pCBt08DLcsqAZacPoofzxuJzXrYH7lZN8Kaf0LaSkhfZbad/lvKlv2T0MptFB7cDpxJal4ZT/q8TGBhPRMmTuXV8GkMqTbX9o9N8Z4vIALQbJUicpxVFUCjKQNh94dw4o97djwiMnC4gz85myEwEqb9oKdHdGSezLH1ZuztDYAcXG2W7uBaW8aeBwW7zURSUy6HVX+H7W+Zxv0X/9fTn5bvvwSv/cAEwsKTzDjO+ZvZFzcRPr4Tlv/RBM0CI9u8XHdZ7+o3NjMlqkWQaHScuYmcXVpDRW0DoQG+x318gPn3K+3a4Fi6+o2J9Lhun61SeiFPcOzAkY8rzzJLd7ZUF7BMvgxu2Yrvabd7tgVEmbLNoPoCGuyOLrtWp5Vlmll7rD6QOM28YTjlNvOhz/29c2tyl9I9W2XTzDGgZWAMICIJxrn6QzgdMPFSmHwZlphRADTkmRk9a/L2E2gx5/Vd8wj3nhHHEHfmWGTLzDF/SwOVVVWde90iIh3lvlEAsOv9nhuHiAw8m14wWWMWGyx+rktnDewW8RPNJFc1xSbbdul55qaCq89sqxrrIfUrsz7ijCOf3/2+cv/npqfY8j+ax+f8DYY26Q0dGAHXfmCCZIcH6GbeALHjzBjf+/mRx9ZNvnP1G5s5tGVgLjLYj0Gh5n32viZ9eY+7mhKod10/IqlLTplWZN6/D1O/MZEeo+DYQBTpCvC00XPMw5M51nXBMXP9oZ4m9gBB0eb8sZSS1xtmn8n6zizjJ4FfkElVX3Av+Id6S1LBfF+CvI1CWyurPKITfwpYzJu58/4OFgvhQ0ywLbw6naySagZV7/MeX1/BWQVLmRhUZh43vVPlF4LT9d+5sboTsyCJiHRGVaF3/eAaqOwFfWBEpP+rq/QGf874HQw/7cjH9wY+/ua9JZjm+Olfw6tXwus/BHuj+X366FR45yfe52SsMb1ugwdBwtQjnz9hqskEa6iGd38COE2lwszr2z9Gmw9875+mpciu92Dlgx17jcdox6EyVu03f1dOHhnd6jFj4k322N7cHiytLEk3y5A48A084qHtddAVHBsaHdQl5xORjlNwbCBq2nPMcYRMrW4oq2yNNczMShpnKWFjRmm3XqtdCvaapfsNTFORTTLHmjTjb7A7KHE1wo9ubxPN5Nnwo5Vw05eezK+QxDEApFhyeHNDFmOtrh4+sWMBsHz3XwJrXeWnTe+QWq00+pk3C9SUUlHb4JkOWkSk2zQNjuE0H6Rev8aU8ohI/+N0mmymrlBbDumrYfMrUFXUseeu/RdU5Zv3ZSf+5OjH9xazbjLv32ZeDyffYjLJdr0P+5fBtjfNjettb5hgGXj7h4068+gzx1ssMPZc7+OZN8Ci/9fxMSbNMjdtAb68v+MTCHSS0+nkgY9243TC+VMSGTkotNXj3KWVe/J6MDjm7rEZMRSHw8kvXtvMba9t9sw2fyT/25TFnW9uobS6+f+jdFfPsWEqqxTpMZ3qOSZ9XHiSKRm015nywfBWMsPsDVCRa9a7OnPscKHxAMRZSrn/m4N8b0r3BuOOqsiVrRU9quW+ppljTUoqS6rMHzirBSKDOjDDTMLk5o9dZZXDLTlcuTKVRy2ZZvvM682H0K8fNGWYPoEQHNPsqQ7/cKgvg9oy/u/5Daw9UMTyX57GiNgQRES6haes0gI44VvXzLsFu2HiJT01KhHpLs+db26u3vQFhMZ1/jxFqfD4KSbLCUzJ4A/fbv9zV//DrC+4F3z60Mx+U68wX272Bvjm37D1dSjPdm2rN0GymFGwzzUT8KizWp6rNbNuhANfwaRLYe7t7e9rdrjpV8Puj2Dvx5C2AobM6Nx5OmDF3gJW7S/Ez2blzoVj2jzOkznWo8Exd7+xZFbsLeB/m8y/3Y/njWBUXOtBPYDiqnruensbtQ0O9uRV8tKNswnx96G2wc6hMtO/Uz3HRHqOMscGIpuPN+to7yemKaf7zpRbRS7gNGnVwd08a2iICY5FU8b6tAL29eQfO4Ci/WYZPbLlvqY9x5rMVFngKqmMCvZvvcdYe0UOw4mFMEsNwfXFjLO6/vjGTYDT7zFvRofPh5N+1vINjyv7zFFTyjdp5g7s/sP6MdQ22Nt1V0tEpAWHHfJ2Nu9B4w6OjT7bZEC4lRzskV41ItKNastNKWB5Fnzxx2M7195PTWAsINz0DEtdDtntyFDa9T48OQ8aqmDILBh/4bGNo6dNWmyWuz/0TgYF5gZDUap5T2r1gRHz23e+mFHw03Vw6h2dD4y5uScAKNh9bOdppxe/MdlYP5wzlKSotksLx7gzx3K7v+eY0+nk27TilpNduWeqjBzKM6u9bWq+dfVLa8tza9KpbTBVO1syS7n8ibU89fUBfv/+DpxOCPH3ITq4DwV7RfoZBccGKnd54Md3mjcar14J+5d793tKKhOOnsZ9rIJjwGLDZnESTTkvfnOwe693JE6neTMCrQfH/EO9gcXEaZ7N7l5pMe0tqWyLbwAW1/knW1MZYnGVLLlLOBOnwdXvmEDZYayuWYiCHVWez6TujDaAgoo6Zt3/OT9/dfOxjVFEBqbPfgv/mQM7/ufdVu0qhUo6wZSI/3gtYDEzWKr/mEj/0nQip00vmtm8OyvrW7M86WfeANHXfz/yc/YtMzd068ohaTZc9sKxB4B6WuI0837TXtd8e/5u01gfIHmO5wbocTVonGssu47L5bJLTebU3FExRzxuVJypiCisrKOosu6Ixx6rv3yym8ueWMvv39/h3dhQC9nrAci3DeLrfd72At+ltR0cq65v5Lm16QD8ZN4IQv192HGonPs/3MUr35pKkbmjYlrM0Ckix4+CYwOVuzzQ4epp4Ggwbzjcb3Tcqd3dXVIJYLWZhpZAoqWItzZmU9tg7/7rtqYyz8w+Y7FCZErrx3z/ZbjiNYjxBs8+2JIDwKTBXfDmxVVaeU+8mRjAHjq4XVNp+wRFABBm8fYaK27Sz2BXTjkVdY18m9Z2X4+6xh76votI71ZbBhuWmnX3pCXgzRwLjjEzscWN9/apLO3BGx1dxWGH134Ir1xh1kUGsuLUJg+c8MndnT9Xpis4ljQb5t4GWGD3ByY7tTUVefC/m836lCvh2g/NDdy+zmKBSZd5H7vfexbsgrSVZr29WWNdzdXvlsK9x+X3X0GFudE8KDTgiMcF+fmQ7Mos25vXPdljTqeTV7/N4IkVJiC8K8dV1VJdDM9fYD4vWX15Mdfc0I4PM2P+Lr3tSbFe/TaT0uoGhkYH8cuzxvDxrXO5+5yxnDF2EBdMTWTpdbP415XTu+X1iEj7KDg2UDUtDzz3IRhxuklv//w+s80THDtO/b9cmVGnBe6nsq6RnTnlx+e6h3OXVEYMbbuHRfwkGHO29ymVdXyw1QTHfnDi0Naf0xGuvhLDi82bIlv8xCMd7WFxZY6F0SQ4VukNjpW6UsJLqw9LDXf504c7mfr7ZaQW9ODU2CLSO2193ZQxgbcRMXgb8jctv3fPpFvSD4Jjm182M7bt+ah51kxPa6w3fZ9Ejqci1/+BYaeZm4gHV3krDTqiLMu8z7RYIXE6xI6BceeZfVteaXm802lmX6wuhEET4LyHwebb+dfR20xeDFhMeencX5pt+bsgfZVZTzm1Z8YVmQI+AdBY652dsZs02B0Uut6zDgo7+qzv7qb8Xd13zOFwcvsbW5j2x2X8+u1tnu05rn5gfPUXyPwG/MOp+f6bPLXTfJS+/8KJ2KwWsktrPBlwTTmdTl5cZ/4m3jR3ODarhSGRQfzfqSN4+tpZPPr9acwbM+jYWrOIyDFTcGygSjrRLIedBjOuN280LDZI/cL0fPCUVR6HzDGA4fMAON3PpG7vPNRDwbFCVzP+mFaa8bfhtfWZ1NsdTB4SzpSkiGMfw6wbYegp3sftDI65U+7DLNWeTU0zx9yz4tQ1OlrNzPvmQDE1DXa2ZJZ2fMwi0n85nbD+Ge/jphlh7uBYUJMymEhXcKw0vduH1q3qq+DLP3kfF+zpubEc7ss/wT+mwvZ2NjAX6Sx7gzcw4r6BOOxUSJhi1tO+7vg53VljcRPB3zVp0IgzzDK/lcyxknRTYmj1gUufAd8jZxb1OVHDTVXCla+b7y2Y70NtKfiFQOLUnhmX1QYxo816N/cdK3SVR/pYLUS1Y2KrcQkmOPb1voKjHNkxW7JKeXNDFqXVDdisFi6dMQQwN5ar6xu9ffHOfYiPK0dSXW9naHQQZ4wbxMTEMKD10sqNGaUcKKgi0NfGhdOO02crEekwBccGqiEz4Oeb4Ko3TU+xyBSY7ErrXvnQ8S2rBE/K+Pj6rfjRwI6eCo4dqRl/K+wOJy+5G4h2RdYYmDcjFz0O/q4SzfjJRz7eLSACaJ451rTnWNOMsdayx8przbYWTUdFZGDL+Kb5B9ZmmWNNyird+kvm2NrHzIzOboW9KDh24CuzXPtYjw5DBoAPb4NHp5jglLusMnoEpMw16+krO35Od2l20gnebe4ZwFvrb5Wz2SzjJ8GgsR2/Xl8w9hwYtQDCk8G3STP65BN7NkvuOPUdyy83wbGYEH+s7ciecgeYlu/OJ62w6ihHt98qV/+w08cOYsfvF/Lg4imE+PsAcKikxpSYAsRP5K2NWQBcPG0IFouFWSlRQOtN+d/cYI5dNCnecz4R6X0UHBvIooY3Lx08xdXzYc+HpukpHL+yykHjIXgQvo46Zlj3svNQ2fG57uGKmrzxa4f16cVkl9YQHujL+VO68HsVkQRX/w/m/wbGnte+57gyx8ItVQyPNdNAF7cRECutqedw5TUKjolXcVU9d/ztn/zlxQ96eijSkxx2+Ow3Zn3iJWZZWwY1pSazqtFVPtK0rNLdM6cv9xxz2GHd42bdfYOiYO/xHcPWNyD1y5bbHQ7vB7Ts9ZC7/fiOSwaO8hxTWgyw/X/NJyxyZzh1KnPMNStj0mzvttgxrmtmm98vTbn74bqz1fozq9WbrQXeIGRPcfcd6+7gWIUJjsW1o6QSYERsCKePHYTTCc+u7roS86/3u4JjY2II2PcB5GwlIdxkKhblHjSTQVisHLImsCbV9PC9eLoJ1M0aZoJjn27P5ZPtuVTWNVJe20BNvZ0PtpiKHHcmmoj0TgqOiVfsaJjyfbPe4CrNc98x6m4Wi6e08mTrdnbnVtBodxyfazfVwcyxL/eYrInTxw4iwNfWtWMZPANOuwNs7bzD5Oo5FuNTyw2nmJ5yzTLHalrPIgPTC6G81kzOoOCYAHz2xXL+Wvlbrt73M1LzSnt6ONJT1j1hAjD+YXDW/d7yybJMb9aYTwD4BXufE9mJzLH6KrA3ds2Yu8KhTWYmTv9wOOVWs63wOAbHCvbA2zeamaTrD8uKKMvw/o0GE8Rb8Tf49B48UxWLdIX1z3gnbtrzEdS4MmKihpuMJovNBMGbZpMeTUMN5Gw160NmebcHRnirFQ4vYT602SwTpnbwBfRRTd9793RwzD2Wbi6rzHc14489SjP+pm50vdd9Y32Wp3XIsaisa2RTRgk+NHLhwT/B61fDE6fyS+dSAqml5pArQBg5jDe3FOB0wuxhUSS5Jgc4eWQMyVFBFFXVc/OLG5h476dMvu8zpv7hMyrqGhkSGciJw6KPeZwi0n0UHJPmLngMfrQSLn8Jrvu4Q723jpmrtPI023bqGh0c6MI06XaxN0KJ6+5TO4NjX+3JB2DemNijHHkcuDLHZifYmDPc/PEtbhIcKztCWWVNgx27w3yoUnBM7A4nxZs/wGpxkmgpZv1y9TUakEoz4Ys/mvWz/mgyiSPMzFyUHIQq18y3wbHmBoebu6yyLKt9Aa/83fDQOHj5sqMfe7y4s6dHzDMNwMH0pOyK4FN9Nax7Ej66E977GWRvbHmMuxF3QzUcWNF8nztwYHNlWGx6Ab68H9b+C3K3IcdJxjp47nzY1U+zaxvrYMOz3sfuwFhoggmG+4fCYNfMeh3JHju02cyQHjyo5azgnhK+JmXcTufAyhwDb7aWX2jPv+amM1Z24w2MPFdZZXua8bvNGRHNuIQwahrsvL815+hPOIp1B4qId+TyctDfCdn9hpkwAidnV7zNvT7P43T97t1tT+Dvy8zNkkuaZIKF+Pvw4c9PYcn8kQT5eW+Y1zWam/1Xzk5uV8moiPQcBcekOavN/CEedx4MPen4XtuVOTbBcoAQqtlxeGllZT4su7dzMyO1R+lBc4fUNwhCj14ieai0ht25FVgtcOqo3hMco7aMaEcxMy27qaxrpK7RNN8vbRL0KjusrLK8ppFTrNv4k8/T1Fb1UL836TW+2J3PxPotnsdh+95i2c48LnhsNV/szuvBkclxtfcTE5wZPBOmX2O2uYNjpRnezLGgw+6EhyaAzQ+cdm//yrY4nfDhL6GuDFKXQ+Z3XfsaOmvfZ2Y56iyTJWOxQX1F1/z92fAsfHwHfPsEbHwenjoDPrmr+QfPjG+863s/bv58dwbHmEUQOaz5Pnf2s3S/b/4NaSvhtavg41+ZUtz+ZMc75v94aCIkN3k/GNWk7YSn71gHgmNZrmb8SSc0D6qDNxDTNEupLMsE5qw+3r5k/d3weSYwM+GC9lcPdJeIoeZ9sb2+W7NnC1yZY4NC2x8cs1gsnDF2EOCdyCunrIbt2Z1rzdK46p8s97udExybwScQrngVLnkagHNs3xJYYl7/l0WRAFw1O5lLpjcvkwwN8OX2hWPYcu9Z7P7j2ez6w9l8ftupvHHzHH50avtatohIz1FwTHqPsEQIHoQVJ0MteezIbh6kcaz7L6x+BOdHd3bP9YtdWWORw0zPh6P4ylVSOS05ksjgo8+s0+3cwbGaUsLevZY3/f/AGEuGJ0ustLrtssry2gZ+7vM2V/ksZ1jZuuM2ZOmdXl6zl1lWb1nLPMe33Pr812zJLOX5tX24j5R0jHv23qEneT/EthYcCz7s5oDVCuFJruOO8vOy7U04uMr7+Jt/H9uYu0JlgSmrBBi5wPTmjHIFobqiKb+7RGzEGTDhYnA6zOt29ziDw4Jjn5o+Y275rsDBoPFw5Wtw3iMw7ntmm7thujTndMLn98HqR7vufJlN/lauexx2vts15+4ttr5mljOuNY3i3Zr2ZHX3HdvzkXfm2qPJbBIcO5ynKX+TzDF3M/5B4/rfLJVtSZwKt+2Gc//e0yMxv8+T55j1lX8zS3tj899JXcDdkH9QB8oqAUbFmdlO9+VVAHDVU+s475+rePXbDpT6Ao7KIs7M/hd+FjsFcafATV/A6IUw4SLqfCMIs1QzsewLAPY7BvOniybyp4smYWsjE8zXZiXA10agn42Rg0KZlRLV5rEi0nsoOCa9iyvFPtmS32LGytQ0c0fcsedjqG45E8wxK3P9IXV/+DuKL10llfN7Q0kleGarpKYEyyEz1XSKJc9TWtm0XLL0sNLJitoGojHfb1tdabcPVXqvzOJqqlLXEWipxx4YQ1FAMoGWev7j+whv+N1HQObXONXXaGBwZwm4G2VD8+BYtevD8OHBMWhf3zF7g7fZ/6TFZrnzXZMp0pNSlwNO04g/NN5si3F9D9wBw46qyPP2Ditw9a2ZdSMsfhbO/qt5vOYfph9TWZb5e2Sxgl8IVOZBzibvudxZNYPGmn+bmdd5Jw0oOtC58fV3hXth1cOw7HeQtxMa6+Hb/5pm850pRS3LNDOZWn1gyhVmW/aGrh1zT6ouhjRXOe/ES2D4fO++w4Nj8ZPMJB3L7j36eZ1Ob3BsSGvBMXfz9yaZYwOtpNItNA582p9F1a0W3Gd+H+14G764Hx4aA0vP7dJLHLEh/4EV8PGv4bnvmWzbJkbHhQKwJ6+CvPJaDhSY37N3/W8b72w6SuZyE19+/BpWnOx1JuF37TsQ5wrUWm2UDzYZkiEOE4BLdSaycEJ8R16eiPQRCo5J79IkOLYrt3lwrL7cZCnYnI0m26CrlWaaZfjRZ5JpsDtY7ZrRZt6YQV0/ls5wZ47hDVxEWioorqrH6XQ2n63y8MyxmkbCLOYNha2+otuHKr3X2xuzOdm2AwDbiNPwn24++J1q28Ys616+3/AuOWW1PTlEOV7cwbGmM6e5+4mVZngzRYJbaTDsOe4IwbGSdKjMBd9g0+8yZa4pxfzuqWMe+jFx9xsbdZZ3W6zre3B4o/Cjyd4AL14CD42GV75vSu/cs166AwEzrzeZdpV5sOlFb9ZY/CQYeYZZ3/OJWTqd3jG4S9AAooebpTLHWte0TG/d4/Dln+Cj2+GdH8Pjp8And3fsfBmurLH4yd4ZF7u5Yflxtecj02YibiLEjDSBKfcNuKZllVYbnPuwWd/8Iqx9DPYvN8HH1pQehKp8sPqa7KjDuX+mq/K9v188wbFWjpfjI2GyySAEkz1WXQgZa6CmpMsuke8pqzwsc6wiD164CNb9xwRsl/+x2e7hscHYrBYqahv5bEcuAFaL+VX5q7e2tquP7s5D5ZRtM+Xr9uFnEB7o22y/c8QZzR43RI4gJqSXBC5FpEspOCa9iyvbIMmST2l1A5V13h4svvWlnvXGjS92/bXd2QoRSUc9NKe0lup6O34+VsYnhHX9WDrDN9C84WwiChMcq6xrpNHhZKZlN3EUt9JzrJ5wTHDMp0HBsYHK6XTy9qYs5lhNcIxhpxJyys2mZGvseQBMsaayLau05wYpx0ddhbdfWNMJStpTVglNMsfS275GWab3nD7+MO0H5vHBtZ0e9jFzOuHgarPu6oMJeAOEHem5U1VkMh32f24ep600wTJ7nelnE5Fitvv4wcm3mPVVD8Ou98168hwYfbZZ3/epWZZlQkOV+V0fNdx7LXfAokjBsVY1DWpuedVMXgDe2RK/eQy2vNb+87lLKpNPbNJEftexj7O3cJeIjr/ALK02WPhnk0U2ckHzY5NmeXsSfno3vHgxfPVA82N2/M9klrkb9ydMNu9ZDucX7A2s5+8y/x/dJc4KjvWs+b9xTb5iNTMUgzfQf4zsDicFFW005M9eb26ahA02167KNwEzF38fGynRZrbINzeY9/GXTB/C8Nhg6hodrNxbcNTr//H9HZxiMTOojj3lohb7Qyec7VnPdUYyZujRb6KLSN+k4Jj0Lq7MsWE+5o5hblmNZ1dAg7fBpk/eFshzfYDf+xms/fex9z9wf1ALP3pwLKukGoAhkYG9Z+YZi6VJ9pgRYamkpLqe0uoGRliyedP/D/zb79EWmWPVleX4WUwz4SBHlaeJvwws6w+WUFKUzzSLq6n3sNMgKAoufwEufZZGiy+RlkqyUnf07ECl+7kbuwfHmp8BN/fNg7oybyAmKKbl893BpPwjZNO4b0i4s3XDBptldVHnxtwVSjO85XKDZ3i3e8oqO/BhcN9nUF9pgovuxvnrXbP/xY5u3tty2g9N4/PybNj5jtmWfCKMON2s52yFmlJvkCd6JNia3Axxl7pVF5oSN2muaXDMXmeyosaeBzd+DqfeYba/f0vLAFdDTetZUJmu7L6k2d5sp/Ls/vG9rymF1C/Nujs4BjDtKrj0mdb7fp35B5hxnbdUsmn/tcZ6eHcJrH7ETFwA3my71sS5ZofN+s5kjVUVmOzS+EmdfUXSFYKj4cdr4Jat3h5kXdGDESiqqsPhNG9jow/v4evOHBw+33uj5rBSaHdp5ZYs8/9vSlIEZ46LA8wEQ0fidDqpP7SVQZZSHD6BWIbOaXFMYFQCuzA3I/Y7Epk+NLJDr09E+g4Fx6R3cQXHUqzmj1nT8q1guymzzHK6Poi537y9+xP49C5Y//SxXbu0SRbDUWSVmKDdkMigY7tmVwuMaPYwylVWWVbTwCiLyQJJtuS1CI7VV3p7uIVaatqVhi79z5vrs1hsW4mvxW7KaVz/HwHw8aMkzHwIbMhc3zMDlOPH3VuraUklmMwOd6ZYrrnT3mrmmPsDbsFu01usNYeXsge7fre7e5n1BHdGUMJU8Gvy+92dCVeZ13bJ2OH2fGSWEy72ZqHteNssD591zzcAfvCWd1ZAm59ZD42H6FGAEzLWeoM3TfvAAfiHQrCrxF/ZYy25g2PjLzRLvxBY5Or1Nu8uE4RsrIGP7zTZSgCF++Ef0+GxE5r/DNdVeG/OJc02f3fdM1x3tOy2t6kpNUFCR4MJ+h3+c9aWwAg4/xHzM2z1MeW9xa7+dwdXmyAxmKxH8GbstcadmbbrPTMZBcCI+QOnGX9vFjLI3CBx/1x00c+7uxl/dLA/PrbDPpq6JzBJmOINkLr/9ri4g2NuU4ZEcLprFssv9+Rjd7TdJ7WspoFZjRsBcKac2maft/WBJmi21TmC6ckKjon0VwqOSe/i+jAe5yjAisMTHHM6HIQ5TbnfJofrzlH5Iaiv9pb2fH6f98NWR9kboOKQWW9Hz7GmmWO9ymGZY5FUUFJlMsfiLKY3RDhVlFU3/3DX0GSCg1CqKVdwbMBxOp0s23GIq2yuErBZN3hnKHQf48qkCS/aoqb8/Z2n39iolvvcQVO76/dIWELLY8KTTQDC0eDNQjvc4Zlj7gy0mhIzG1pPyHCVdCaf2Hx7YJS3bL0yj6NqrINUM7MZYxaZGT8BGl03fJr2C3OLGw/XfQQ/fAeufs805AZIOcUs076Gva7eY02z2tzc2WOFe+HLB2DXB0cf50DgsHt/nk//rcly+v7L3p87q83M+GnzN6Wvez8x7yWev8C8LyhJa/4znLXezDAakez92fc0km8yy2JfU5Fn+q/tfMeUr829vePnCAiDJNf/nf3LzXLfZ2bpLpeEI2eOjfueuf6hTaYHH5hZA6X36EyZ+RF4SipD/b3BaTf3bKWJU5sEx1rPHAPw87EyJj6UGUMjCQvwobS6gU0ZbfdGyyiu5lSrCbbZRi1o87hVcVfzk/qf86z1YsbEh7Z5nIj0bQqOSe8SmgBWX3xoJJ5icl3BsarKUpPNAuxxmsyu6uIsU/7iVl8JH/6yc9ctP2Te7Nr8vHffj8CbOdbbgmMRZhln3kBEWiooqqqntKbeExzzs9ipq2neV8xRVepZD6VamWMDUEl1A+PqNjPcmovTLwQmXdbimIhR5s7pGPtecsvVlL9fa60Zv9v8u2HMuSYj6ozfmSzDw1mt3uyovCZluNXF3g82ZYdl6wZFAa6AbE03zEjcHu5G64d/eLdavTNXVuQe/TzpX5u/SSHxJgst+bBSHXefqsNZLCZLpmlpjzs4tuN/rn5oFtP76XDuvmMrH4QVfzFZUGKawNvrTJ+kqGGmv9vw05ofEzkU5vzErL/zE3hsNpQ3mTW16c+wu8xr8EzvNvfP+pHKiHu7DUvN/8nwZLj+M5i8uHPncQcY3BNbuLO/zrofLvi3mXwjfHDbzw+JhaEnm3X3LOJNJ8eQntfVmWMVtVhw8MuGJ+AvQ00ZOUB5jrkZYbGavzNtBsdCPOvjE8Lw87HiY7N6JsxafoTSyoziakZaXTfHk9rOaIyLDOEjx4mMSU7E1lvaqYhIl1NwTHoXq83zQSnZmu/JHCspNHfqa52+OF1NiKsLM73BscBIk8q/79PO/bFumsFgPfp/i0xP5lgvK6uccY35EOZq7hxJhafnmDs4BuBTX059o7dHm7O21LMealFwbCBKK6zkB66sMcuU74N/SItj/JLNG8cJloNszzh6k1vpRewNkPkdNBwlqFmWBZX53kbLrQXHRpwOV7wMi5+Fub9skWHo4S6tbBpYeOUKeHyu+fBzeOaY1WZ+l4N3prrjqabUm/lzeOYYNAmO5bTc15TDATvfM+tjzjZ/UyKSmvezbC1zrC3uQIE7u3n4vNaDC+4ZK4tcJbEVucfei7M/8PRpG2V+xtpyym2mRLim2JT/DZoAY84x+5p+GHcHdaOGebe5/z0LenlT/n3LTPCvtvls4DidsOUVs376PUcMEhyVuywybaX5v1+carIuR8w3fcvcE28cyYQLveuJ073/96R3cPdgLM0wFRyd5HA4WbO/kK9253Ofz3OcUfm+6Wf57ZPmAHfWWMwYU+buuvFL0X6or/KcJyUmGF+b+Ts0ZYi3guKMca7SyiMEx7IKy4jB1SvwCD2HTxoRg81q4dzJrWRKi0i/oeCY9D6ukp0kS76nIX95sQmOlVvDCI01f7x8q/LMXSUwd5TcUy1vf6vj1yw7rPfNUbgzx5J6W+bY+Avg+k9MbwbcPccaKKtpYBDe4Fi4papZAMzaNDiGeo4NRAfyK5hndWVETL+69YOihlNlC8Pf0kDh/k3Hb3BybLa9Cf+aCU8vgM/uafu46mL49xx4dIo3wNJaWWV7HR4cK9zvamTuhANfeWfDbPp7tyf7jmV9BzjNLJAhrWQQtydzbPWj8MBg2PiceewOroA3e8w3uF0Tv3iEJTSfMXTKFa0f584cc3Paey4DrzcpcGVzHa1/VkAYXPGqadB/w+fw49XeQE/TAK8nqNvk39CTOdbLg2Mr/gqbX4KNzzffnrnOlI/6BntmJu60uImmCqCxBt79qdmWcrLpi9de7tJK8M7YKr1HcIzrRobT+7eiE97ckMWVT60jbvdzXOOzzLtj57vmRo47SzNxqlmGxrmqO5yQ5y1h9rVZGRFrbuhNSYrwbHf3BjtQWNVmK4iy/AysFieNFl8Iim5zrGdPjGfH7xdyxQlH70ssIn2XgmPS+7gaHydZvJlj1SXmrk+1LQyra0azoPoC75300ARvmcm2N1v2LDgaT2Poo//Rq290eErKel3mmJtrdrlwSzXllTWUVNU3yxwLp4qyGm/fMVudd4atMEsVZdUKjg00RTnpBFrqsWMzGROtsVjIDzX7ggoUHOsTMtbBWzdASbp5vP1t04OpNXs/hbpyaKg2s/n5BHQsiHM4d3DMnY3lbkYPpg+Rvd58AA5tcife3XesJzLH3P3GklrJGgPvONvKHMveCMvuNd8/q6+ZXc3diB9MgABMb7F2ZCg34y6t9A2GcW0EL6JHtNxWeeSZ2vq14jTY/aH3Q3R7svWGzITTf2MypywWb8lw0+CY5/1C00xAV+CtMs8EmZuqr+74e5LuUuHql+eeLMJt88tmOf6CVrOGO8RiMX32wPQNAxjVwZ5hIYNM2bZvMEy69NjGI13PYvFmjxV0vu/YJzty8aeeW/xMpm31afdB2BDzd2jvJ02a8U/1PqmNpvy/OXc81588rFlmV2yoaa5f3+igvKb1PpZ1RSbYXRsY33YWtEuA7xEyT0WkX1BwTHofV+ZYcpPgWF25KeGq9QnHP8rMCuXrrPe+6Q1LgLHnmA9zxaneVOz2cve1iGj7g+D27DKe+voAWSXVOJ3g72MlJsSvzeN7VEAETlfvHnt1MSXVDQyylHp2h1uqms1Y6dvgLbEIpUbBsQGoNs+8wa0MGgI2n7aPizRldgGVnZz8Qo4vd9+kuIlmwo6aYtNQvDW7XQ3cE6eBxWbK+Y5UhnY07r5aZZmmZHF7k+DYwdVmGZoANl/vdldgn+qizl+3s/Z8bJbD5ra+/0iZYw4HfHQ74IRJi+GeXLj6neYzn025wpS8L/xzx8c24WKznHGtmTG0NdEjTXAxKMZ8wASoGqDBsZpSeGYhvHolbHvdbIttpUT4aOJcGWEVh7xBL3fmWNP3C/4h3t55TQNpFbnw4Gj47+newFRPcTq9Pw8Za70B6LpK2PGOWZ/aRlZiR535BzjvYZj2Q/P/YdpVHT/HRU/AHftbD/pKz3MHhAtdZcsZ6+DJeWbikHaoa7SzNrWIi2yriHSWQtgQgk5d4u11t+af3hsWrmoIoM3g2CmjYvjd+ePx9/H+zQrwtRERZP6+5FW03lLA6fr/7AhVuaSIKDj2/9k77/A4qvNt37NdWpVV77Is995ww3RM74SEQEICBJLAjzRCCElII4UvjRRCSQiENBJCQuiYbsAY4967ZclW722l7fP9cWZmd6WVrN587uvyNavZmdlZeTU75znP+7ySsUiEONbS6afDF8DfLgZKfnsKKUmJNKiaPb9ii1gm5grLvm6/729pZawyiS587/nd/PjlffzmTWEhz0+JQznBLNOoYbaI1upAQqiFuqZmXEo4n6GrOGYPhMUxqxLE3dE+YqcqGRuYGksA8Lsm97qdJUkIBA6PzBwbF3i15hvJBeHS80Ovdd/O1xHuLnfZb+GuQ6LEbDDEpYRFmj3PijwmveOjqmVhdS1lN8oqR0Ac62wWGWh7/idyqWr3ivPTXS9d6c05tv0f4vvIliiCx2MJzBa7EA0KlvX/XIvPFP8n5/+o522scfDFdaIcUM/Daj9J/07f+mH3rqLpJyirjIU9MdydtWY3eFpEJhJ0/+zmLhLL8k3hdRVbwNcGlVvhifOh4Uj/z2Go8LaFu6WqoXDn0zd/IN5TShFMOm1oXsueCKfcDFf8Hj72p26dtPuE2SJypiRjk8hQ/lAQXvyycAq+dV+fdt9c2oTX7+c268tixcrbxUSJ3gyoYjN4msXnUi+rhLBQVr6lT6+TlegAoCZGE6FAMIS9Q0x2WFMG4ZKWSCQTBimOScYeWrvvQkXc1Fe3eAi5xYxtKC6V9AQbNarmLtCzDvR26rr9fv/L/XvN5t4zx1RV5VCtEIxe2ilKOcdsSaWOlp2QQju1lWVRTyXjpjkiVywuEB3O62vvue21ZOIRCqkkuUsBsJ7AXeHQnJtO/yiUvUn6j1cTuu0J4cmDg6/Bkbfhxa+E3bcla0VGUHIBZM8HZxpYhsAZqztvXv+eWE5dHRYboPuExEiWVR54Rfx7/o5wAPSUs8NNAbpiiGMxnGPb/yGWZ9w1fOHhCZkndvIl5YjX1zPTJqJzzN8Jf70SXv9u7OePb4TNT4jHH38STvmccNydKHOsJyJLK/WJtLjU7g4+vcNppDimbw+itPnx80X57Wjg7iKU7n8ZjrwDmx4TP1/6m/6X+0pOXnRn8JF34I3vhbP9yjf2KXvv3YN1rDZtYRJVotP64s+KJ7Jmh0XaBdfDLW8L4V9Hb1BSs7t7CXOs00wS7t2aVm+356paPGQhJmIcqVIck0gkUhyTjEW0gVO60kIcHqpbPCge8QVoik8lPcFOjeqK3kcftGTPF8vWyr5nfKhq7DKJCJo6/LR5RF5BSDts/lgL4++CEicExFSljQRf9E1xkuKmuUNkjnn8QRJVd9TzgY4WJCcP1a0e8lXhhknI630AmZAuMv9cwSYCwe6d8Dz+IP4Y6yWjhE8Tx2wJWri4IgYVf78GtjwJfzgdXv0mfPSo2G7mJSfMXekXk07VzkNzsC28PuywgV6cYyMgjunOIl87bPqTeDznqp6378k55u8Mu5hnXz605zhQnJo4NhEzx8rWQ8k7ouyqqzMu6BeiL8DCT4v/z0sfEG7IgX6u9ey86t3dO6xGkq85Ao9/FL7/0Lefe424P+mohycvhU2PQ6D7YH1Y0cUxsyZ6H3gV/q6V6y69RQjDEklfKTpDCFW+Nvjw92KdPUksuzZ8iMG7B+q4zKyVTS6+ITrr7vp/wdf2wFWPiImaSBKzROdZ1HDZZS9kas6x2hhllccaO8hWxPhCidUBWCKRnHRIcUwy9ohziVkkoECpo6rFg9XbDIAlIY00p41q3Tmmoeoz9XqnmYBHhCL3BXe9cEygQFLsL8fSBne3dePGOaa0kRWRNwZ6IL9wjrV5AiQr0e8v1CnFsZOJo/VuJivCDWNOn9rrtknpQkDOVJppcPuinnN7A5z2s3f4+KMnvmGVjBB6WaU9QQwy9JI+NSgyqkIBIYwdfVesn3nJ0L7+yjvgsy/Cp5+FL7wHsy7rXRwbSedYV2HFZI3uLtkV/XvG0ywEMZ3yTaK5QGIOpPReljxiJGSIZVe30ETAyBpS4eCr0c99+HtRHhuf1nsJan8wuq7ugmYtnzRWBEPOfCE8dTSAVqZudGTNXQg3vgyTzwS/G16+Ex5cEt6uN45vhAfmwOY/D+596EJpzgKtu6YqyisLVsDqHw7u2JKTD7MFPvlUuIFPUj5c8ZB4vOOfvYq/VS2dHK1pDHfInn1l9Ab2xN67x+sNSkrXnfA0szTnWG0M59ixxg5yFK2EX4pjEokEKY5JxioRHSurWz3Y/c0AOJLSccXbqCW67OWMh/eJEHmbE8xaAHJfM2v0jpfOjOjw5AhK64V4FDnxXJA6tp1jujhWHO+J6lQJ0ZljbR4/SUSLY6pHimMnE0drWyhUtIFTWu/imFnLHEtSOqhtbI56bl9VK/XtXrYfbyYY6qNzUzK8GOKYNqO/+LNgssBpd8Idm0Wu2MJPw+QzxHN6ycpQYbaKY089VwzKFQVyF4ef7yoy6C6Bkcgc04UjPQdtyjlGVmNMHMlg0a77kaWVpVpzgUmrhtZ1NxgmsnOsKiKIe//LIu9o/8uw4RFY+zOx/vyfhJs7DBY946hmb7h0LJbL3GIPd9XTSytbNHEsOR8cSfCp/8CF/w8SskWjig2P9v7aoRC8/HXRWOO1b0NrD51S+4JeYuvMFIL1ja/A1w/CzWsG36FScnIS54IbnhWlyx/7k5hcScqDzqZexdyNRxs51bSbRKVTTCpEfif0hX6JYz1njh1v7CBHc46RlNu/c5BIJBMSKY5JxiYRofyVzZ04gyITy+nKxGxSaLNlGJvWq0kcbw2w/ki9GJjE93Nwpd9sJkV3qjlU08an//QRO443U9ogXGgXzM7GYhKDn7HvHBMC4tIsyNTEMVUbIEdmjrVGOMcCNvG8opdASU4KmisPY1WC+E120dyiNxzJeBFlOS210R0rS+rCImu7J3bbdMkIE1lWCaJr3LerYPX3xfVyxkVw5UNisHz57wbXnbKvRHYe6zpbrzvHRkQc08SCc78Ly2+DC37S+/aKErtjpd55s2iIhcXB4NSdYxNQHIvsUnfkHXjudtGVcs09wgVedDos+OTQvV5KkchCDfnDHVd7crUURJRWQtg5pjemsNhgxW1wya/Ez4ff7P21d/83/H79HX0OO4+J7sZMyBDly0WrRInaWBF0JeOTxGy49AGqXAv5xn9307DgC2L969+Bkndj7nK4tp0LTFrX5JmX9D/rThfHqncJIa4XMhP1zLEY4lhDKxlok8E9VI5IJJKTCymOScYmEeLYkbp2khFiTWKqmA33OrKMTfUSy02l2hdkf8UxPT+miyjwp/ePsu5wPQ+vPUyZVla5qNDFDy6fw02ripifN4DuSyOJ9nuYmeQnz9ws1mXMBIRzbMfxZvzBEK0dPpI151goScyGm32t3Q4nmbh4aw4C0O4sPPFNqqLQahGfrfaGyqinjtSHu5y2RDR8kIwikYH8OkMRtK+hqiq3/2MLt/xlE6G+ugUdSbDidtEgIHN29HOR1+++5kYOFL2sMmsuXPT/IH3aiffRc8faNXEs4A27hIbadTcYjLLKQZSnqips/Rs8cZEo7RsLeNvDHR+dmRD0ws5/AQrMvFS4H696dOgFnynniGWn5jLpqbO1IY5tEo62Vu0a2VUEnnyGcHA2Hum5tDLghbc1MUwvO9vx1MAD/dsjnGMSyRDzh3dLeGZLOT9rPFN0nAwF4N83QFtNt20PVTdznlnLaZx5af9fLDFbc7mrcGxDr5tmJumZY14a3T7u/s8OdlcIQay2ogyTohIyWcMTMxKJ5KRGimOSsYnWsTJfqWNneQspmjgWlyxu6gLOcDewalU4pDaXaTeteilFH7rYABHiWHSHsU3a8T462shRraxyUpqTT6+YxPcvm4PJNMZnW7VBZpy/mdX5YpCpZApxLNXUwbHGDv6zpRy3uwWrEhT7aOWs9qCbW/6yidv/sQV1uAeoklHlwyMNtFcdAMB0grwxnQ6b+Gz5m6PFsUjnWKtHimNjAr2s0jY8ZVPt3gCv7KrmzX217K3qh6h+4f1w/dPdnWp6IH8oILK9YuFtg6Eo/TbKzDJ63y6Srs6xiq0i49KZAem9d3odUXQBxF03MJHR1wF/uwpeuAOOrQ934xxtavYAqhApF1wbXn/Wt+CT/xDux96yigaKLo7p9CSO6aH8tXuEiKcGhQiWkBW9nSNJZH0BHH4r9rGOvCMyzhKy4MqHYb72ft//1cDeg/55T5DimKRvbD/ezP2vaLElJ2BneTMA+2va4fIHIX2GuE6XvNNtW2vVVtKVVvy25LALrL/okxEnKK2MzBz78wdH+ffmcn62Zj9Nbh+BJuF+VxNzZadWiUQCSHFMMlbRnGNTLHUEfB6cihakGadljUVkA9RozrE9la24vYEBlFVWdjtmQ7vXGOg3d/jZpc0yFaWP8VLKSLRulXQ2EufRboozROvtLJuwl//2zUO0NQlnQQALlmThikhUOnhzXy2v7KqmOoYVXTIxaPX4ueuZHUxGDPST82b1aT9/nBATQq3VUetL6qRzbMzh65I5NsQ0RwyaPjraxwmJ3rDYwZYoHrtjXMNDIXhkFfx+KfgHcW0KBcPfEf0RC7p2rNRLKiedOrbK03TBL+jrWWTsjR3/jB7Utlb2vO1IopcYZs+DBdeLjNFZl8MZ3xje1518BigRt8w9dLYmKUcIZ2oI9j0v1iXmxC5XnnquWEaKYzV7xT8I55sVnS7yVE+/S/y8/+Wwe64/6E5Jp3TISPrGL187wB/eK+GeZ3f2OlEaDKnG5MiB6jaCZjsUauJvl8+qNxAkv00E8QcnnSFyKQdC4UqxLN/c62YZWlmlLxjizX3iXnhTaSMfHW008sbMMoxfIpFoSHFMMjbRxLFJ5nrSFDG4C2Iyulg6ktLxqeJms0ZzjgVDKtuONQ+grFIb4Ec4x7aURWcY6PcEhanjSByL/D3o71FzjsUF28hNslPd6uHlj8SNeKc5EZNDDKCTCHf6rGiK6MommVA8/NYBFra+w/nW7WJF2pQ+7adqLgiTO1wuEQiGONYY/ty0SnFsbBCrrHIIaeoIdyz9qGSIcsKMUP4YJYHtNdBcJpa1ewf+Gh2NQsCA/pXTdHWOVW0Xy/ylAz+X4cDqALtW+t+1K2df0H+3WXPFcqyIY1Vad7vs+ZA1G+45Bp/46/C7PuJckLdEPDbbe//M6KWVe54Ty56yjKauFsuj74GnVTjCHl0Fj58HPjc0HBLP6+W+GdNh2gWAKjrM9he9AYUsq5T0kbJGMUn86u5qntte0eN2R+ra8fjF9dQbCIkoEv1+ojFaHDta72ahIj7b9qJlAz85/ZpbtR0Cvh43s1vMpMQLAW6fJuB5/CGeWHeUbBnGL5FIuiDFMcnYJLkAUDAHOrl7iZiN7zQnGjfAaYkOo2NlNSlYzWKbTaWNscWxjkaRneKPIfTEyBzbrIljNkv4TyQryU68zTIU725k0H8PLRVh94jmHFOCPr65WpRQetvFzYHXkmi4S1ItHvJcoitbuRTHJiyz9v2Wh2y/I1utA2t8eCb2BJg1h6HdEx50lzd14g+qfN78Ilea1knn2FhhmMsqI51jG0sb+5471hu68BArL6ulPPx4MOKYXmIWlwrmflzXuzrHqneJZfb8gZ/LcGHkjg0glL9OlFpTfJZYjhVxTP9952i/b6tj5Bx7emllcn7vYpxeWlmzW9u+B3Ese54omfS74f8ViLB9NSSaaNTsgfrDYrvIDsIr/08st/39hEHk3dDFMVlWOSLsrmjh+8/v5pG1R2ju6Fm8GasEQypVzWF37vee38PxiAmwSPQML5391W2QqoljXZxjh6rbWGQSn21lMJMKaVPEhHnAE/5b6wG9Y2UkG0sbyVW0cYIUxyQSiYYUxyRjE4vNyA25MlO4U+KSw7kwaQl29odEWcOBUAFnzxA3e5vLehDHPviNyE55+evdX8soqwx3q9xUKgSja08Jl05MSnMO6i2NOPrvIaiVpGbNFa4HRTjuLp8RzzVL8o0wfp81SeSgAJdOT2DlFLF/eVPsm6GRoNPj45ln/kFpZfWJN5b0m4KOfQDUTf04fHl7n51jDpe4kXT6w39jJfXtTFEq+Lb1n/zE+rjMHBsr6N0q7YnDcvhI51hzh5+DtUPQ6VYv+4rlHGs5Fn5csyf6uY7G3vO1/B4RLv/P68Ph5P0VClyFYlm7X+TpNJWKn7Pn9e84I4HuEGofgDhWL5p0MOVssexsjD25NJIE/VArrlmj8vuee40Qmaed1/t2BV0G/D1loCkKnP71sMPP4gh3tazeFf4/iGwUMfkMyJonOlfu/m/fz93vAa+WCdifjD1JvwkEQ3zlX9u49MF1/OXDMn62Zj8r7n+Ll3aOEYG5j9S2eQiEVMwmhYUFLto8Af7vqa20evz8a+Mx3j8UnhzbXRGdN7m/qjXCOVYSdV2uLj9CptJMEHN05+L+oiiQf4p4XLGl100zI8QxS0ResCGODUdOoUQiGZdIcUwydtFKK5VK0ZnJrJfaAGlOG3f6b+MK733sUKfysSXii21rWTM+u0tsFBnIr89cbX8KqiLawAe84e5TmiPA4w8as2A3rSoi3ibEpMnjTRyLcwHaTYCrED75lLiZcIgbccXTwo+vnMvslGB4e+0m3exrNZxjFc0jNCBqqxEutwg2vPQ4H99zO2X/vDNq/f2v7uPMX7xDbZvMQxsooZBKWlAMmpVFn4LErBPsESYhXfy9uYKN+IOilKKkzs085SgATsVLu7u9x/0lI0TQL2bVYcjEMY8/GPVzV4fgewfr+O+W8qj8uX6jO8dilcZHOsd0t0BrFfznc/DzyfD2j8W6plL46I/hslIQnf6OrYcDL4ezq/orFOQsECKGuxb2/E+sS8oPN4IZS+gio7ufZZWdzaJsFYQLyqrFCYy2e6ypTEz2WOPBVTTyr58xHb5ZChf9rPftsuaJz4hOUi8D7+VfgHvK4BtH4O4SmHeNWH/0vfC9SaRzTFFgzpXi8ZHuQec9orsHzTbjHkAyPLy6u5rnt1diUuCSeTnMzknC4w/xwxf34guERvv0+kyldu+XneTg99cvwhVvZWd5C8t+8ib3PLuLm/68icPaZIh+zzw3T0yw7q9ug5TJgCJE2UgXsNbdtylxOtgGGVWiO8/0jsE9kKXljgFcvVg4ORVCLDVpDtmuXZMlEslJixTHJGMXrWOlEVYbYXtOS7DTSgI71KmYTQpnz8gkJ9lBpz/I1nrtYx05sNJv9FHh9XvDs1h6aYzZboT9bz3WhD+okploZ3K6k6VFYtAzOWOciWMms+hulbsIbnzZ6EQpRDPA04zDaubzy4TomJWVYzjH8LaSnzKCZZXBADx2Dvzh9KgudKaqbQDkte0KbxpSeXHDXiyNh3hjb/cW4ZK+UdvaSTbib8SVPblf+yakib/FTKWZujbhTDxS52aOqdTYxt/ePCTnKRkE3ggX1xCUVf7urUPM/t4a1h0KD3Sa3EIc0yvbfvrKfr7+zA6++d+dsQ7RN3Sh6URllTV7RDe/h1fA7v+IdUfeFsvXvwuvfgP+c5O4voSC8MHvwvvqwkJ/nWNWR3hAtkHLfcoZgyWVEH5v/XWO6Y6lpDzxnaB/9+rfl6NFg15mOGX0Osv1JTzcYoPcxeGfTxT2rShCyLQ5w464Q6+LZVKeWB+J7uY7+p74bPcFI4w/Y2w1jpiAPL5OTBJ96ZxpPPSpxTz3f6vITLRT1+bllV2j/DfUD/R7v7yUOPJT4vn1tQsBkddlUiAQUvn+C3sIhVT2VIr7to8vEdUW+6vbxLVSd2RF5I65GkVuoDd70eBPMk9zjp0glD8zKSyOXbEwj0lp8cxRSklTWsV3Y8HywZ+LRCKZEEhxTDJ20ZxjBDpFKeCpXzaeSk+wGY/zU+KwWUx8bLH4En75sFbmE1McA46+C6Xvi8et2o1KUg4oCt5AkJ+8LMo2TpuWjqIofOeSWXxm5SSuW1Y4pG9vRLj6D/D5teFSIDCaGtDZDEBcQAygzfEp4Y52nlbyU8SM3ogE8rfXQGu5+D87+p6xOq6tDIBJagW1jeLm63BtO/8v9Gtes32TqgMbh//cJig1VcexKwGCmLC4+tepyaSVIKfRSk2zcOaU1LUzVyk1tvG7+5mHIxk63n8A3v15uKTSbBMD9kGwv7qV3751iJAK649EiGNaWeUpk1Kitj9cOwjnmC7k67lXkUSKYx0N4n16msOh53X7RUfLyu3i50OvC5Fs8xPQdDS8b9l6sRxIidmkVdprjWKJX1/Qyyp115C7Xgh63hOUvupdEtOni6WeszbazjE9oD7SSTVWiSyt7CmQPxb6Z8mvxRnEeq85C8X3uLcVNGf9CXFHiGOSIeP9Q3Xc9cwOI0ZgS1kT2483YzOb+PQKcR2zWUx8ZqV4/MQHR3vt+jiW0KsG8rUqgrNnZPLHG5bw4yvnsuarZ2CzmPjgcAP3vbQXty+Iw2ri4nniWnGssYOGdi++5CJxMK16wxcIMdkjri/O4hWDP8k8TYRuPBKuFgn6ox3DhDPHTAosKHBx1vQMzjRpEziTzxz096NEIpk4SHFMMnbRxTEQuRx54ZnYtITwLJDeQfIarbTyzTJtJrWjQTjEVDU8cz75DLHc/4pYGmH84gv9F2sOsKeylZR4K9+8UHR2nJ6VyH1XzCU5boDtpscaEc4xICwiOlzhcotI51hz59CEbPdCsCU86OrcJ2bMVVUl1ScGwlYlSOmB7QDsLKngVNMeLEqIpOPvDut5TWRaqoVQ0GRK7X8rdWc6QUyYFJX6mgpUVeVIbXuUc0zVP1+SkaW9Dt76IbzzE2g+LtYNsqRSVVW++9xugtp1oFZzC0K4rPLcWVnceGoRXzijGICmDj/t3j66WrpilMpsFkJXJPp70tn+D7E89/tCBPR3iHLLyGyyzU/AK3eJx1qnVSOLcSBiQdGq6J/HqjimB/K31YjvwWduhDXfPHGnQ12UzJghlrq409pzt7oRwXCOTet9u7GAHsoP/cszSp0SXZKZHuO9msxQfKZ43NfSSvcAM/YkvfKjl/byny3l/GujuN48obnGrliYS0ZEKd91ywqxW0zsLG/p1g19rKJPjOZq4hjA+XOy+fSKSUzPSuSLZ4pMsSfXlwIwKyeJjEQ7WZpL64yfv8MzRzXRqeEwvHoPnicuZ55SAkDy1L41AOqV+NTw9UB3j/31SvjN3KhGAPr97JzcZBLsFu66YAY3ZmrXk6nnDv48JBLJhEGKY5KxS/4SMFlEecIZ34h6ymkzY9c6SU5KE+JYUbqTZZNTaVS1gWAoIGZWPS3h3J2FnxZLvfQmQhw7UtfOn7Qbm19csyBmd5sJQaRz7Oh74cFl2pRwWaWnlewkOyZFzPTVt3tjHWnIqC4P38R07H0NVJW61k4K1LDjr/moKLFsOvgBFkUMmKd4dtMwzOc2UemsFzfzbfbs/u9sMuO2CKfQB9v3su5wPXEdx0lSws0bQp2tPe0tGU6qI8oZdafNIEsqn99eyabS8ICuLkIc051jqfE2fnD5HL518SxjImHArtPMOSJXytsSfg86LZo4lq4JN2oIrE6YdVnY6aSXWCblwxUPi+OZrKIj8fk/jj7eQMSC/KVCiNMZq+KY/vs48pbohKg7piu29b6fEQSv7a+XVY62cyxW98axSuFKsMRBQna4OU5fMFui8496EgKLtdLKki7iWDAAr9wNmx6Pbk6hTxBK59iQUdvm4WCNcCi9ta+WujYva/aI5kE3nxYdVZCWYOeKheLv6L9byxkP6M6xvJS4mM/fftYUPrtyEiuL05iXl8wXzhBi2cxscR/p9gUpCWn3F9ufgo8eIanyfeyKn3ZzMspQ/R3rJZEla4UgVrZOdHJd8y1jk9OnZfCti2Zy/9XiWp1IBxnNorxTimMSiSSSfvQvl0hGmNRi+NoekQXWxfKsKArpCXYqmjuZlBrO4/jEKQVsPNpIJw7i8AhXlJ7JYU+G6eeDYoL6AyL8XRfHknKNMqD5+cmsnt33cPJxh5atRuk64S4J+mDmpaITl17KEfJjVX3kJMdR0dxJeXNnVLefoaamvAS98CQtUMP7Gz4kLs7JKUo47FvVOtM5KsOllEtMB9lU1sh5c3KQ9I9gkxDHPPEDa2FuT8mFugbKykr4/gt7mKOURT1v8rb0sKdkWIlsaa87bQbhHAuGVH73lhColk1OZePRxijnWHOH+Bt1xYfdh/kpcbR0+ilv6mBG9gBe26xNipStg+Mbww4mb1vY8Tr9fHEdB5h1qQh2zpwl3v8urYtf9lxY9CnxL+gX1/6u4fTOAYhj1jiRdXNsvfhe0fMxxxqTVsGcq0TjgHUPhNdX7+p5H4jhHBsj4pj+eU4fB+KYMw1ufVt8Vvqb8ZU9N1wu2dN71XPHyjeJvwv9b/zou7DxD+LxsQ/h8gfFOciyyiHnwyPh6I7NZU38fUMZwZDKwgIXs3KSum1/0bwc/r25nPcO1qOqKsoYz37TA/nzXLHFMYfVzA+vmNtt/f+dPRWrWaHB7aO0XBPH2oVo+FpwKUfUHC699DoShio3cMZFsP3vsO+FqK7zHHoNDr4G0y/AajbxhTMjunGXvAtqUIjPkVUqEonkpGdAV6aHHnqIoqIiHA4Hy5cvZ+PGnnN//H4/9913H1OmTMHhcLBgwQLWrFkzqGNKTiISs8Fij/lUTrIQa6Zmhl0RiwtdADSi3Sh2NBpfyiRkCmFID8oteSecOZaYTUO7cEBkJsZ+vQmDXlZ54GWRSTT5DPjY42JAakvA6HDpCXesHO5Q/va66FKpLW89Q/2xvVHrklsP0tLpZ0pneGDnUtyU7j+BC0ISE0u7ViJ1orDoHrBnikHbqaY9lNS5mW8ujXre7DtBrpFkeIgUPvSykkE4x17dXUVJvZvkOCt3nS/EkrqILrHNmnPMFR+dAwmDvG7k60HLEfcCejdbR7Jw5ujM+7hYZohSeFo1Z0bWnPA2ZqsoR0vICnfDhIGLBXppZfbcsRtwrihw2W/Dgz/9vbYcMzInu+HrEE0OIOzOGwvimKc1/F2eOqX3bccKWbMhtX/NTsR+EU5E3b3XlZQi0Q0wFAjn5wFU7Qg/3vUMvPAl8fjYh2LpGofZqWOU9YfD4lgwpPLIWnG91bshdmXF5DRsFhMVzZ0cqXOPyDkOFFVVDedvT86xnlg2OZU/fXYpl83PpVQNO9N9ip3v+G9m05QvUXjKxUN3slPPFe7hluOw/vdinf45X3NP99J8gJ1Pa/uuHrrzkEgkE4J+i2NPP/00d955J9///vfZunUrCxYs4IILLqC2NnY3pHvvvZc//OEPPPjgg+zdu5cvfvGLXHXVVWzbtm3Ax5RIAH5w+Ry+c/EszpgeHtwk2IUZsjGkDQY7GsLlBInal7Q+43rknaiySr08Lz1hgotjelklQHIhfOKvoqsQiA5gRih/S8Qgt4PhJKQNejsdwrG3wLuFA3vFTX67Vr43OVTK2r0VLDIJ90CHtm2obMOwnttEJb5TfPYtKQUDO8CC6wC4xvwednyc6xIDV1UxA2D1y7LKUSFKHBuccywUUvn92+IYN6+azOR04dJtcPsIBMWAo1nLHEuJcI4VaM08BnXdKNAymyK7kOkllckFkLdEZDMlF0DxWWJ9ZDkaRItjOooiBC2dhAGKY6d8DqadD6ffObD9RwpHMlz7dzEJctUfxDUfRKfPWDQcAlQxkeTURMSxII7p3e6cGeEJnomKXqZrcYjS4J4oOk0syz4Ir9PLqmdcIpa7/iP+Ve0QpcCzrxzy0z1Z+UBrTDJTc8f6giEsJoVL58d2Y8fZzCzTup+/d7Au5jZjhZZOP25fEOjZOXYiitLjOaZmEdSGmk8Fz6Ge5GgH11BgjRNOYggL6Nf9S0wKNZZAbZdrXdVO2P8SoMCSG4f2XCQSybin3+LYAw88wK233spNN93E7NmzefTRR4mPj+eJJ56Iuf3f/vY3vv3tb3PxxRdTXFzMbbfdxsUXX8yvfvWrAR9TIgGYm5fMrWcUYzaFZ+0THJo4pueOdTSEO1Xq2TJTzhHLknegSSsFS8yhwS0cEGkJ0SWcEw69rFIxwzWPh3/W0We6Nz1mzBgOZ8dKjz9IvEf8HwXmXw/Aqaa9ZLaLjkZ1ueL/K0tpZss7zxKveHGbEvHO+QQAmc3b8AVizAxKesXlE6KxM3MAzgYQM67JBaQo7dwat5apflGKFcpZKI6ruvH4g0NxqpK+4u8M50UBNGrdGe0Dc459cKSe/dVtJNgt3HhqEWlOG2aTgqpCfbuPYEg1AvmTu5RVwmCdY1oof+0+kRsJEeJYvpjs+Py7cPNr4YYSmbOijxHpwIlaHyGODaSsEkT5zqeeGR/Og+x58NkXhcNCFwZ7Kq2s1TpwZswKO+L0QP72GlGeOhoYeWPjIIx/sOQvhfmfhLO/IyasekLvmloaKY5p/69LPwfTLgBUeO42sW72laLcUzJojjV0UN7UicWkcPeFM4z1Z83IJNXZ8z3k6dOE4PzeobErjqmqaly705w2HFbzgI5TmOrEj4X31EX44nN42Hcp6Ql2lk9OHcrTFcy+Ivw4c46YGCnUumFG/n0AvPszsZz7McicOfTnIpFIxjX9Esd8Ph9btmxh9erwzaDJZGL16tV8+OGHMffxer04HNFZRXFxcaxbt27Ax9SP29raGvVPIomzmjEpkWWVDdCml1VqOWL5S8WMUkdDuPwmKccInU9zTnDn2PQLoOh0uOKhsDsjkvN+KJYbH2MBYqA9nGWVeypbyEaUJyTMOZ/O5CnYFT9Xm8U1wpa/kDqrmIld3fIsAE1pi3DNFN26FnGAsoaxXaIw1mjp9JOFuDlPzS0e2EFMZlj8WQDuUp/E7GmCxFxMRacDIvBWF04kI0TtXhFQrxPSfv+2BPZXt3Lhb97jpZ19d/9sLWsG4PzZWSTHWzGZFNK1yYO6Ni+tnX4j89sVF1lWqTvH+nbdaGj3cv1jG/j1GxHCXkKmluWlQsUWsa5Fu14na27HzJnRZcGuSSLIH4TrJrWHz7buzLEnhV2zJwu6MFjTgzimiyuR7rr4dNHQADU82TTSGJ0qx0lJ5WAwW+DqP8CqL/e+nV7aW7UdvO3in15KnT0fTvuqeBwUE3+ccvNwnO1JyXrNNbawwMXp0zJI0iZmeyqp1NErHTaUNNDS6afNM7a+IzeUNLDwvjf48csi1qK/JZWRFKTGoShwk/frPLTwWWpJYW5e0vBkrU09L9zldcZFYmmIx++Ht4t0jZ1599Cfh0QiGff0Sxyrr68nGAySlRUdVp6VlUV1dXXMfS644AIeeOABDh06RCgU4o033uDZZ5+lqqpqwMcEuP/++0lOTjb+FRQMsDRIMqFQFAWn3UJTlHNMb2GufcbMVjEjmzFTzDAt/iykTDYyxya8cywhE258CRZeF/v54rO0kjmVFft+AqjDWla5/VgzWYrohKck5+NYdC0Adi2MP7VwFqZsUR51hlkM3LLmnYNSsIwQCkWmGprqKobt/CYiVfVNZChiQsGRNogMmsU3CAciiE6An3keJVH8nSUpHbRKcWxkqdbD+LsMPuxJ/OaNQ+yvbuOx90r6fLgDNeIzMjs3HC6dmSgGILVtHqOkMsFuwWYJ307kp/avHPt7L+xh/ZEGfv/OYWoj8syMLmR6d2FDHOuh1MxkCofIZ8wUIkMsCleITshdyzBPBnRhsHq36O724UPRXQ31hg6R7jqTKRx0PVqllXrX0vSTwDnWV1yFQigOBUQwf80eQIXEHFEuXLgy7MDMmBV20kgGzfbjzQCsKE7Dajbx208u4q7zp3PBnN67P8/MTiQz0Y7HH2LBD19n4X1v8NV/beNQzdjI6Hzyg1JaOv1sKGkEBl5SCWC3mMlNFvu/sltMxs3J7d6oYEiwJwjx15EMC0UFQrjseH04d+zQa2I585Lwd4VEIpFEMEStQnrmt7/9LdOmTWPmzJnYbDbuuOMObrrpJkyD7FLyrW99i5aWFuPf8ePHT7yT5KQgwW7poawyQoBdeTv830dw+3q4/HegKDS4T5LMsb5w/k9AMZHQtI8MpYUjdW4ODtPN25GyMuyK1lE0IRtl/sejno/LmkbawsvED/ZkmH0F1iU3gCOZZrMoEXHXHB2WcxsXBP3C7RErdLYHGipLAejE0b2stj8kZsNZ98Ck0+DmVyFjOjjEzW8S7iFzjoVC6ok3mqi8+UNY9+u+bau7fnIXRa1uU+28sU9cB3dVtPTZrbC/SvzNR3aczNAaltS2eWnSwviT46xR++kDqqYOP+3eQK+vsWZ3FS/vFJNlwZDKc9sihG69VGbH0+Jz3hxRVtkTGVppZaS405WUIrhjkyiL7AOBYIjgRPkM6o6wmt3w94/Ba98WIpmOnkXW9feXqOUo6QLlSGM4x8ZBp8qRRHfHlH0QzhvLni+WigIX/FT8TZx339htHDEOqdM69uol5GfPzOSOc6ZFxXzEQlEULpkf7qgYDKk8t72SSx5cZ1QvjBZub4B3DkRnPQ9GHAMoTBVO3kNaN/i5ucmDOl6vXHg/3HMs7C7NXSScxJ2NUCdiOozvkN6+HyQSyUlNvxSq9PR0zGYzNTXRtvqamhqys2PPlmRkZPDcc8/hdrspKytj//79JCQkUFxcPOBjAtjtdpKSkqL+SSQgxLGmqG6V2mcrMavnneDkcY71BWea0dHtiinCffHwO4eH/GVUVaXymCgD8TnSwWKD1GJ82aKjaFCxiJnxxZ+Buw7B3SWigYAWFN1uFeKYp6lqyM9t3PDeL+DR0+BvV4ZdkiDKiZsjJg06m+H9X8HDK8nb+gsAmq1Zgx8wnXk33PRyuCOeQ9z8JikdtA5Bycj/tpUz9wevsfbASdigpaUc1j0Ab/4AyreceHtdHOuSg7W1OmCIOyEVNpU2nvBQnb4gR7Vy5ZnZkc4xTRxr9dLSoYXxO6PFsUSHFZeWQdZbXqEvEOK7zwsxZnqWyEV7ZnM5qu5kmn6BCGB318L2p8KuJteknk982S0irH/p53p/g6nFhpDbG/5giMt+/wHn/mrtxMjQcxWJWIFQQPyDsDOvrQbcdaCYuue36aLUWz8MZ9mNFK1VYdEuQ2YERTHpVLEsWx8hjkVk7RUsg//bEA4slwwJ9UZGbf8nU7998Sxe/crpbLl3NS/ecRrZSQ58gRC7yltOuO/+6lYeXnt4SK9F+vX2rf21eAMhJqXF86Mr51KUFs9F83p3wp2ISWnxUT/PGU5xrCtma9h9XCpiOoxOvC5ZbSSRSGLTL3HMZrOxZMkS3nrrLWNdKBTirbfeYuXKlb3sCQ6Hg7y8PAKBAP/973+54oorBn1MiSQWTruFBlUb9DSVxXaOdSEYUmnUXBATPnOsr2i/r0/NEb+PF3ZUDnm21/bjzZjahbBldoWzOmwLRWmlOa1YZFspiigH7VIm5XWIMO1g60ksjh3V8jSOvitEsrYa4SJ77Bz4/VIhmFTthN8thLfug9q9FNW8DkBn/OBufGOii2NDlDn20o4qOnxBPjp6YkFnwuGOCG1+/5e9b6uq4TD1LuLYB8eFIyE3WZREfnik4YQvfai2DVUVgcy6WwwixLE2j+Eci8wb09EdFccbey6tPN7UQV2bl3ibmaduXYHDauJQbbtRsoTZCvPFtYCXvgreVjHw7+KMiyJvCdz6NuQtPuF77AvvHaxjX1UrpQ0d4fMaz5hMYWdRnBaMXfKOWOo5ZKlTwBY9qOWsbwoBvKkUnrhQTDyNFJseE0Je4cqTI3OsP+ilY+Wb4Mha8ThSHJMMC/Wac2wgk6lWs4lZOUmkJdiZl5/MKUXCvb2/+sTu/O89t4efrzlgdBEeLK0eP2f/ci03PP4R/94kJtMumZfDDSsmsfYbZ7Nk0uDC8yelOY3HiQ4LBamDc6L1G6O0UhPH9KYurkHESUgkkglNv2sb77zzTh577DH+8pe/sG/fPm677Tbcbjc33XQTAJ/5zGf41re+ZWz/0Ucf8eyzz1JSUsL777/PhRdeSCgU4u677+7zMSWS/pBgt7A5NAMVk7jZ79AGggk9CwFNHT5UVWgwKfHWHrc7qdCcdpMd7Zw5PYOQCn/oR15RX3h+eyU5ihhkmSODtRffAItugHO/3+v+Ia3TnDJaIdGjTSgUdgvEpwkheN8LotFEawUEOlGfuQn+dT10NtEcP5n/mC82ds8pHIYSJU0cS1Q6aO3svaSuL+yrErlX7hOU501IIgWIA6/03GEQhJDmbQEUyFkQDqYHqj1W0hPs3Hm+yFj5sOTE4pheUjkzJzFqfUaSnjnmpVlzjrliXDPzXXoof8/iWFWzyBfLdcWRnmDnormi3Og/WyJK9xZ9WizVkAiFv/LRnrPEhoHIc9k4UQTa838Ep34Jbl4jfq7eBe114cy67BglR65CuGmNcPK2V4cFteHG1wGb/ywer7h9ZF5zPJFaLP7egz5o0VwxOfNH95wmOKqqGjEcGUMQwzFTK1s/UN17YzGPP8i24yKf9YkPjg5JGeamo42UNnTw/qF61h0WTQYunpdzgr36TqRzbG5u8vCE8feGLo4d2yAmkLo2dZFIJJIu9Fscu/baa/nlL3/J9773PRYuXMj27dtZs2aNEah/7NgxI2wfwOPxcO+99zJ79myuuuoq8vLyWLduHS6Xq8/HlEj6Q4LdQj3JVKctDa80WXrNVtJLKlPibVjMwx7FNz7QnXbtNdy4qgiAD7Sbp6EgEAzx0s5KsjVxjKTc8JM2J1zxe5h1aa/HMCUJwdPaeRKW3AE0HQVfu+jSNP+TYl39ITqrDhibKA2HoOU4R9Vszmj8Fne5P81PbF8hkDqduEWfGPpzGkLnWHOHj8oWIaCcKLtqQtLZFP3zO/dHh6dHUq8FlrsKRQfGhEzjqXYcTMtM4Ixpohx5T2WrURLZE/u0gdqMrOjSQ905VtfmpVl3jsUSx1L0UP6eyyqrWsRzOZqjbfUscc3RBVHxgrPCpTFnfTO2cDNMNLp9vLkvLLxPGHEs/xQ4/8cikDpLcxkdfTcib2xO7P2ScsKh7i0j1ARl59MiM8g1SYRoS6JRFLjhOSEcmizi799VNNpnNaHp8AXx+EXG51DEcMzQytZP5BzbWd6CP6ga5/DwO0cG/dp7KqMFuaK0+CENzY8Ux4YtjL839Gyx9hqROxbwAAok9d5VVCKRnLwMaPr1jjvu4I477oj53Nq1a6N+PvPMM9m7d++gjimR9AenXXysD6StJqfhI21lpign6YEGbQYuzSnzxgx0caythtkLxE3N8cYOvIEgdot50Idfd7ie+nYfk+KaQSVaHOsjVpfYJ943dKLduKJqh1hmzQlnBDUcot6USwFQFsokX6mjEwe3+L7O9EkFnDc7i4+fch4W533Dc0528VmJV7y0uwfX5XRvhEhycjrHNIdXxiyoPwgHXoZNf4Jlt3bftms3v4RsUQIHuNU4Eu0WMpMcFGc4Kalzc/+r+1hRnMZlC3KjQqQ7fAHsFjMHqmM7xyLFsSY9cyy++3WzQAtiLuulrLJKEz71jmZ6+WajludjcM2foXIrzBhZceSF7RX4gyrpCTbq231sKWvCHwxhnUgTKMVnCod1yTsRnSp7KcvTB5UjFcy//SmxXP4FUWIv6U58qggjP+1rohR5kA2vJL2jO7birGbibYN3serOsZI6d6/XFz0rMj8ljvKmTv6+oYwvnlVsdBAeCHs1cey2s6bgC4RYPStrSN1dkWWVc/NGMG9Mx54ghPXmMjgk4iRIzBH5thKJRBID+Q0qmXAkOsTNyp6kM0HRbqZPEMYfDleVX5gGEc6xzEQ7TpuZkNp7hhCH3wwPZmJQ1+YlGFJpaPcamRlzEkQXI6MbWj9wpomBWnKgIRzifTKhi2PZ88OiSP0hOquFc+zV0HLO9/2cc7y/JK1oHv/8/Aq+cOYUUodTBLaHZ4d97uZBHWpfVXgm3e2dAGHo/UUrq/TnLxfd5gDW3APHN3bftms3v4hrXjsOEuziWnj6VOEe+9em43z16e08sS4crt7S6ee8B95j+U/fYqcWDj0zu4s4ppVV1vXSrRJgSoYI2D9S197j2zOcYy5xTP1z2dBVHEvOg1mXjfig/79bhTvq9rOm4oq30ukPsqvixKHZsahv947NQP8pZ4vl3hehTnOc9ubO0zuFto6AcywYCJeNT79w+F9vvJOQObjuw5I+Ua9VGqQnDs33aJ4rDqfNjC8YorS+51zXzZo4dvOqyUzPSsAXDLHz+MCuRzr6BNTpU9P57qWzWTklbVDH60qCXeSMKQosKnQN6bH7jD5xeFATx2QYv0Qi6QUpjkkmHE5tEFgXShCz4tBrGD9EOMeGID9iwqCXZbXXoCgKxcZgN/bNmxoK4v3nZ+C52zhw+GC355/edIylP3mThT98ndUPvMvmsiZsFhP55maxwQCcY0kZYqCWTvOQ5FuNO/SBY858SJ8uHrccx1EvyqPsWdOpsU3C6srloesXj4zjxWzBZxazxYHO5kEdam9EycfJWFYZcAvn2NO72/Eu/SLMuUoEk78XI5y/vos4lhApjsURrzlqv3TuNL66ehrnzxbPP7T2sNFV9MUdlVQ0d1Lf7qXdG8CkwLTMaHEsXZtA8AVDlDUIoTyWc2xqprhelDV04AuEYr6/Si1zTC+r1J27bZ5Aj/uMFMcaOthV0YJJgcsX5rKsSART97e0srbVw7ee3cmyn7zJjX+OIWqONoWngtUp8urUICQX9l5ypItjI+Ecqz8oyqBsiZAyefhfTyLpA+FKg6G5XzSZFKZrkxA9lVYGQyqby0SZ/bLJqUzPEtsf7UVMi4XbG+D9Q3VsKWui1ePnmDbZOXsYSx6f+OxS/nbz8igX2Yiii2PHPhRLmTcmkUh6QYpjkglHgl24GNq9AVh6K6CE2533gJ45li7LKsMkag0MtLD74gxxY1PSgzj21BsfYg+K577y+Ft88z878QfFALfV4+dna4Qroc0boKnDz7TMBJ677VTs7kpxAH3Q1Q/sWlllOi3UtA6uhG/coaqiCyWwtjWbJjVBhPID+e0iuL1g2nzev/tsXvvaGVEdB4ebgE3cuIc6mgd1nH0neVllZ4voVnm0w8ELO6rglJvFE40xsma6OscixDG3GkeCJo6lJ9j56urpPPypxUzJcNLc4edPWqONZzaLTl763/rs3CTibNGlbHaL2cgYO1gjBnIpzu7OsawkO4l2C8GQSmkPXW6rW3RxTJRVJsdZjRJP3ZU2Wry6W2SnrihOIz3BzrLJ/RfHWj1+Ln1wHf/ceJyQKvbt8HX/HL+6q4pb/7q5eznpSGCLh8++ABf9Aq55Aj73msix6omRLKvUxf/subJUUDJmMJxjQ1hpEA7ljy2OHaxpo80TwGkzMzM7keJ07X6sH+LYw2sPs+CHr3PD4xv5+KPreVZrNpLnisMVY4JjqJiWlchpWt7lqJChiWOq5tyVnSolEkkvjFzLJ4lkhNDLh9zeAMy8GL55FByuXvepl86x7hhllSLsvjhdOEFKIsqk6tu9rNldTXWLh23vfsCntPurRKWDpzcfx+0L8JtrF/Lo2iM0un1MyXDyq08spL7Ny6qp6cT5m8GviVoDCUhNyCSEglUJ0lhXBdmjkGkxWrRWQkc9Icx84XUv1nff4fXkfHJpwIQQJTOK5pAyCoJvyJYMndUEBiGO+QIhDteGP2snozimas6xJjWBx9cd5ZrPFKCAECb09roAQb9ozgDh8trEcHfedhw4u2TjWMwm7jp/Brf9Yyt/WneUqVmJ7ChvwWJSeOYLKzlU205hajyxyEy009zhx6u5u5Ljun/GFEVhSmYC2483c6im3XA6RFKplVXmamWVJpNCSryV+nYf9e1espIGnqUzWF7ZJcQxvXPb8slCeN56rKnHfbry1EfHqG3zkp8Sh1ubFNhb2cr8fBdv7ath1bR0AkGVu/+zkzZvgPl5ZXzp3GlD/2ZORP4p4l9f0CcxOurB7xHNH/rL+gdFd9XVP+xdiNPLxnMW9P81JJJhQneOpQ/h/eKMrN6dY3pJ5eJJKVjMJoo0cexofc9l65GU1LXzq9cPEgyp2C0mvIEQv3xdOPxn5YxCUP5IojvHdGRZpUQi6QU5FSeZcCRomWNGGVZcSu834IRnAmXmWAS6OOZrB2972DkWMVP5ved3c+9zu/n9O4cpUqqN9feuzsdqVnhpZxVn/mItf3pfDNzvuWgWCwtcrJ6dJRwpeuv5hKyBDbLMVtpN4saurW6EAqLHCpqrosJagBcb7d4A7zWG82Za1XiKJ00alVOzJ7gAaGtu6DVzqjeO1LXjC4ZL607GskqlUwyImkhkf3UbG+odoJhEqVl7RIfWpjJRbmmND2f3aX+/QUx4sBnl5pFcODebxYUuOnxBvvzPbYDoGJmWYGdFcRq5rriY57VkkvicmRQ4ZVJKj13IpmmllZEi597KVv696Tjt3gBtHvF/mp0cfh09d2xUXFQa5U0d7ChvQVHggjlCZCxKF0Jhc4c/pvurK75AiD9/IK57Xz53mvE721XRwl/Wl3LbP7byyT9s4Bev7adN+2y/tre6x+ONGeJSxOcMBpY75mmF178LH/wWmo/1vm2V7hyb3//XkUiGiYZhyKjVO1ZuKGngY4+s55G1YXewxx/kz+tLAViuOVgnG+JY35xjv3nzEMGQyjkzM3nqVtFxVv9OHc6SyjFB+nTxvamTLJ1jEomkZ6Q4Jplw6A6J/gymG9xDmyExIbAniCwagPaaiLJKMdANBEO8f1B0ibx4XjafKA4PZhdkmHno+sXYLCYqmjvxBUOsKE5l9azM6NdoFmVcAymp1Gm3Cru+p6lywMcYl2gDx31qEQCrpqZRouYYTx835ZEYw9EzElidQghIUjp4duvAREu9pFJ3L7l9wZOu6YLZI1xKzaoQmR7/sDwsfrUcD2+ol1SmTgmXnyWKz0KHKQFQjLLKSBRF4fHPLjVKBgGuXXriWfUfXzmP9+8+m30/upD/3HYqDmvsLoJ67tih2rAb4kv/3Mrd/93JPz8SwkiiwxJ1bmNBHFuzW4hUy4pSjXLkRIcVp1ZiqpeD9saLOyqpafWSmWjnioW5Rqe2XeUtvK6JYHurWvnnxvD/4+6KVqPhSTCkcv+r+/jbh6VD9r6GBEUZXGll9U5Ee2KiP8NdCYWiMxUlkjFC3RBnjgHMyknEalZo9wbYUtbEz1/bz2HtuvnrNw5SUucmM9HODSuKgLA4VtPqPaGren91Ky/uFPdHXz9/OosLXSzID7vsZ09055jVAanF4Z+lc0wikfSCFMckEw7DOebphzg2DBkSE4KIUH79Zqypw0+T28eeylbavAESHRYevG4xC+Iawvv52jl/Tjbr7zmHf39hJY9/9hT+cMMp3VuE64OjQQSkehwZAARbqwZ8jHGJVnK02St+d9+4YCZlSrg0tTluFGdHHeLGO5EO/re1glCo/6LWwRohwi7WOlwFQ6pRxneyYPU1A+BKF+6lt/bX4k3QxLHmsvCGDYfEMl3kjW091sTGjhxYcTtPJd4EgDOGOAaQ4rTx988t5/NnFHPdskLOmJ5xwvMymxQKUuOxW2KLYjrTsqKdYxXNnUZDj6e1fLPc5Gh3mj7g1K/Jo8Gb+0TO4kVzs6PWZ2mNA6pbexfH9la28sAbomTpxlVF2C1m5muD0Q0lDWw91gxAnCYqrpqaZgiUr+8Vr/3Krir+8G4J339hj1H2H0mHL8DWY02GYPzyzir++F6MLLrhIFm7zgzEOaaXSkLv4lpzKXhbwWyDjJn9fx2JZJgwyiqHMMfTFW/jT59dyr2XzGJlcRqqKtxe6w7V89j7IhPy/qvnkazlPbribcZEwoncY4+9dxRVhUvm5TAnNxlFUbhpVbjBRU/O3wlF5DVkEJOxEolk4iPFMcmEQ3ch9CejSHar7IGIUP54m4VcbXBYUt/O+iNCDFtRnCZCtCNDwr1ixlMPsj53VhbJcd1Du43B0SBm8kJOIeApbTUDPsa4RHNV7AgUYTYpzM1NIntK2GERSJkyWmdmiGMZ1k4qWzxsKGk4wQ7d0R2K8/JdxrqTqrQy4MUaFC6iooICVk0VA6bDPs3l1RzhuqnXxLG0qbR5/Fz/2AZueGIjnnN/zIuW8wBiOsd0bBYT3754FvdfPc8IxB8KpmaIHJ2SejeBYIgPj4Q/B7pgluOKLqcebedYIBhix/EWAFZNjQ6RztYy0Gp6Ecee317BlQ99QEVzJ3muOD61XJQ2686xyhYPwZDK1MwE/nLzMi6am82Pr5zHhVr55mu7q1FVlYe1sqqQCq/t6V5uef8r+7n64fU8s6Wc5g4fX316Gz99ZT/7q1u7bTvkGB0rByCOVW4PP47lHKvcBo+dA2u+LX7OnA3mGN8dEskoUT9MDZzOnJ7BLacX891LZwPw8q4qbn5yEyEVrl6cx7mzoruu6xOWPTU8AQiFVN49KBq7fHpFOGbh4nk5LJ+cytkzMshPiV0+P6HIFL9T4tPANkpdMyUSybhAimOSCYc+CGzr40C60xfE7RNdbGTmWBcM55gWyp8hnCBH6tysPyJKKk+dkgahIDSVhvfzxg6V7YaeOTOIDAhFE/CsnbUn2HIC0dFoDCz3qpPISXZgMZs4d+UyfKpwo9iypo/e+Wni2Lw0IbT8b1v/B9F6VtnMNBPnW3diJXByhfJ3iLyxoKpgS3DxaU1k2dCg3dhH5jU1aMJ02jQ2lzbh8YfwBkI0uH24veLa1pNzbDjJS4nDYTXhC4Q43tRpXDMiyeniHNPFsYZREsf2V7fR6Q+S6LAwRbve6ejiWHVLdycXCHfjj17aiy8YYvWsTF780mnGpEBmooOspPDky1nTM1g2OZVHPr2EyelOLtBcapvKGvn5aweiOrXqzQEi0Qe8f99Qxiu7qvEHhYNMd1wOK0m6ONZLWWRPnMg59t4voWILHHxV/CxLKiVjjOGeTJ2dm8RFc7NRVfAFQ1wwJ4ufXjWv23ZFaVruWA8dxEFcz+rbvcTbzEbuIYgJkae/sJI/37Ssu6N/IpI1RyxTJve+nUQiOemR4phkwhHpHOtLRpGeN2Yzm0gchQHkmCZBc461CeeCnju2t7KVzaUiD2nllDQxSApGDGa9fRyg6YOrQTjHrC5RZhbn7T7wnrBorrH2+ALaiDdmfk+bns1+8wwCqomc2aeO3vnZRZlGcaIQszZqnbb6ij8YoqxBuKbmH36EP5r/H9eZ3zKEnpMCLYy/mQRc8Q5Wz84iM9HOQd05FpU5Fi6r3HA07M5q7vAZbrtYgfzDjdmkGF1uD9W0Gc4xuyV866G7UXX00vZGd2wBarjZpnWjXFjgwtTFRWeUVWpdNruypayJ+nYfSQ4LD39qiSH06czLC+f8nDUjOn8xzxXHGdMzUFWMMO4L5ginyIaSRmNADqJL8DEtm2xneQsPrz1sPBfZ/GDY0J1j/S2r9LZD/cHwz13FMZ8bDr8pHsdpA/lJqwZ2jhLJMBAIhmjq8APDG8Nx94UzmZWTxM2rJvPQ9Ytj5jpGNkn69+bjhmAeyfuHxLoVxWnYLCfxkG/GxXDGN+CCn472mUgkkjHOSXyllExU9MyxkAqd/hMPphsiOlWeFDNo/aGLc0zPpnhyfSmd/iBpThvTMxPDzhUdbx9Le5oHnznmTBP5N0mBhpMnsF1zX1THTQOgIEWE1ptMCplffJ4DH3+HoqlzRu30dOdYmlmICGUNHVGD+xNxvLGDQEglzmom4ejrAOQp9bj70CVwwqA5x5rURJLjrFjNJj65rJByVSv1051jnlZo10qK06byUUlYiGzp9Btuu97KKocTPXfsqY3HqGrxYDObokL/s5O7llUKN8ZolVVu0/LAFhWmdHvOcI71UFapB/mvnp0VcyA6L88FQLzNzNLJ3Y//6KcXc9tZU7CYFBLtFn54+Vzm5iURDKlGFhnAdu0cdcqbwmLdkRERxwYYyF+zGyOMH6JLg0EIYwEPuCbBV3bCTWtg3icGdaoSyVCiX5dMisj9Gi4mpzt59Sun873LZmMxxx6q6WWVL++s4u7/7OTzf91MS6c/apv3D4lJw9OnpXfb/6TCYoNz7oXC5aN9JhKJZIwjxTHJhCPOakaf8O9LRpHRqVKWVHYnQcu4aBeDvisX5XHZglzj6RVT0oS7orEker++lFX63IY7ZjDOsQRNHMug6eTJpNI6VR4yi1yxAq2jI0B2ZiZz5i4cjbMKo4ljVn+70bFw+/HmPu+uh7YvT3WjaFl2Tjwnz/8vGH8bTSQYpXmLClxUGOLYcVDVcKdKZybtipNdFS3GIZrcfjp8o1dWCXCBlqW19oBwMCye5OKcmWHXVK5rbJVVbtM+p4u0RhCRZBniWHehV1VVIxtMzw/ryjkzMzGbFC5fkBuzmUG8zcI3L5zJum+ew2tfO4PsZAcXzRVdRyNLK/W/pbyI31281klTL0ceVpIGmDmm542lTdX2LxefYZ19L4rlrMvAkQSTVoa7r0okYwA9byzVaRvSfMaBoItjvqBoVOMNhHhtdzif0OMPGq7t06eduNGKRCKRSKQ4JpmAKIqC09b3jpX6zc5QtuWeMEQE8gPYLWZ+98mF3HvJLIrS4vnUMi0rTHeOxWsDd18fBmi6a8CebIgpA8GeIsS6TKWZ5lEaUI84WlnlzqDIoRpzgbp6SVRrOYu0Ln1btXK1vqAP8C9w7DXWORXPSZY5JkoQm9VEXFqHsoxEO5W6OOZ3C3eZLo6lT2NLWRPBiM6glc1hR9FoOccunpfDfVeEXYwri9NZNjnVcFbprkedtITRC+RvdPuMzm+LClzdntddbjUt3Z1juytaqWjuJM5q7rHj57z8ZDZ++1zuu2Jur+eRnewwRMPVWgj35tImAtogeNtx8bf0xTOLydQ65t14ahEQbn7wyNojvL1/mJqU6M4xXxt4Wnrezu+B0nUQ1Nwset7YzEu0593QqV0XAl44+Jp4POvyoT9niWQI0CdT08dA86aiNKcxEVyoTZA9tz0sWG882ogvECIn2cGUDBlCL5FIJH1BimOSCYleWtmXjKLIskpJF3TnWONR0LpBKorCLacXs/YbZ3Pq1HRR1lWxRWyXs0As++IcG4K8MQCcYiDqUPw0t/YyUJsoeNuN7oTrO4QwGOkcGxPkLQaLA5qPcXaKKMnd1qUUrDf0TpVLgtuNdU5ONnFML6sMO8cyEu34sFKjusQ2LcfC4ljalG5dQSs0ccxsUqJyvkaaz6ws4uFPLebCOdlct7yAeJuF31+3iJ9cNZfCtOjPru4ca+7wG2LQSLFdE52KM5wxS6b0ssq6dm+UCAmwZo9wdp09MyNmPpBOWoK9X9k/0zITSHJY6PQH2V/dRjCkGt00TylK5befXMSXzpnKl8+dht0imh/8bUMZP1uzn+8+t6fPr9MvbE7R9Q2iG7F05f1fwpOXwOY/i591caxghXHdNkozj7wjyvETsiB/6bCctkQyWOrbx06lQZzNzH1XzOWrq6fx98+JcsEPSxqo1sR7/fvgtKnpMjJEIpFI+ogUxyQTEqfRsdJ/gi3DnYfGwkzgmCNrDmTNFU6w/30eQl0Gq3v+Bw/MhvKN4ucCLc+hL+KY0alykOKYzYkP8f/d0dw9kHbCUbMHUFETstjTItwlY845Zk+EaecBsKxjLQA7jjd3ExR64kidGxMhilo2GetEWeXJFMgvhJpGEg1xLM1pQ1GgXNWEheZjhlBK2jQ+0gZDKZrTTBfHnDbzqA+OLp6Xw6M3LCEzUQhM58/J5lNaB85IUuLFewSM4OuRYmtZMwCLY+SNgQjgNimiK2V9lwy9N/cKEfiCHkoqB4rJpLBY6zK3payJw7XttHsDxNvMTM9KZOWUNL5+/gwcVrPRTfgP74oy99o2z/DlMGbMEsuavT1vc1z7XijfBMFAOIw/a0441F8Xxz78vVjOvUaWUkrGLA1jrNLg0ysm8dXV0ylMi+eUSSmoKry4oxKAQ1r+4Ny8gTvzJRKJ5GRD3oFIJiThjpV9cI659Zud0Z8JHHOYzHDNE2CNh5K14QGMzqbHRWlN2jS47Hcw9Vyxvk/OMW1QNFjnmKLgNolGAR2tJ0HHyrp9AHhTZxIIqdjMJrISHSfYaRSYczUAaaUv47SZcPuCHKzpw+cCUVY5VzmKzR92Ap5sZZVBt15WmUCSJo5ZzCbSnLaI3LFjRqfKUOoU9laJRhh6J8QKLah9tEoqB4LZpODS3u9Il1auPyKuH6dMii2OWcwmMrQyxuqI0srypg4O1LRhUuDMHkoqB8OSwrA4pnfTXJDv6pZ5pJdO6Q0D/EEVt2+YBOUsrVS2Znd4XSgIH/zWyESkbr9Y1h+ApqMQ8ovvkuSCaHGsfDOUvg8mC6y4bXjOVyIZAmq0vy29nHksccUiUe78spZPqDfn0HM/JRKJRHJipDgmmZDog8H2PjjHwjb5sXezMybImAHn/1g83vJk9HN6Sc0VD8GSz4JdiFT9KqscrHMM6LQkAuBrazjBlhMArflBc5xw3eSlxImmCGON6ReAJQ6lqZQrs4Sjry+llY1uH80dfpabhAio55edbGWVgTbxO2smkcQIcSs9wR52jlXvNvL+6uyFePwhrGaF+VrOm+EcG0fiGESG8ve9w+lgaenwG0H3PWWGQeyOle/sF66xJZNShqWD3ZII59izW0Wm0NKi7gJerEFw03AJjIY4FlG6ue8FeON78OJXRFmw3kW1/hDUan/P6dOFM0y/7rcch3W/Fo/nXzv4yRKJZBjRm3F07bI7FjhTC93fW9mK2xugrLEDgCkZUhyTSCSSviLFMcmEJCyOycyxIWH2FWLZeCQsfAV8YfdXSpFY2oVIhbctugtZLPRyHFfhoE/PZxVigL+9cdDHGvNoYkiVReSNjbmSSh2bUwhkwBXWjwDYVHri/5/D2mz3IrvWna9wJQDxysnVrTKkZY55ba4o8TMzycHbwYXih93/AX8HKGYO+4WbrDA13hD6WzrF5MB4E8f0kqWRcI51+AKoqsq6w/WEVJHx1bWDZiR6x8qaCHHsbU0cO2dm1rCc44ICFyZFiJ0bSxuxmU1cH6MkNaY41jFc4pjWVCBSHKvcJpZVO6Bya3i9vwMOvykeZ8wQS905duh12P8SoMCqrwzPuUokQ4TejEO/DowlClLjSHRY8AVDvLmvhmBIJcFuIStJTvxKJBJJX5HimGRCog8G+9Kt0ug+NEYyJMYkznRIFGIM1VoZTctxQBVlMgmijAu7NjhTg+Dv7HYYg4YjULsHFDNMPmPQp+e3CXFM7TgZnGNHASgJioH4mAvjj2TWZQDM9ogg7g8O158wA2ntASE0zLKK3BTylgCQQOdJ5RxTOoU4FrC7otZnJNjZrM6g3jkdQtrvI6WII43iOjY5PRzgrzOeyiohwjnWPrzi2IHqNub/4HXu/PcO3j0oPncnKovUHSN6WWWnL8j6I+K6c87MzGE5T6fdwqycJOPnjy3Jj+lciXSImIY7ty1zJqCAuxbaxe+O6l1iqQZh+z+jt9//slh2Fcf00sv5nwg/J5EMA6qq8vSmY+wqH3jjHt0xOhadY4qiMDdX3As9t004TKdkJox63qREIpGMJ6Q4JpmQJBrdKnsfTKuqagzA0hOlc6xXcuaLZbWWJ9MkRBpSijAStK1OQHvsa+/5WPteEMvJp0N86qBPLWTXSoy0EPNxzyvfgF9MNVxiBqGQUVa51S1+b9PHcp5I3mIAnC0HSLCEqG3zGs6wWARDKv/bVgGoFAS0sltNHIvH2yexe6Jg8jQDoDqi/z4yk+yAwgdpHwuvTJ9GSZ0bELlTri7iWLyt5+6JY5HUBL2scnjFsY2ljQS0z9xz24QY21tJJYQdI/og+cOSeryBEHmuOKZnDd/fop6DZjYp3HbmlJjbFGc4KUiNY3K60yjFbB4u55jNCanF4rGeO1YdkT+278Xo7Tu0PMiMmWKpi2MAWfPg0l8Pz3lKJBpv76/lm//dxZUPf8Bj75X0u1mFqqphcWwMOscA5uYJEf29Q+LvTc8hlEgkEknfkOKYZELitIvBoF6G1dLp579byvEGosssWzsDBLQOeqkykL93sueJpR62rOeN6SWVILJkIksre2KvJo7p5ZqDJV4MBE2egc8IjxnaakSjA3cdrHtAlKd+9AfY/hS0V0OgExQzHzaIm97p2YmjfMK9kDIZHMkoQR9X5or/m3WH66lu8fDG3ppug5MNJQ1UtXiY4WjGEuwAkxWyhShrVYL4vL24EScS9Yew+Zrxq2a8zpyopzK0ksl3bGcaeWykTaWkXohjxRlOXPHj2zmWbjjHhjdzrC6iNNIXDOGwmlg2uXexPrtLWeWHmmvszBkZw+rQ0LtgXresgMK02G5Ru8XM6189k5e/fJrRFXTYMscgOnesrUa4yHSC2v9dcpey+XTNHZY2DezJkJAN1/1TiG0SyTDy5j6RgRcMqfzklX184W9bjNLzvtDc4ccXEB27M8doqaLemVLvDC3D+CUSiaR/SHFMMiFJsIvBoS6OPfjWIb7+zA5+/cahqO3qtZLKRIcFu2V8uStGnOwuzrHGCOdYJDbtZszbGvs4zce0PBoFZl46JKdm1txnNl/zkBxvVNn5L1GWBLDz36L726t3w3O3w7EPAQi5CjnaJAa9M7LGsDimKJC7CIDVLuHMeWNvDR97ZD23/nUzH5ZEl8H+d4vIsLtusggSJm0qOMJt6IN9afQwEdCcletDc7A7k6Oe0rslVrYDZ9wtSpNnXERJnXDkTU5PwBUXLfSPt8yxfK1UuKyhI+bz/9p4jCc/ODro16ltixbflk9Ow2Ht/XtAzyMr1zqBHq0X5xhZ9jgcnDo1nY++fS73XT631+3ibGbibRZDIG0crrJKCE+Y1OyBGq2k0hQtzDL78vBjsy38feFIgi9vhTs2yhB+ybCjqirv7BdNTj62OB+b2cTre2u47MF1HNUmFk6E7hpLddrG7P3inNzo74upMoxfIpFI+oUUxyQTkgTNOaaXVepdyP67tZxAMIQ3EKTR7QuXVMpOlSdGL6us3SfC+GM5x+DEzrGtfxXLSaeGs8oGiTUxTbx0oAdBbrygqrDt7+KxJQ6CPnjz+/qTsPnPALQ7C1FVSE+wjf0uq5o4Ns8kxIz1RxqMLoqR3Svd3gCv7q4G4Nx0bX3mTDBbCJqFC0b19lKqO5HQStJeDS3r5gLL1MSxunYvrLwdvluHJ2+l8TstznCS6LAQaWIab+KYXgqkC36RuL0Bvv2/Xfzgxb3Utnm6Pd8fdHHsltMmc+GcbL66etoJ95mcLs6tvKkTXyBEWYMYWBf14OYaSrKSHH3uTKs7oYetrBIinGO7wyWV0y+IFsgi3cFp08Ac8Vl0pkeJ3xLJcLG/uo3qVg8Oq4mfXDWX/9y2kvyUOI41dvCTl/f26Ri6ODYWw/h1Jqc7o8rop0jnmEQikfQLKY5JJiQJDr1bpehEdqBGCDV1bV7WHqjjk3/cwMr732LbMZFRlSZLKk+Ma5IYyIT8IkS5qUys71Ec6zKwDfjgxa/Ae78QP8//xJCdml0Tx+KD47ys8vhGqD8omhxEZvAo2qW69H0Aai15AEwfy64xHU0cS23Z0y0ofm9VWMzcU9lKpz9IdpKDfL/22dLyiVSrVnJ1MohjzcehchsqCm8El3T7nenOsTrd9WQyU9rgRlUhyWEhzWnDZFJIcoT30ycLxgvF6WJAV9niocMXnTNXUudGqxjiSG3fHB89oYtrp05N49EblrCoMOWE+2Ql2YmzmgmGVI41uilrFM6xSaljqyzQFS++04YtkB/C4ljtfjj0hnictzg8keIqhJwF4etXxvThOxeJpBfe0Rq9nDolHYfVzPx8F3+5eRkAb+6r5UiEEB8MqQSCoW7H0DtVZo/RkkoQmYSzNRer1awwaSw37JFIJJIxiBTHJBOSFG1gUNHcSVWLh7aIIO87/72dbcea8QZCPL1ZhH6nJUhx7IQoSnRppeEcmxy9nd6xsqtzbPvfYcuTgAJnfRsWfWbITi0+WYRoJ4TaY97UjgtaykX5JMCcq4R4mLMQHC64+JdRm5aERKfK8SSOKTV7OXeqcInM1HLS9kWIY8c0kWFKphOl/oBYqXWvU7VSXZN/cGLIWCYUUmlvbYJd/wbgSPx8GkjuURxr9wYM4ehonZ43Fu5MFuk4G2/OsRSnzXA+6Y0GdCIHsX0th+qJmlYhMOr5XH1BURTDPfbhkQZ8gRAWk0Kua2y5SVK0//9hdY65JkH+UjFhUrZOrMueD/lCdCBjFljs4e8IPYxfIhlh3tkvxLGzIzrKTslIYPUs8fMT646yubSRO/+9nUX3vc6qn71NfZfMw7HcqTISPXesKM2JxSyHeRKJRNIf5FVTMiFZkO8CxMBKD0x2albz1gihTB94jfnStLGCLo4deh18mvjl6hK4bDjHupQ41milCytuh7O+KcL7h4j45HRxKko7zf0I2B0z1B2AR0+Hqu3CnXfql8Fkhs+9Dl/bDYs+LcosNXZ1CqfcuBDHkgsgPg1Cfr67DB74xAIev3EpAKX1bjp9Il9NF8cKU+LF7wPE4BrALsQIk9/d7w5j44V1T36bhAeK4K37ANhoPxWgW35Ygt1CnJaLpbvHjDD+9LB7KbJj5XgTxyD8XkrqexbHYpVd9pVgSDUC//VS1b4yWSv7XHtAZBgVpMaPuUGoPkHUOJyB/IoCVz4SdW0iay4s/ZwQzZZ/XqwrXCmWBcuH71wkkh44Wu9mS5moEjirSzfaW04XHVf/ufEY1zz6Ic9uraDVE6Cm1csT66JzDWvGQVklwKqp4n7olKLBdwKXSCSSk42xdTcnkQwRKU4b07SshX98JEq0zp6ZaXTumdmlw1+6LKvsG8VniuXe58UyMResXW4U7Vowta/LwLWtSixTuzjNhgBLghCLXLQPr1NiuNj6V+hshMw58IX3RNYWCNeFPVEsi1YZm29odgEwI3sc5IlEhPKnNO/m6sX55LniSE+wEVIxSp6PadlNs5ztQlg1WSBVDFxMmuAaj4cOXzDGi4x/8iteASCECdKm8Yb5dACSujjHFEXpVlqpC0bFGWFxLHK/8datEoSrA7oLYFHiWL0bfzDE/a/u40/vl0SVYAZDKnVt3m5ian27l5YOPw3tXkIqmJT+T45M0YS7D47UAzBpBPLG+kuKkTk2zJMF6dPgPCHokpANidli3S1vwtTVYv0lv4LbPoTis4b3XCSSLjR3+Lj5yU2EVFhRnEpBlzLD5ZNTmZeXTEgVJYnXnlLANy4QjuW/fVgW1c2y2iirHNvi2Hmzs/jf7afynUtmjfapSCQSybhDimOSCYs+a7ZVC/2emZ3Izz42j5tWFfGPW5aTGDFglM6xPjLtfJh8RvjnrnljENGtsktZZZsIWycxe+jPK05kBTkUP82t47CjYbtoMc+CT8b+nQJMOQcAVTGzrU0IkNPGg3MMDHGMiq3GqpnZ4j3opZW6c2ymSZQ6kzoFLGKAb9JKdZ14cHfJoJoIqAEvBQHxvj/l/AN8aTPHvEKA6VpWCeHSSj1Q/qAmME6J6EymZ07BOHWOaULfkS5llZFllkfr3byyq4o/vFvCj1/ex+k/e4d3Dwo312/ePMjSn7zJpQ+u4/ntFQA0uX1c8Ov3uOz366jSBrrpCXbMfQy519GdYx6/KOEuShtbeWMQLqtsGonJgqW3wOW/h48/SVQnCB2rA7Jmx35OIhkmVFXl/57aytF6N3muOB68bnG3bRRF4cHrFvG11dN5884z+dk187ntzClMz0qgzRvgr+tLjW2rtTLsse4cA1hUmDIuJ0UkEolktJHimGTCsrQoOlx5RnYSSyal8v3L5pCWYGd5cdhyLjPH+oiiwEW/EK4eiC3k9NSt0hDHcob+vGwJBNA6lDbXDf3xhxu3cKDgzOh5mxkXgSWO9oxFBLCQm+yICl0f0+SdIpblG41Vs3Kic8eONYpui1OatOyigmXGtooujimduL0TzznWVLYLqxKkRY3nw4Z4qls8hmOha7dKiOhY2ebF7Q2wr0r8rS0ocBnbuOLGbyA/iPw0iHaOBUNqVJnlscYOQwyzmBQa3D4e10qh3tPW76ls5Sv/2s5re6p5dlsFDW4fxxo72Hi0EYDMAYRrT06PdmyOReeYLo52+IJ4/MP8N2MyweIbYNLK4X2dQaCqKr9+4yAff3Q9Z/9yLQ++dWi0T0kyzLy5r5YPDjcQZzXz+I2nGJMKXSlKd/KV1dOMLEGTSeH/zp4KwBMfHMUXECL4eCmrlEgkEsnAkeKYZMKytEvewowuLpsVxWnG4zSndI71mcyZcNqd4vGkU7s/H0scC4XC7qjhcI4pCm6TeF1P6zgUxzp0cSy9521Si+H/PmLN/N8AMD17nLjGQOQPgejE2SFEiVk5YeeY2xugvt2LQoiU46+JbWdfEd7fpjvHhBg00XLHWo5uA2CfOglQeOqjMhq0rKj0GK7WyLLKHcebCYZU8lxx5LrC2U/jOZAfYIrmziqpcxPS2lNWNHXiC4SwWUzE20THyFd3CdH9c6dP1rZvR1XDItppWv7O7946xD83HjOOr4tq/Qnj15ncxSk2FsWxJIfFcMQNe2nlOOBovZvfvnWITaVNHK138+Dbh2kazjw2yagSCqk88MZBAG5aVWQ4lfvKJfNySE+w09ThZ0NJA95A0MjvG+uB/BKJRCIZOFIck0xY8lPijGyIeJuZ/JS4qOdPnRIWItKlc6x/nP1t+KoWFN+VWN0qOxtFRzMAZ2b3fYYAj0Xc/PraGobl+MOKWzvn+LTet0uZxJ5GcdnuKvaOaZxpokwSoGILlK3n9PI/YibI/qo2o6TydEcppvYakVsXWb5rCzvHvv7vHZz5i7WUDrJT4VjCX7ETgH0h0dziwXcOo6pw7szMmG6HghQhxmw/3symUhE0vWRStFM2shzTaRt/4lhBajwWk0KnP2h0iTOy1dKdhsuj0x/EpMAnl4rfXUVzJxXNnbR5AigK/PLjC4i3mdlT2crh2rALzXCO9TOMHyA53kpaRE7lpDFYVqkoyqBLK4fdcTaC6O7KaZkJzMhKxBcM8eLOylE+K8lw8freavZVtZJgt3CrFrrfHyxmE+fPEV2hX91dTa1WUmmzmIy/K4lEIpFMPKQ4JpmwKIrCKVpp5fSsRExdcmVmZicyOd2JK95KXhfhTHICFAVcBbEzZPRA/khxTA/jj083cqSGGq9VtC8PuBuH5fjDhqr2zTmmcaBaG+SNJ3EMwmWSpevgmRvJ2PpbLrJspc0bMErgrnJsEdtMv1A0IdCxCfHBiYcDNUJM+85zuyaMg8zRsAeAmvjpgPhIANx5/vSY218wR7gv1x+p57U9wjl1SlHP4th4zJ6xmk2GI0vPGdPFsSkZCYY4BjAvL5mitHiSHBZUFd7RukjmueLITnbwqeXhjrp61qQvKEqlMgdYImWUYCl0m3gZK+illQMRx7aUNTH3+6/xmSc2Uq919RzPHKgW5duLCl18clkBAM9sLh/NU5IMEy0dfv7fq/sBuHlVkdGcor9cqF1n39hbTWWzKPvPSrKjyOw8iUQimbBIcUwyoTlfu7nRS2siMZkUXvrSaay96yzix6GzYswSq6xyOPPGNAJ2FwCh8SaOedsgqA1e408sjunh6+PKOQbh0sqNfzRKbFenCNH0zx+UAiqnBz4U28y6LHrfiED+BLsFu8XEB4cbeHZrxQic+DCjqqS1i/yjSXOWYzWLgdcl83OYk5scc5fCtHgWFboIqbBXy2w7ZVJ0Gfl4D+SHcO6Y3tFUD+cvznAaz4EokVcUxVj31j7x+dIFrFtPL8ZmEbc7X1k9Leo1BuIcizx2risOu2VsZrrpDpeBlFW+d7COQEjlvYN1XPzb97t1DR1v7NcmFWZkJ3HFwjysZoVdFS3s10QzycTAFwjxxb9vobShg9xkB58bgGtMZ0VxGkkOC/XtPn76yj4A8l1jr4RaIpFIJEOHFMckE5rLF+Ty+tfO4MvnTov5vNNuiRpESoYAvVulL2IwpTvHhiNvTCPkEM4ZpbN52F5jWHBrGWnWeLD1fuNd3+6lwe1DUWBqZkKv2445dOeYv8NYtSxOlDVVt3qYqlSQHqgGSxxMXR29r/aZyo0P8peblxkCx09e2Tf+S79aK3GGWgmoJjKLF3DlwjzSnDa+fl5s15jOlQvzjMeJdgszumTQ6ZljNrPJEIbGG3pTlVd2ietHpHOsOMI5pudH6h0u1x8RZcq6gJWZ5ODJm5by4HWL+OSysIsMBiGOaa81FvPGdAbjHNNLUC0mhdo2L3/bUDak5zbS6ALrzOxEUp02zpkpyvsffOuwEbguGf/8+s2DfFjSgNNm5vEbl8bs9ttXbBYTq2eL0sod5S2YTQq3nz1lqE5VIpFIJGOQ8XnHLJH0g+lZieN2cDguiekcG8Ywfg0lTgykzd6mYXuNYaFDyxvrQ0nlQc39MCk1njjb2HSr9EjGLLBGZzNldxwynFJTFC3/J2t2d5FQE8dOK4xjyaQUbj29mMxEO41uH1uPNREMiU50ennmeEKtFnljh9U8CjNT+MXHF7DpO6ujnFGxuGR+jhG4vrDQZTzW0fMWe+rQNh64cmEeJkWU+K0/Us/2482AuKbrQpjZFC6fn6L9znSxI7L08tQp6Vy2IJcEu4WiCEFroGWVl87L5ZRJKdywomhA+48ERubYAILnD9WKa81p08R1Sc9cGk/88MU9rH7gXY41dBi5hrqI/NlTiwB4eVcVH//Dh9S1jb/3J+nOO/trAfjB5XOMpi+DQS+tBPh/V8/j9Gm9dJSWSCQSybhHKgYSiWRoiSmODb9zzOwUZWU2X8vAD1KzB349F97+STj4abhxa3ljvZRU+oMhfIGQ4X6YPt5KKgHMFshbLB7PuAQAU3sVF08R4s1kRSu9TY0xM69ljuluRKvZxHLNLbSltInX91Tz27cOcfd/do67HLKO4zsA2K8WUpAqRJuu+YixSE+wc4YmXER23tUpSI3nt59cyO+uWzh0JzvCZCY5OHO6GIx+/q9b8AVCLJucyqycRObmJvPpFYXcc+FMEh1CBNI7XOpEimORRA6as5IGJh4WpsXzn9tO5cK5w3dNGyx61lJTP8sq/cEQR7WGF/pna7zljtW3e/nrh2Ucrm3nvpf2oqqi8Y7e/fXUKek8/tlTSI6zsuN4Mw+vPTzKZywZLKqqUt4kssEWFaacYOu+cc7MTL5wRjG/+vgCPn5KwZAcUyKRSCRjFymOSSSSoSVeyz7ytUOHlv9lZI4N30DSmiAGcY7AIMSxI29Dy3F47+fwxvdGRiA7QRi/2xvgnF+t5aLfvmc4Z7qW0I0bzrwbpl8EF94PKUUAXFso/r+KDHEsRkaMvXuprl5yt6msiXcOCLdAdauH442dw3Puw4Snci8AlfZiHNb+uQF/ctU8vn7edG5aVRTz+SsW5rGkSxbZeONjS/IBaPcGALjnopkoioLJpPDjK+dx6xnhz0tXt11xemz33WxNHFMUDLFkIpIywLLKsoYO/EGVeJuZ+Xki924siWOhkMpPX9nHf7f0HKj/yq4qgiFx/X5Ty6Dret08d1YW379sNgC7KwbxvSEZEzR1+I3rxFA1ybCYTXzr4lnGdUgikUgkE5vxmdIrkUjGLnEpkDET6vZD6fsw+4oI59jwBfLbE4U4Fh9qO8GWvdAREea//neQOQsWXj/IMzsBJ3CO/WdLuSH46IHk465Tpc7kM8Q/gKy50FTKKY4K8lPmMNNbDyEgLZZzTBM5vGFxbMkkIY5tLWvCaQ+LShtLGykcwzlQXVEahGPFk9z/4OhcVxxf6iFPcaKwelYWSQ4LrZ4AF87JZnEvjpBJafGYFAipYDUrPXYh1p1jqfE2rOaJO0c40LLKw1pJ5dTMBKMst2EApZnDxYaSBv74XglxVjNXLMzFEuP/8Pntld3WzcjqXmY3O1es21/VhqqqshPhOOa4VjqblWTv90SDRCKRSCQgnWMSiWQ4mHymWJa8K5Yj4BxzJAtxKUltxx8cYMCynv9l0QbVpev6vq+3DTY+Bk39DK42MsfCpXGdviDHGzsIhVT+/MHRbruMu06VscieB4Ctbi9rvnoGC+K130Ms55jR5MFtrJqZnUSC3UK7N0BNRB7S5tJx1K1UVXG2lwJgSp86uucyRnFYzXzjghksKHDx7Ytn9bqt3WI2SlMnpTm75bDprJySxpJJKXxqeWHM5ycK+Snid7GnspWQ5qJq9Zy4xPJQjRChp2YmGM665g7/wK+rQ8zmMpEr2ekPGl0oIzne2MGWsiYUBc6aEc6ImhnDcVucnoDFpNDmDVDRPL5cp5Jo9Fy5wtTxMzkikUgkkrGFFMckEsnQU3yWWJashVAI2vVA/uFzjjmShDiWrLTT5gkM7CCdmrCSM18sm4/1fd9Nj8Mrd8Gjp8He5/u+n96t0hkexN3y102c/vN3+PTjH1Ha0EFynJUVxaI8zmJSesxSGldkzRXLml0kKF6Uds1dGFMci84cAxHEvnhS2EWUaBdG6I3jSRxrr8UedBNSFdILZ4722YxZblhZxPP/t6pPjkC9i2VvfyNOu4X/3nYqd54/Y8jOcSyytCiVRIeF2jYvW4818cf3jjD/B6+zZndVr/sd0jpVTstMJDnOaoiMjWPEPbYp4m9867HuDVhe3ClcYyuL07j9rLDoHKsc3WYxGZ1/D8QQ2iTjB10cK0iR4phEIpFIBoYUxyQSydBTtAoUEzQegartoAYBBZyZw/aSFi2QP4V2Wjv7F0Bt0KENtHIXiWV/XGCV28TS2wr//gzsea5v+3Upq9x6rIkPDgsX1fojYnndskJ+fOU8kuOsnD4tfWJ0X83WxLHa/VB/UDyOSwln1kWiN3nwd0AoaKxeGiGO3XK6ENVK6txjKh+pNwJ14n2Xq+mcMmXsBruPJ/SSyVguoZMNm8XE6llZgCjP/v3booT31d3Vve6ni2PTsxIwmRRStWD/sdDRMRhS2Xas2fg58jFAhy/AX9aXAnDFwlyWFqVw1owMFuQnMzMn9mdC/6zEcqFJxg/lTZo4Jp1jEolEIhkgE2CEJZFIxhyOZMjVOhPufFosnRmiY+FwESeEkjjFR1v7AAc5eomjLo61VkCwjy60mj3R+254pOdtVRU++B0c39QtkP+JdaKMcllRKukJdtKcNm48tYipmQmsv+ccHv/s0v68o7GLaxLYkyHkh13/EetiucYg7ByDqNLKU4rCQtqVi3KZniUcIJtLu7tJxiKVJbsBOGbKY3qmFHOGgi+cMYX7r55niKUnO3o3zX9tOk6r5qjdoTX2iEUwpHKkLuwcg3DTgrGQO3agus0IXQcxmRAKqbx7sI6Gdi9/fK+EmlYvBalxXLkoD0VRePKmZTx/x2nYLbFzqGZkC0F1X1XriLwHyfBgOMekOCaRSCSSASID+SUSyfBQfBZUbIbtT4mfhzFvDAB7EkFMmAnR2dIADOD19LLKjJlgtkPQC63lRmfFHvF1CJccwKW/gcfOhuMboP4wxMqSOvoevPFdcBWKslMgFJdGZVOH4er4weVzmJaVQKc/SJJDBGs77RPokq0oMONCIZ5uelysS40Rxg9gcYBiFg5EnxscYjC7eJKLZUWpZCTZmZTmZGlRKgdr2tlU2miIAmOZpmN7KQQ8SZMx9ZCPJekfyfFWrls2sbPE+sOZ0zOIt5np8IUdl6UNHTS5faRojrBIjjV24AuEcFhNRkOD9ASxXcMYcGRuKRPX6AX5yewob6GsoYPvPLeLf248ToLdQkC7nn7rolk9imFd0R1lsqxyfCMzxyQSiUQyWKRzTCKRDA9TzxVLrzYbrwWwDxuKQrtJDHI8bfX9319VDedYTSiBQJLWur0vuWN1+0ENidLInAUwdbVYv/0fsbdvOR4+dms5AOf/cS+n/ewdgiGVlcVpzM5Nwmo2GcLYhGT+J8QyoAVh9+QcU5SIUP5w7pjdYubfX1zJQ9cLl+LCAhcwfhwgofpDAMRlT+zsK8no4bCaOXuGKGdPT7CTrwleO8qbY27/3y3iejQzO8nIGkvTRLSxUK68SXOFnjMzy8gK++dGcT1t9wbw+EOcMimFi/ohjs/SnGMl9W48/uAJtpaMRQLBEJXNHkCKYxKJRCIZOAMSxx566CGKiopwOBwsX76cjRs39rr9b37zG2bMmEFcXBwFBQV87Wtfw+PxGM//4Ac/QFGUqH8zZ8pwYolkXFO4Eq58BC78GVz/DFz662F/yQ6zGOT42xv6v7O3DUKiXOfM3+/kg3qtlK8vuWN6SWXWHCHkLPyU+HnHv6Iysgz0BgURVPrF61lMCl865yTpXDj5LEjICv+c1oNzDMDeXRzril5OU9Xi6XGbsUIopJLcIYTX7OK5o3w2konMzadNJivJzrcvnskpWk7fjuMt3P/qPj72yHojaL+6xcOf1pUA8MUzw3+LRlll++iXVW7ROlWeUpTC4kKXsf6cmZn8+toFXL4gl198fAGK0ncnZlaSneQ4K8GQyuHanq8vkrFLVYuHYEjFZjGRmWgf7dORSCQSyTil3zU6Tz/9NHfeeSePPvooy5cv5ze/+Q0XXHABBw4cIDOze9j2U089xT333MMTTzzBqaeeysGDB7nxxhtRFIUHHnjA2G7OnDm8+eab4ROzTKDyIYnkZERRYOH1I/qSHksS+CHoHoA4ppVUdqo2PNgpV7XukX1xjhnimCZyzLhIZKC1VULJO2EnmU5btDjmU+x0YOfuC2dw86rJOKx9Kwca95gtMPca2PCQ+LmnskoI5455ex685rmEK6aiuRNVVfs1QB5pDlQ1MUWtBgUmTZ8/2qcjmcAsmZTCR98W16DWTj/Pba/k2W3llDWIMrQ/vlfCPRfN5NdvHDScVxfMCYvWaZo4VjfKzrFGt4+KZuEyXVjg4lhjB//eXI7dYuKHl8+hIDWeqxbl9/u4iqIwMzuRj442squihbl5yUN96pJh5rhWUpmfEidL1CUSiUQyYPrtHHvggQe49dZbuemmm5g9ezaPPvoo8fHxPPHEEzG3X79+PatWreL666+nqKiI888/n+uuu66b28xisZCdnW38S09PH9g7kkgkJy1+qxjUhNwDCGTXSiqbSCA9wc5xQxzri3NMBKuTNUcsLXaYc7V4vPf57tt3cY61mJIBhTxX3MkjjOnopZUAqZN73k4vq/zvLfDbhdDWveNeVpIDRQFfIDQmwsN74+CBvdiUID7FhsVVMNqnIzlJWFgonGO6MAbwtw9L+d+2cp7ZIsoTv3XxrChhOZw5Nrp/U6UNohlHTrIDp93CZQtyuXxBLg98YuGgQ9hPmyruOR999wjegCytHG/IvDGJRCKRDAX9Esd8Ph9btmxh9eqwC8JkMrF69Wo+/PDDmPuceuqpbNmyxRDDSkpKeOWVV7j44oujtjt06BC5ubkUFxfzqU99imPHendreL1eWltbo/5JJJKTm4BdiGOKZyDimNinWU1kQX5yz86xUAie/Tw8/38ip0xVo8sqdWZfLpb7X+7e8bK9NurHJkQ5aJrzJCwHyVkA59wL5/0I4lN73k53jrVXQ9PRmHlukSU1lZrDZKzirz0AQKO9AEwy/lMyMszKScRmFp83q1lhcroTty/I157eQUiF65YVskQrvdTRyypHO3PsmCboTUoTAkiC3cLvrlvEJfNzBn3sm0+bTGainbKGDp78oNRYv6u8hV3lLYM+vmR4MTpVpkhxTCKRSCQDp1935PX19QSDQbKysqLWZ2VlUV3dfRYf4Prrr+e+++7jtNNOw2q1MmXKFM466yy+/e1vG9ssX76cJ598kjVr1vDII49w9OhRTj/9dNraeu4cdP/995OcnGz8KyiQM+8SyclOyCEGdWZPc/931pxjjWoC8yLEMbVr5lj9QdFhcdvf4dDrwsHU2QiKSXS51Jl0miit7GiAY+ujj6E7x3IWAFAXEq6o1Bjd4yY8igJnfANWfbn37WZfAckFMO188fOOp4Uw2YWcZFFaOdbFMWtLKQDuBNlZUTJy2C1mZucKMf66ZYV888JwM4jlk1P54eVzuu2TNsacY0VpziE/ttNu4e4LxfX7wbcPU97UwebSRq56+AM+9sh6SuvdQ/6akqFDb8IyOX3oPxsSiUQiOXkY9unqtWvX8tOf/pSHH36YrVu38uyzz/Lyyy/zox/9yNjmoosu4uMf/zjz58/nggsu4JVXXqG5uZl///vfPR73W9/6Fi0tLca/48ePD/dbkUgkY5044Tyy+AYw069ljjWTyOycJCrQnGNtVfDeL+GvV0BnM1TtCO/z3i/g8Bvicdo0sDrCz5ktMOMS8XjvC9GvpYtjZ9+LmruIf/rOFIdIOAnFsb6y7Fb42m742J/AbIf6A1C9UzynqrD5z1CxJSJ3bGyH8pvcdQCEnH3vqieRDAXfuWQWn105ia+fN4PzZ2dz/uwslkxK4dFPL8Fm6X5baATyu72oMQTpkaLMcI4NjwBy9aI8FuQn0+4NcO0fNnDHU9sIhFR8wRC/eP3AsLymZPAEgiGji+myyb24jyUSiUQiOQH9Sr1PT0/HbDZTUxOdl1NTU0N2duwb/O9+97vccMMN3HLLLQDMmzcPt9vN5z//eb7zne9gilFO4nK5mD59OocPH+7xXOx2O3b7SViCJJFIesQUL5xjdv8AxLEOIY41qoksTHZgTcykw2snXvHC25qYv+9FqNsf3qd8E1RsFY/1MspIZl8O2/8u9rvo56J8ztse7rhYuILmT73OSz8SAltKvBTHTogjWTQ82Psc7Py3cN8deBVe+iqkTSO3+K8AVI1155hXfN4siRmjfCaSk42lRaksLQqLCH/8zCm9bq87Wv1BldbOAMnx1mE9v57QnWN6WeVQYzIpPHrDEj712EeUaE6x/JQ4Kpo7eXlnFbec1sSiwpQTHEUy0uyubKXdGyDJYWFWTtJon45EIpFIxjH9co7ZbDaWLFnCW2+9ZawLhUK89dZbrFy5MuY+HR0d3QQw6oF1ugAARqNJREFUs1kETvc0A9ne3s6RI0fIyRl8joREIjl5sDjFgC8u0H9xTI0I5E9LsJOXGk+52qUxSNkHYedYonZ9UoPCIXbWt7oftPgssCeJnKyKLWKdW8sbs8aDPdEIjk90WGK6NiQxmH+tWO56RuS57dOceQ2HKHL6AahsGdvimMMnnA625KwTbCmRjC4Oq5lEh5hLHc2OlWVdMseGg5zkOP71hRXMzUsiPcHGn29cyscWiw6Yv5TusTHJhhLx3b28OA2z7FQpkUgkkkHQ75HYnXfeyWOPPcZf/vIX9u3bx2233Ybb7eamm24C4DOf+Qzf+lZ4kHjZZZfxyCOP8K9//YujR4/yxhtv8N3vfpfLLrvMEMnuuusu3n33XUpLS1m/fj1XXXUVZrOZ6667bojepkQiORmwJQoxKz7Uc15hTwTa6wFoVhNIc9rIdcVRpmrChTNTLEvXhUv5Lv0NxKfD5DNEqZ8pRpdJix2mag1MDr4qlnoYf0ImKAqNmjiWdjLmjQ2UqavF7769RjjIDrxqPDUtVAKM7bLKYEglMdgMgDNFllVKxj56aeUL2yt46J3D+IOhEX39Vo/fuFYOV1mlTmaigxfvOI113zyHaVmJfOGMYgA2lzbFnNRds7uam5/cNOoNC05WPjwixLEVxWmjfCYSiUQiGe/0q6wS4Nprr6Wuro7vfe97VFdXs3DhQtasWWOE9B87dizKKXbvvfeiKAr33nsvFRUVZGRkcNlll/GTn/zE2Ka8vJzrrruOhoYGMjIyOO2009iwYQMZGbLcRCKR9B1HkhDHEgckjjVgBdzmZBxWM3muOH4XuJqkrCKWX3cv/H4ptGjZhmYbTD0X7joogvgVBY8/yJv7alg+OY2MxIiS7+kXwp5n4eBrcO73RIA/QIK4Zja6xYDqpAzjHygWGyz9HLz7M3jlGxDRgKHAcxCYO6YD+RvdPlIQAdIJqdI5Jhn7pDltHK1387u3RdzF3Lxkzpw+cvdoeqfK9AQbCfZ+37r2G0VRcFjFhEdBqnCqeQMhmjv8pERcq8ubOrjz39vp8AV5YXslN582edjPTRLGHwyxuVSUqK+U4phEIpFIBsmA7jDuuOMO7rjjjpjPrV27NvoFLBa+//3v8/3vf7/H4/3rX/8ayGlIJBJJFPHJ4uY4iXYCwRAWc9/NsXpZZUgL9c9LiWOXWswfE1awPG0K5C4Ml0ZmzgZzdO7O3zeU8eOX95Fot/D186fzmZVFmEwKTDtPCGg1u6H5eIRzTIgielllqlNmKPaLpbfAul8bjRQw2yDoI7VlLzCXujYv3kAQuyWGo2+UqWvzkqcIccySmDnKZyORnJisJEfUzyOd6RfOGxv5boQOq5lUp41Gt4/qVo8hjqmqyvee30OHLwhASX37iJ/byc6uihbcviCueCszsxNH+3QkEolEMs6RATcSiWTCEO8SQoNT8dLW7u7XvkqnyIBS4oU4lmt0PdQGgZNWhTfOWdBt/41HhUjT5g3wgxf38o+PyrSTSoWC5eLxwTXhTpW6c6xdllUOiIRMmP+J8M+n3AyArW4ndi27raZlbJY51be0kawIJwxO6ZCWjH2+cGYx155SwHKtG+BIlxCORN5Yb2Rr4mB1S7hc+9Xd1by9v9b4uaSuf985ksGzRe9SWZQqJqMkEolEIhkEUhyTSCQTBktcMkFV3CC7W+r6ta/VK26yzU5RmpnfVRwrOi28cc78qH1VVWX78WYAzp0pBLq/bzgWzqeZfqFYHnytmzhmOMcSpDjWb1beIVx5Dhes+goASmMJ05JFHlLFGC2tbG0Un4Eg2rlLJGOc+fkufnbNfBZPEt0a6zVRf6Qo051jqSPvHAPITtbEsVYhjgVDKr98TQT06+WlUhwbecqbhGg6JTNhlM9EIpFIJBMBKY5JJJKJg8lEmyJukjta6vu+n68DS0g4IfRQf9051uYJ0OrxQ+EKIcQAoaz5BEPhYObqVg+1bV7MJoWfXj0Pm8XEgZo29lSK0jlDHDv6HtQfEo8ThIgmA/kHQeYsuPk1uOlVSMqF5EIAVsaJbLixmjvmbhK5cx3mZDDJr2HJ+EEP5h/prpWlmnOsKH2UnGOaOFalOcde3FFJSb0bV7yVn149DxDfA+3ewKic38mKLlZmdyn7lUgkEolkIMi7colEMqFoN4ncEW9bQ9930nKr/KqZhCQXAE67BVe8yBWrbO4ERzKccy/BhTdw/tNtXPnQB4Q0gWz7sWYAZmYnkpXk4LzZwhX2ny3l4vgZM0ROWdALxzeIdYmiS2GjkTkmxbEBUbAMsmaLx7mi3HWBuRQYu+KYr0U4xzptqaN8JhJJ/0jXHK71bSMnjoVCKkdqRZ5XYerollXWtHgIhlR+97aY5Lj19GLyXHHG7+WodI+NKNWt4nPYNRNPIpFIJJKBIMUxiUQyoegwJwHgixDH1FDwBDuJbZtIJC0xfJOdp7nH/vphGe8erIPTv86uJT/mcIOHXRUt7K8WXTH1ksoFBS4ArlmSD8ALOyrxBUKgKLD8i9GvqTnHGqQ4NnTkLARgWqgEgMN1YzMgO9gmSn4DDimOScYXGZpzbCQzxzaVNtLg9pFotzArJ2nEXjcSwznW6uH1PdWU1AnX2GdPLQKgOF04lmUo/8hSozn59P8fiUQikUgGgxTHJBLJhMJrEYOnoFsIXlv+91s67stl3/qXet6pTZS5NakJhgMAYHK6yLd56qNjfPaJjWwqbWRXRYvx/IYS8Rq6OLZQE8dOn5pORqKdRreP9w9p2WfzPwFxYTHk22/U8szm4zS6xSAzTXarHDwZMwHIDYn/z81aWPNYQ++MqsanjfKZSCT9Iz1RXKd0UX8keGFHJQAXzM3GYR2d7rORzjH9un/VojwS7KLpe3GG+K44Ip1jI0YwpBrlvbKsUiKRSCRDgRTHJBLJhMJrTQYg1CGEkbj9/8WJh5a9b/W806E3ANgRmhLl4PrmhTP54plTmKaF/b5/qJ49EeLYhyUNBEOqIZjp4pjFbOLCOaJs8t2DmjhmjTM6Kqoo/Hufh/te3Bsuq5SB/IMnWTj2nJ4qTIoI5I/sLjdWsHaKwbU5QXaqlIwv9Myx5g4//mBo2F/PHwzx6m4hdl++IHfYX68ncozMsU52a1mS+vUeIsUx6RwbKRravQRDKiaFqEktiUQikUgGihTHJBLJhCJgdwGgdDZBKEShV2TDWDp7yCALhWC/cJW9GloW5eAqSI3nnotmctOqyQBsPNrA7sqwOLbxaCMHqtvo8AVJsFuYkhHumHXaNBHsv+5QRGOApbdAfDoNrnkEsNDmDeAPityy1Hh5cz9oXCKQ3+SuZX62GMxuLmsczTOKicMnzsmWnDXKZyKR9A9XnBWzSXQEbhiBjpUfHK6n0e0jzWnj1Cmj57TM0sSxVk/AmAyZk5tsPG+UVcZwjtW1efH4T1DaL+k3ehh/RqIdi1kOZyQSiUQyeOS3iUQimVCEHC4ATJ4mGo7vJQHR5czq7UEkqdgCbVW0qXF8EJobcwZ62WRRDrntWDMHtJwxi0mhpdPP91/YDcCiQpcxaARYOSUNs0mhpN5ttJsnKQe+vJWnZj8adfw4q5k42+iUC00o4lLAKgK7z84WA/exVFrZ7hWdTxNDYnAd78oc5TOSSPqHyaQYnXVHInfsxR1VAFw8L2dUBZBEuwWndo32BULE28xG2T2EnWNH69uNRi0g3Kur/t/bfPKPGwiMgNPuZEJ3BcswfolEIpEMFVIck0gkE4u4FACsvhZq930YXu2PFsdC/7uN4F+vho1/BODt0CJ8WEmJEYw/JcNJmtOGNxDCH1RJjrMazrBNmvjy5XOnRe2T5LCyIF84C6LcY45katzRgyQZxj9EKAokFwCwNFUIklvKRl8c63jvQd7+07dY/KPXOeeX75KqiLIsu3SOScYhaVppZd0AxbFfvX6Ae5/bhaqqvW6nqirvaZmNF83LHtBrDRWKokSFvs/JTYqaDClIjcdiUvD4Q1S1hku5d5W34AuG2H68mX9uOj6i5zzRqWmV4phEIpFIhhYpjkkkkgmF4hSiVZqnDP/xzcZ6ZyAskqieFkw7nsJc8hbs+jcAa4JLccVbscZwJyiKwtKicJj+vLxkVhaHS3yuW1YQ9bzOadNEptT7h+uj1te2RQ8q02ReytCh5Y7Nim8GYG9VK25vYNROJ9hWS/zb93JO+cOcF/qQ+nYvaQhxTHHKzDHJ+EN319a39V8cq2vz8uDbh/n7hmOUNnT0um1pQwd1bV5sZhOLC1MGdK5DSbQ4lhz1nNVsojBNuFZL68OllTURQtkDrx+guWPkGhlMdGpaZRi/RCKRSIYWKY5JJJIJhX3GaryqlQL/UYqq1hjrk4LhrLD2+oqofYJmO++GFvTq4NJLKwHm5CVxxvQMFEUEVN9z4ayY+5yhucs+OFxPMKLUpk4bVOanxAHSOTakuIRzLMVXS26yg2BIZYfWTXQ0qDu0yXj8q6R/cvG0ONI05xiakCuRjCcyNOdY/QAyxyKdnJXNnb1uu+mocPsuKEgetS6VkWQnxRmP5+Yld3s+P0WIYxVN4fdVHSGONXX4ufs/O+n0yfyxSI7UtXP579fx3y3l/dpP/91GipYSiUQikQwGKY5JJJIJxcLpxbxjWQVAUqjZWJ+IGwJiMOfWxLGyUCa/Nd/IT+K/SQcOlk/u7v7SiRTH5uUlMysniX/duoL/3X4qyfHWmPssKHCRYLfQ3OE3QpwhLI7dc9FMVk1N4zMrJw3szUq6oznHaDnOoknCbRLZRGGkaSvbbjx2eOp4KP1/JCuaYyZeimOS8Ud6oi6O9d85trk0XN5ecQJx7CNNHIvlyh0NspPDzVrmxRDH8lxCpIl8X3ou1rkzM7GYFF7fW8M1j66nqqX3934y8fA7R9hZ3sI9z+5k27G+l8HLskqJRCKRDDVSHJNIJBMKk0mhefYNxs9tahwBVVzqQm5R3uhpEuJYFWn82n0+T9TNJNFh4c7zZvR43Fk5SaQn2LGYFBYWuABYXpxGQWp8j/tYzSbOmC4EkDf31gAiR0cXxxYWuPjHLSs4Z6bMnhoykkXHSpqPGc68qhZPLzsMM9W7ANgXvxQAZdtfxXrFZOTjSSTjCaOsciDiWIRzLNJhFYtNmpC2rJdJi5EkO1lcT+wWE1MynN2ez9Wer4whjl2+MJe/37KcNKeNPZWt3P6PrTKgH2j1+Hl5VyUA/qDKHU9t63Ppqf67lWWVEolEIhkqpDgmkUgmHKeeeRF7Q8KNtV8ppolEANyN1QD4W0QHtFrVZexz1/kzyEi00xNmk8JTty7nn59fYZTP9IXzZgvh6/W94rVbOv34tEFRb68nGSBaWSUt5eRog6bI3J++8rcNZaz6f2/z2p7qQZ1OYvN+AA4WXQen3Bx+Ij4NTPIrWDL+SNfKKhv6WVbZ6QuyO8JB21tZZXWLh2ONHZgUWDJpbIjIxVp3ygUFrpidM/M0Mb6ypXtZZVaSgxXFafzv9lUkOixsO9bMQ+8cGYGzHtu8sL0Sjz9EcYaTorR4Kpo7+dP7R/u0b7isUn6PSiQSiWRokHfmEolkwlGY7mRN6qcJqQp7U86mEVEC09EshI5Qm3BxhZxZFKbGs7I4jU8tLzzhcadnJfa7xOfsGZmYTQoHa9opa3AbrrHkOCt2y+jn6Ew49LLK1gqyk8SgaSDOsY1bt3JG20t8/e/r+PMHfRusdcPvIcNbBkB84SI4/8eQWiyekyWVknFKesLAyip3lDcTiMherIxRWni8sYM7/72dn76yD4DZuUkkOmKXrY80K4vT+O0nF/KLa+bHfD7XJcQx3RGnqqrhbsrRcrEK0+L58ZVzAfjd24fYWd48zGc9tnla6+B5/bJCbj97KgAfHW044X4dvgBtHtFoJVM6xyQSiUQyREhxTCKRTEiWXHwTS0J/wbnqi7SZhTjmaRaimMldC4CSmM17d5/NU7cuj+kEGApc8TYjy+yNvTVGp8pM6RobHhJzRcli0Ee+rQ0Il9/0h080/ZH7rY/zivUeXn3pv+yrau3/udTtx0yIJjWBvIIpYHPC1Y9BXCpMO6//x5NIxgADFcf0MH792herrPIXrx3g2a0VvLBDlNqNlbwxECX7VyzMY1Ja95JKgDyX7hzzEAqptHYG6PSL8P3IXKwrFuZx6fwcgiGV3755aPhPfIyyv7qVXRUtWM0KVy/O5xTNIbijvAVvoPemBXqnynibmUS7ZdjPVSKRSCQnB1Ick0gkE5Izp2ew9b7LueaUAtrN4qbb31YHgK1TiGPB+EwAFEUZ1nMJl1bWGM4xWVI5TJgtQiADclXx/13b5o3qFtoXUgPiM1JoquNvtvvZv3dHv0+l/dh2APaphUzOSBAr80+BbxyG83/U7+NJJGOB9ESROdbo9vX6d+UNBKM69eoZYpfOF3+fuoik09LpN8qYlxWlMjndybVLC4blPQwH2ckOFAV8gRANbp9R9pcSb+3WbfPr589AUeCt/bUcrGkz1pc1uDne2DGi5z2UbC5t5MLfvMfb+2tOuO37B0UG6OnTMkh12pic7iTVacMXCLGnsvfJiMi8seH+/pZIJBLJyYMUxyQSyYRFv2n22IQ4FmoXgofDI0QTEkcmCF8XxzaXNhoDIekcG0a03DGXvxazSSEYUvvtckkMicGZxxSHXQkQKFnX79No1zpVHrdOIc4WMTg2yXJayfglNd6GokBIFQJZT/zurUN86k8f8Y+PylBVlZ3lIm/s4nnZUSKSzss7q/AGQkzLTODpL6zgnbvOYmZ20rC/n6HCajaRlRjuWKl3pIzVTXFyupMLZmcD8OjaI6w/Us+tf93Mmb9Yy8W/ex+Pv3fn1FjEFwhx9392sr+6jV+/cWJHnF4+uaJYuAMVRWFxofiu3lIa3bUyEAzxgxf28OOX9uL2BvjL+lKAXhviSCQSiUTSX6Q4JpFIJjw+h3bz7RY34wl+sTQnZ4/I6+enxDMtM4GQilEuJJ1jw4iWO2ZqPW6IkP3JHfP4g7hoB6Ap7RQArPX7+n0aphrRqbIleWa/95VIxioWs8korTzWi8vp/UPCGfRRSSN17V4a3T4UBebkJkeJSDr/3VoOwDVL8setG8gI5W/uNBqBZCfHzsT6wpkif/DZbRVc/9hHvKF1NG7zBKJ+L+OFv6wvpaTeDcCuihYO17b1uG0opLLxqHASLp+cZqw/pUiIY5vLGqO2/8XrB3hyfSl/WneU0372Nmv2VGMzm/jyudOG+m1IJBKJ5CRGimMSiWTCE3SIm29zZz34PThD4qbd5sodsXNYNVUEsJdrOTuZiTJEeNhIKRLLI28bofz9yR1rbusgSRGD/rjpZwGQ2XkYXyDUr9NwtopudGrW7H7tJ5GMdebniRzHHcebo9Yfa+ig0xfE4w+yVyuN21fVyoFqcc0tSnMSZzNHiUgg8si2lDVhUuCqRXkj9C6GHj2Uv7K50xDkc3oQxxYVpnD6NPG94Iq3ct2yAvK130t5jDy2sUxZg5vfvSXcYqlOUXb77NaKHrc/UNNGqydAvM3MnNywO1DPHdtS1oSqipLbN/bW8Id3SwDRyKapww/AT6+eN2Y6mUokEolkYiDFMYlEMuFRnRkAWL2NoIXxe1UrickZI3YOp02N7k4onWPDyMLrwWyDkrWcb9kKQHWMzng90dokPiMhFJJnnQXATKWMg9X9COX3d+IMiNKglFzpbpBMLBYVugDYFiGObTzayFm/fIevP7OdXRUtRmfKow1uth8T283ISgTCIlJ5Uwe/eG0/n/jDhwCcMzNzXHcfzHWFHXG6cyxWWaXOI59ewktfOo3N31nN/VfPZ2a2+P2UNw1v7tihmjbeO1g3JMd6e38Nlz24jjZvgPn5yfzw8jkAPL+9MipTLpKPSoR7e8mklKhmOHPzkrGZTdS3+yhr6EBVVb73/G4Abjy1iNe/dgYfW5zPj66YwzVL8ofk/CUSiUQi0ZHimEQimfCYnUKYivM1QZsoXakjGZc2wz0SLC9OxWwKlwrJzLFhJLUYVtwOwLWNj2LDT1Vr351jHc1i0NhOAkrWHEKYSFXaKTla0vdzaBXls27VTkFOTt/3k0jGAQsLhGNn27FwNtRTH5URUuG1PTW8uTccyK5GlJPPyNbFMSEYPbGulIfeOUIwpHLR3Gz+38fmj9RbGBbyNdGvoqnTcKv25BwDSLBbmJuXbAhE+SkiQ2s4nWNH6tq56uH1fOaJjUYH0d7418ZjnP7ztzmqlUz+a+MxfvTSXg7XtvOr1w9w85ObafUEWFTo4o83nMJ5s7NItFuoaO5kY2ljzGPq61cUp0Wtd1jNzMsXrsStx5podPsMB97dF84gK8nBrz6xgBtWFg307UskEolE0iNSHJNIJBMeS5LoShkfaEJtqwKgVnUZ5R8jQaLDyqICl/GzdI4NM2fcBQnZpHoruNy8npr+ZI61COdYuzkJrHE0OkTAf3Pptt53VFXQcu3UluMAVKlp5MvQaMkEY35BMooiRJy6Ni9ub4DX9ghBLBhSeVILTNc5VCsy/HRnlC4i6R0dv3HBDB759BIjy2y8YpRVtoTLKntzjnVluMsq270BvvC3LbR7AwA89dGxXrdXVZWH1x7heGMnb+6tIRRS+f4Le3h83VFWP/AuD759GIDPrJzE059fSXayA4fVzKULxITAX7p8DvRj6nljyyandnt+rlZmeaC6zcgwy3PFEW+zDOxNSyQSiUTSR6Q4JpFIJjz2ZNEtMl7twNdQBkCtmkJK/MiJYxDOHQOZOTbs2BNh7tUATFPK+xXI728XAlenRQzSvGmzxBM1e3rf8f1fwi+K4cAaOurFoLNSTZNCqGTCkeSwMi0zAYDtx5t5Y28NnREdFr1aPt/CiAkBiHSOxRnrClLjuOX0ycN8xiNDOHPMc8JA/liExTFRVhkI9i/n8ETc/8o+Dte2k+gQQtPLuypp6fT3uP2ROrfRdKGypZMGt8/4vwVwWE385tqF3HfFXGyW8JDiplXi/3PNnmqO1LVHHfNovZv6dh82i4n5mksskqla6e3BmjZKtH2LM5wDebsSiUQikfQLKY5JJJIJT0JyGn7VDECgUnQQbFRcxNnMI3oep2nhy3aLiaQ4OQs+7LgmAVCg1BkOlb4QaBdd9jxWUTrmyBOlXq7WgwR7yNABoELkm3H0PTo1cazRnI7DOrKfM4lkJFgUUVr53HYRvn7tKQXojSbNJoVrlxYY2zusJialCZEjUhy76/wZ2C0T429EbzTQ6PYZwfE5SXG97RJFZFllab2bhfe9we3/2DJkItkGLevrF9csYEZWIh5/iOe39xycv/ZArfG4usVDlZbdmJVk5527zuKdu87iyhgNFKZnJbJ6VhaqCn98N7ocfVdFCwBzcpNi/r9P10TXQ7XthnOsOF2KYxKJRCIZfqQ4JpFIJjwup40GhAvIVCvCfdutab3tMiwsKUzhi2dO4fuXzUFRlBPvIBkcKbo4VktVi8fofnZCOkTJT8DuAsA1eREA0ygzuuvF3K1ZlJV5aw7gbxRllW22rIGcuUQy5lmohfL/b1sF7x8SgvIXzixmaZEolZuZnRjVTXB6VqKRuzg1M4FTp6RxybwcLps/cl2Dh5skhzXK5ZTniuvXRIjuHKtr8/Lc9gravQFe2VXND17c0/frVw+oqmqUa87KSeS6ZUK4fOqjY8axu77G2/vD4lhVi4fKZj1HLY7J6U5yknsW/m47qxiAZ7eV88jaI4YLbI/WxXRubnfXGIjPCQiBcE+F2LY4I6Ef71QikUgkkoEhrQsSiWTC44qz0agmka00YW8S7eY77CPXqVLHZFK456KZI/66Jy2uQkA4x3yBEM0dflL6kDNn8ghxLOQQA3tzzlwApigV7Gttp6CHDLG2pjriAU/VfpQkMTD0OLMH+y4kkjGJ3rFSL1k+b3YWxRkJfHrFJDYebeS82VlMTndiM5vwBUNGp0oAq9nEU7euGI3THnae/79V7K1sxRcMMTM7qV8TIclxVhLsFtq9AZ7bFnZ0/X3DMSalOrn1jOIBn1ddmxdvIIRJEc69qxbl87M1B9hf3cZz2ysoSnPy2Sc2kuK0cdHcHC6Zl8OmiED9SOdYb00GdJZMSuW0qemsO1zPz9bs51evH+Dtr5/FrnLhHJuXF1scS3HaSE+wUd/uM5xusqxSIpFIJCOBFMckEsmExxVv5SM1j9mUYQr5APDHjbw4JhlhtLJKl+ImkQ6qWjx9EscsnmbxIF5zFyYX4MGOQ/HSXnMUijJj7hcXEIO+RE8FqiLKhUIJ3UuOJJKJwLRMUTpX2+bhc6dN5pJ5IoT98gW5LCpwkZPswGI2MS0rgT2VrUbe2EQn0WFlefHAnMmKopCfEsf+6jZKG0TW19WL83h2awU/fXUf+SlxXDRvYN1vj2s5ZjnJcVjNJpLjTdxxzlR+8doBfvzSPqxmE62eAK2eAI++e4RH3z0CQKrTRqPbR22bh+ONncYx+sIfbljCf7aU88QHRylr6GDNnip2V2pllXlJPe43LTOR+vYGAloZu3SOSSQSiWQkkGWVEolkwuOwmvmheitPBC4kpF32OhKLRvekJMOPPcEQuPKVul5LIqN28zcBYE7QBriKQotFPPY29ZDPEwrhDLUBYELF1SkaPyiu/IGevUQypjGbFP702VN44Y7TuGJhHhZz+JayIDXe+PnzZxSztCiFyxdMnPLJ4UQvrQRw2sz8/GPz+czKSagqfOXp7az46Vss+8mb7K9u7ddxdWEr8vi3nl7M1MwEGtw+qls9TM1M4LefXMg5M8MTAFctysNiUgipsKO8GYBcV9+aDDjtFj57ahE3nVoEwN82lNHmCWAzm4zyyVhMywqLYQ6riZx+dPyUSCQSiWSgSHFMIpGcFFjjk7gv8Bm+l/sY1/m+Q8A1ZbRPSTISuMK5Y6UN7j7tojvAbInh7qJum3jsb6mOvZOnGTPdQ7MdaYX9OVuJZMJxxcI8nvniqWRKgaNP6KH8AEuKUrGYTXzv0tmcOzMTXyBEdauH2jYvf/uwrF/HPa51nYwsC7dZTPz4SlE2nmi38McblnDFwjyeuHEpr3/tDH505VzuPG86Wdr/nR6m31fnmM45M7O0cxAC3cycRKzmnocg0yKEs8npCZhMMqNTIpFIJMOPFMckEslJgStOlNOtb0vnw9AcUuKto3xGkhEhJdyx8khdWBwLhVS+9ewu/r6h+wDTGRSODFtSuPTW49CcFG09iGOdTd1WtarxpKSkDvTMJRLJSUiks2v5ZHH9sJhNPPzpxfz5pqX8SBOz1uyu7lcXS72ssiAlOjNxRXEaz95+Ki986bSo8sXpWYncsGISTrvFyBjzBcTr5fTROaZTmBbPtMzwsef2kDemE7mtzBuTSCQSyUghxTGJRHJSkJYgxLEyLcfFFX/i7CnJBEAL5c9X6jiidUsD4YD458Zj/OzV/VEd2lRVJVkV5ZFOV1gcCzqF88Hsron9Oh2N3VZVqmlkJtoH/RYkEsnJQ6Q4tmxyWFy3W8yc/f/bu/OwKMv9f+DvGWAWlmETkF1DRVHLraMgieZCeY5hdVo0l/xWfjnaMfWXlltqXi7nZGbH4lhWdlTUNr9m2aWeTNLSXBAtLEVwTUFFdpB1Pr8/RkamAWZAhYF5v65rrst5nvu5n88z3tczz3y4l3BfjLo/GJ7OTrheXI6DZ83vO3Wp7rUV7GXe66tXiCfat6k7CdX2DxPwWzMh/x892OXWUM26VqqsVnPIZVg9cREREd1JTI4RkV0Y9SdDkqTq5gS/XlZMzE6tQI1hlWdqJMeqe1EUllUi/0aFcfuN8groYCjn5nnrx5zCzbDqpKbsWq2nKS80354pXhxKRkQNUj3sUe2oxL1B5kkkRwclHupmuB99/XOm1fUae47VsdpufQI8biXUHJQK+Lo1/L42+ObQSqDulSqrebmo4H3zO5qT8RMRUVNhcoyI7MJf7vXHkBp/ufbgsEr7cHNYZZAiG9lF5cgvMSTCLuXewOPKveijOGnsUQEAebnZcFAYEqha91s9x5zcDT9GXcqzaz1NaYEhOZYpt3p6ZLLnGBE1UIS/Di8N7oh/PH4v1I4OtZb5c3fD4gY7UjOtGlpZWaVHZn4pAPNhldZoWyPJ7+emhkMj5gDrFeKBCH8d7vFxsWrl0rgegWjjqkZkWONW/iQiImoox+YOgIioKSgUCiwa2Q0Hz+xFYVmlydAVasU82gEAQpTXAAgysovQK8QTZVkn8aZqNTLFCym5o9H9Zg+N4hzDsMkiaOHqeCuxpfEyrDrpXnm91tOUFxqSZsf0YfBV5sJBIchWtoGLml+zRGQ9hUKBaUM71Vum3z1e8HJRIae4HIfO5iCqQ5t6y2fml6JKL1A5KhuVsK85jNLfo3HfnY4OSmx7sT+UCoVVE+y/NiIC8/7SBQoFJ+MnIqKmwZ5jRGQ3/N21+DQ+EqvH9EIHX8t/uaZWwCMYAOCMUnihEBlXbw6tvJ4BAPBX5CDr6lVj8Rv5hh5ghQrT9uHaJhAA4C05xqG5NVUWGpJmV8QTF8XQQ7FE638HL4SIyMDRQYmBnQw9W78/XftQ75qqV6oM8tA2auXHmnOO/XH+sYZwdFA26PxMjBERUVNicoyI7EoXfx0e6sakhd1wVANuhv/vYMVV44qVioJLxiIlVzKM/y4rMPQAK3EwnRPH3ceQZHNXlCAvP9/sNPoSQ3IsD67Yqu+PK+KBC7ped/BCiIhuGXAzObYvrfah3oBhgZGff8/Db1mGRUaCGjHfGGA651jAbSTHiIiIbBnHexARUevm2R4ozMQ9ikycuVYEEYH2RhZws1OC5Jw1Fq24OTzyhpOHSRWOLp4ohRM0qEB+9iV4e5rur16tslCpw4flw7Cy8nH8xTPgbl0REdm5/jeHUv6aWYBrhWXwqWW45H/2n8OCr341vg9u5HQCbVwN84xV6QX+7pySgIiIWif2HCMiotatbTcAQITyPDKuFaHgRiW89beGIqkKzhv/LTd7gFWo/rCamkKBXIVhsv3i7Itmp1CW5gIAnN2rF31o3IpuRETW8HFTI8JfBwD4Md2895iIIPHgBZNtna2YCL82DkoF/G4m3wI8eF8jIqLWickxIiJq3dreCwCIUJzH+eslOJ9TjADFrYn13Ut/h756HrGbPcAqNZ5m1RQ4GlZNK83NNNvnVGZIjrl4+kLtaPhq9dVxpUoiunuqh1buTTOfd+zE5QKcvloElaMSic/3xT//ei+euj+k0eca2TMQIV7OuL+dl+XCRERELRCTY0RE1Lq17Q4A6Ko8j0q9HnvTrsEft5JjgXIF2UVlAABlqSE5Jlpvs2qK1YYfolX55skxVXkeAEDh4m1cCbUxq8IREVlrQEfD0Mq9p7MhYrpQyP+lGOZVHNrFD/07tMGTfYKhcmz8Y//Mhzpj78xB8HblfY2IiFonJseIiKh18+0CKB3hoShCAK5j00/n0FaRY9wdqriCi7mG1dxUN3uAObi2MaumXGtIjikKs0x3iEBbaZik38HZGyN7BCLAXYO+95gn2IiI7pTe7TyhdXJAdlEZTt6cdB8AKqv02Hb8MgDg0Z6BzRUeERFRi8LkGBERtW6OasCnMwDDvGPlBVehUlQZdwcoruP37AIAgLbCkBxzdPM1q0bv4mfYd+OK6Y7yYjhKBQDAya0N/j64I/bPGoxAD05cTUR3j9rRAf3uMQxz3Hf6GkQEa/aewfB/7cO1wjJ4OjsZh14SERFR/RqVHHv33XfRrl07aDQa9O3bF4cOHaq3/MqVKxEeHg6tVovg4GBMmzYNpaWlt1UnERGR1YxDK8/B/+Z8Y8VqH1QoVHBU6JGfeQYA4FJl6AGmcTf/Qalw8wcAqEv/MPn1DUMvtDJxgrNL4ya8JiJqjAc6Vs87lo0dqVlY/M1vSLtSBIUC+N+YsNsaSklERGRPGvyN+cknn2D69OmYP38+jh49ivvuuw+xsbG4evVqreU3btyIV199FfPnz8dvv/2GDz/8EJ988glmz57d6DqJiIga5GZyLMr5sjE5VuESiAJtEACg/FoGAMBdb0iOuXq2NavCycOQHHMt/0Ny7OYKl7lwhc5ZdedjJyKqQ3XPsEPncvDx/nMAgCf7BOHo3KGIjwlrxsiIiIhalgYnx1asWIEXXngBEyZMQEREBFavXg1nZ2d89NFHtZbfv38/+vfvj9GjR6Ndu3YYNmwYRo0aZdIzrKF1EhERNcjNFSu7KM8bV6pUeASiXGdYvU2Rdw6lZWXwUBQBAHRtzJNjWq8AAIBXVTagvzUss3qFy1xxhU7jdNcugYjoj8J8XBDgrkF5pR4HzxruRZMGdoCnCxP1REREDdGg5Fh5eTmSk5MxZMiQWxUolRgyZAgOHDhQ6zFRUVFITk42JsPOnDmDb775BsOHD290nQBQVlaGgoICkxcREVGt2nYDAOhKL6Oz4iIAQOMdAni2BwC4lvyOvGzDXGJ6UcDVw3zOMTf/jigQLXQoQtWBBMPG6xnAzQn6c8UNOq3j3b4SIiIjhUJhHFoJAJH3eKNdG5dmjIiIiKhlalByLDs7G1VVVfDz8zPZ7ufnh6ysrFqPGT16NF5//XVER0fDyckJYWFhGDhwoHFYZWPqBIClS5fC3d3d+AoODm7IpRARkT3RegJtwgEAf1XtBwCovUKg9ukAAPAqv4TCHMN3ToHCFQoH8yRXgI83VirHG958twjY8Diwqhew7UUAN4dVsucYETWxmpPuP/0nPg8TERE1xl2fpTMpKQlLlixBQkICjh49ii1btmD79u1YtGjRbdU7a9Ys5OfnG18XL168QxETEVGrFPV3AICDvtzw3j0Qrv6G5FiQXMGVrEsAgAKle62HOzooURQxCnurusOhqgxI/9awQ/QAgBzRQadlcoyImlZ0hzbwcHZCoIcWsV3Nh4QTERGRZQ0a/9GmTRs4ODjgyhXTZeyvXLmCtm1r/zKeN28exo4di+effx4A0L17dxQXF2PixImYM2dOo+oEALVaDbVa3ZDwiYjInt33NLD3n0DeBcN7XRBUKsPwo0BFNk5eMSTHShxrT44BwMPdA/Bq8gv4yOEthHcKh2LwfBRcOI4929YhUT8Ez6g5rJKImpa7sxN2TRsAR6USGieH5g6HiIioRWpQzzGVSoXevXtj9+7dxm16vR67d+9GZGRkrceUlJRAqTQ9jYOD4YtbRBpVJxERUYM5OAEP/L9b790DAQ/DECSdogQVV9MBAGUqrzqriOrgjUJ1WzxUuhhH+/8b8ItAdrsReKniRVxS3QOlUnFXL4GIqDa+bhp4cRJ+IiKiRmvwn7inT5+O8ePHo0+fPvjTn/6ElStXori4GBMmTAAAjBs3DoGBgVi6dCkAYMSIEVixYgV69uyJvn37Ij09HfPmzcOIESOMSTJLdRIREd0R940GUrcATlrA1Q9QKFCg9IBOn4c2BakAgApN3ckxtaMDBnfxxdZjl/HNL1noHeqFgtJKAOB8Y0RERERELVSDk2NPPfUUrl27htdeew1ZWVno0aMHduzYYZxQ/8KFCyY9xebOnQuFQoG5c+fi0qVL8PHxwYgRI7B48WKr6yQiIrojHFXA+G0mmwo0/tCV5KGzZAAKQK/1rreKh7v7Y+uxy/i/lEuY8mBHFNyoAADON0ZERERE1EIpRESaO4g7oaCgAO7u7sjPz4dOp2vucIiIqIVIf/dxdLj2rfH94c4zcf/Tc+osX1Glx8Nv70P61SI8G9UOfdp54sWNKejb3guf/C+nAyAiIiIisgUNyRPd9dUqiYiIbFmVLtjkvZObT73lnRyUWDCiKwBg3YFz+DH9OgD2HCMiIiIiaqmYHCMiIrvm5NXO5L3a3dfiMdEd2+Dhbm2hF2DTIcPql5xzjIiIiIioZWJyjIiI7JrWt73JexcP6+a7XPhIVwzo5IPqBSo7+bne6dCIiIiIiKgJNHhCfiIiotbEIyDM5L2bd1urjvPVabDuf/6EvJJyZFwrRvdA97sRHhERERER3WVMjhERkV3T+pj2HNN5+zfoeA9nFXqHqu5kSERERERE1IQ4rJKIiOybygV5CkOvryJo4aDSNHNARERERETUlJgcIyIiu5fjZJhnrEDBoZFERERERPaGyTEiIrJ7RZoAAECxI5NjRERERET2hskxIiKye+VuQQCAG06ezRwJERERERE1NSbHiIjI7vl16Q8AcA7q3syREBERERFRU+NqlUREZPeC+48COvVCB+8OzR0KERERERE1MSbHiIiIFArAt3NzR0FERERERM2AwyqJiIiIiIiIiMhuMTlGRERERERERER2i8kxIiIiIiIiIiKyW0yOERERERERERGR3WJyjIiIiIiIiIiI7BaTY0REREREREREZLeYHCMiIiIiIiIiIrvF5BgREREREREREdktJseIiIiIiIiIiMhuMTlGRERERERERER2i8kxIiIiIiIiIiKyW0yOERERERERERGR3WJyjIiIiIiIiIiI7BaTY0REREREREREZLccmzuAO0VEAAAFBQXNHAkRERERERERETWn6vxQdb6oPq0mOVZYWAgACA4ObuZIiIiIiIiIiIjIFhQWFsLd3b3eMgqxJoXWAuj1ely+fBlubm5QKBTNHc5tKygoQHBwMC5evAidTtfc4RDdNWzrZC/Y1slesK2TPWA7J3vBtk4tmYigsLAQAQEBUCrrn1Ws1fQcUyqVCAoKau4w7jidTsebENkFtnWyF2zrZC/Y1skesJ2TvWBbp5bKUo+xapyQn4iIiIiIiIiI7BaTY0REREREREREZLeYHLNRarUa8+fPh1qtbu5QiO4qtnWyF2zrZC/Y1skesJ2TvWBbJ3vRaibkJyIiIiIiIiIiaij2HCMiIiIiIiIiIrvF5BgREREREREREdktJseIiIiIiIiIiMhuMTlGRERERERERER2i8kxAEuXLsX9998PNzc3+Pr6YuTIkTh16pRJmdLSUkyePBne3t5wdXXF448/jitXrhj3Hz9+HKNGjUJwcDC0Wi26dOmCt99+26SOLVu2YOjQofDx8YFOp0NkZCR27txpMT4RwWuvvQZ/f39otVoMGTIEp0+fNimzePFiREVFwdnZGR4eHlZf+88//4wHHngAGo0GwcHB+Oc//2kWc58+feDh4QEXFxf06NED69evt7p+sh2toZ23a9cOCoXC5LVs2bJ667U2nkuXLmHMmDHw9vaGVqtF9+7dceTIEYtxk+2x9ba+ZcsWDBs2DN7e3lAoFDh27JhZGUvx1aa0tBTPPvssunfvDkdHR4wcObLWcu+++y66dOkCrVaL8PBwrFu3zmLMZJuaqq3/8MMP6N+/v/H+2LlzZ7z11lsW47Pmvv7II48gJCQEGo0G/v7+GDt2LC5fvlxvvZmZmRg9ejQ6deoEpVKJqVOnmpX5+OOPzb4vNBqNxZjJ9rSGdp6Wloa4uDi0adMGOp0O0dHR2LNnj8W6LT2nA8DKlSsRHh4OrVaL4OBgTJs2DaWlpRbrJttj623d0vNLTk4O/v73vxvbY0hICKZMmYL8/Px6601KSkJcXBz8/f2NvzcTExNNylRUVOD1119HWFgYNBoN7rvvPuzYscNizEQNIiSxsbGydu1aSU1NlWPHjsnw4cMlJCREioqKjGXi4+MlODhYdu/eLUeOHJF+/fpJVFSUcf+HH34oU6ZMkaSkJMnIyJD169eLVquVVatWGcu89NJL8o9//EMOHTokaWlpMmvWLHFycpKjR4/WG9+yZcvE3d1dtm7dKsePH5dHHnlE2rdvLzdu3DCWee2112TFihUyffp0cXd3t+q68/Pzxc/PT5555hlJTU2VTZs2iVarlffee89YZs+ePbJlyxb59ddfJT09XVauXCkODg6yY8cOq85BtqM1tPPQ0FB5/fXXJTMz0/iqGX9trIknJydHQkND5dlnn5WDBw/KmTNnZOfOnZKenm7150u2w9bb+rp162ThwoWyZs0aASApKSlmZSzFV5uioiKJj4+X999/X2JjYyUuLs6sTEJCgri5ucnmzZslIyNDNm3aJK6urrJt27Z66ybb1FRt/ejRo7Jx40ZJTU2Vs2fPyvr168XZ2dnkeaE21tzXV6xYIQcOHJBz587Jjz/+KJGRkRIZGVlvvWfPnpUpU6bIf/7zH+nRo4e89NJLZmXWrl0rOp3O5PsiKyvL0kdKNqg1tPOOHTvK8OHD5fjx45KWliaTJk0SZ2dnyczMrLNea57TExMTRa1WS2Jiopw9e1Z27twp/v7+Mm3atAZ9xmQbbL2tW3p++eWXX+Sxxx6Tbdu2SXp6uuzevVs6duwojz/+eL31Ll68WObOnSs//vij8femUqmUr776ylhm5syZEhAQINu3b5eMjAxJSEgQjUZj8ZmLqCGYHKvF1atXBYB8//33IiKSl5cnTk5O8tlnnxnL/PbbbwJADhw4UGc9kyZNkkGDBtV7roiICFm4cGGd+/V6vbRt21beeOMN47a8vDxRq9WyadMms/Jr1661OjmWkJAgnp6eUlZWZtz2yiuvSHh4eL3H9ezZU+bOnWvVOch2tcR2HhoaKm+99ZalS7Poj/G88sorEh0dfdv1km2ypbZe09mzZ2t9uGxsfDWNHz++1uRYZGSkvPzyyybbpk+fLv3797eqXrJtTdnWH330URkzZkyd+xv6/FLtyy+/FIVCIeXl5fWev1pMTEydyTFrn4eoZWlp7fzatWsCQPbu3WssU1BQIADkv//9b511W/OcPnnyZHnwwQdNjuM9vfWwpbZeU13PL7X59NNPRaVSSUVFhVV1Vxs+fLhMmDDB+N7f31/eeecdkzKPPfaYPPPMMw2ql6g+HFZZi+qun15eXgCA5ORkVFRUYMiQIcYynTt3RkhICA4cOFBvPdV11Eav16OwsLDeMmfPnkVWVpbJud3d3dG3b996z22NAwcOYMCAAVCpVMZtsbGxOHXqFHJzc83Kiwh2796NU6dOYcCAAbd1bmp+LbWdL1u2DN7e3ujZsyfeeOMNVFZW1n+hVsSzbds29OnTB0888QR8fX3Rs2dPrFmzpkH1ku2ypbZujcbGZ42ysjKzoWVarRaHDh1CRUXFbdVNza+p2npKSgr279+PmJiYOss05vklJycHiYmJiIqKgpOTU511W6uoqAihoaEIDg5GXFwcTpw4cdt1UvNrae3c29vbOIS9uLgYlZWVeO+99+Dr64vevXvXWbc1z+lRUVFITk7GoUOHAABnzpzBN998g+HDh9dZL7UcttTWGys/Px86nQ6Ojo4NPq5mzHU9v/zwww93JE4iAGhYK7UDer0eU6dORf/+/dGtWzcAQFZWFlQqldlcXn5+fsjKyqq1nv379+OTTz7B9u3b6zzX8uXLUVRUhCeffLLOMtX1+/n5WX1ua2VlZaF9+/Zm9Vbv8/T0BGC4OQUGBqKsrAwODg5ISEjA0KFDb+vc1LxaajufMmUKevXqBS8vL+zfvx+zZs1CZmYmVqxYUe/1WornzJkz+Pe//43p06dj9uzZOHz4MKZMmQKVSoXx48dbXTfZHltr69ZoTHzWio2NxQcffICRI0eiV69eSE5OxgcffICKigpkZ2fD39//tuqn5tMUbT0oKAjXrl1DZWUlFixYgOeff77OeBry/PLKK6/gnXfeQUlJCfr164evv/7a4vVaEh4ejo8++gj33nsv8vPzsXz5ckRFReHEiRMICgq67fqpebTEdq5QKPDtt99i5MiRcHNzg1KphK+vL3bs2GF81q6rbkvP6aNHj0Z2djaio6MhIqisrER8fDxmz55dZ73UMthaW2+M7OxsLFq0CBMnTmzQcZ9++ikOHz6M9957z7gtNjYWK1aswIABAxAWFobdu3djy5YtqKqquqMxk31jz7E/mDx5MlJTU7F58+ZG15Gamoq4uDjMnz8fw4YNq7XMxo0bsXDhQnz66afw9fUFACQmJsLV1dX42rdvX6Nj+KOuXbsa63344YcbdKybmxuOHTuGw4cPY/HixZg+fTqSkpLuWGzU9FpqO58+fToGDhyIe++9F/Hx8XjzzTexatUqlJWVAYBJvfHx8VbFAxgeQHr16oUlS5agZ8+emDhxIl544QWsXr26IR8J2aCW2tYtaew9fd68eXj44YfRr18/ODk5IS4uzpgAVir5SNCSNUVb37dvH44cOYLVq1dj5cqV2LRpE4Dbb+szZsxASkoKdu3aBQcHB4wbNw4iAsDyfb0ukZGRGDduHHr06IGYmBhs2bIFPj4+Jj+2qOVpie1cRDB58mT4+vpi3759OHToEEaOHIkRI0YgMzMTQOPv6UlJSViyZAkSEhJw9OhRbNmyBdu3b8eiRYusroNsU0ts6zUVFBTgz3/+MyIiIrBgwQLjdkttfc+ePZgwYQLWrFmDrl27Gre//fbb6NixIzp37gyVSoUXX3wREyZM4LML3VnNO6rTtkyePFmCgoLkzJkzJtt3794tACQ3N9dke0hIiKxYscJk24kTJ8TX11dmz55d53mqJ9T8+uuvTbYXFBTI6dOnja+SkhLJyMiodUz3gAEDZMqUKWZ11zXHxrlz54z1/v777yIiMnbsWLM5ab777jsBIDk5OXXG/9xzz8mwYcPq3E+2rTW082qpqakCQE6ePCkiYlLvlStXrIqn+hqfe+45k20JCQkSEBBQ57nJ9tliW6+prjk7rImvtnt6TXXNOVatvLxcLl68KJWVlcZJ+quqquosT7atqdp6TYsWLZJOnTqJyJ29r1+8eFEAyP79+0Wk/vu6SN1zjtXmr3/9qzz99NNWlSXb01Lb+bfffitKpVLy8/NNynTo0EGWLl0qIo1/To+OjjabR7J6Anbe01suW2zrNVmac6ygoEAiIyNl8ODBJgtTiNT//JKUlCQuLi71Lgxw48YN+f3330Wv18vMmTMlIiLCqusjsgaTY2KYTHPy5MkSEBAgaWlpZvurJz/8/PPPjdtOnjxpNvlhamqq+Pr6yowZM+o818aNG0Wj0cjWrVutjq1t27ayfPly47b8/Pw7OiF/zUlvZ82aZXFC/gkTJkhMTIxV5yDb0ZraebUNGzaIUqmsN5lrTTyjRo0ym5B/6tSpFldMI9tky229JksT8luKrz6WkmM1DRgwQEaNGmVt2GRDmrKt/9HChQslNDS03tgac18/f/68AJA9e/ZYFYe1ybHKykoJDw/nKn4tUEtv59u2bROlUimFhYUmx3bq1EkWL15cZ93WPKf36tVLZs6caXLcxo0bRavVSmVlpVXXSLbDltt6TfUlx/Lz86Vfv34SExMjxcXFVp9/z5494uLiYjbpfl3Ky8slLCxMZs2aZfU5iCxhckxE/va3v4m7u7skJSWZLPldM0seHx8vISEh8t1338mRI0fMlhr/5ZdfxMfHR8aMGWNSx9WrV41lEhMTxdHRUd59912TMnl5efXGt2zZMvHw8JAvv/xSfv75Z4mLizNbIvr8+fOSkpIiCxcuFFdXV0lJSZGUlBSzL+Ka8vLyxM/PT8aOHSupqamyefNms2V8lyxZIrt27ZKMjAz59ddfZfny5eLo6Chr1qxp0GdMza+lt/P9+/fLW2+9JceOHZOMjAzZsGGD+Pj4yLhx4+qt15p4Dh06JI6OjrJ48WI5ffq0JCYmirOzs2zYsKFBnzHZBltv69evX5eUlBTZvn27AJDNmzdLSkqKZGZmWh1fXU6cOCEpKSkyYsQIGThwoPG7oNqpU6dk/fr1kpaWJgcPHpSnnnpKvLy85OzZs1Z8smRrmqqtv/POO7Jt2zZJS0uTtLQ0+eCDD8TNzU3mzJlTb3yW7us//fSTrFq1SlJSUuTcuXOye/duiYqKkrCwMCktLa237uq23bt3bxk9erSkpKTIiRMnjPsXLlwoO3fulIyMDElOTpann35aNBqNSRlqGVp6O7927Zp4e3vLY489JseOHZNTp07Jyy+/LE5OTnLs2LE667XmOX3+/Pni5uYmmzZtkjNnzsiuXbskLCxMnnzyyQZ/ztT8bL2tW3p+yc/Pl759+0r37t0lPT3d5Pz1JWu/++47cXZ2llmzZpkcc/36dWOZn376Sb744gvJyMiQvXv3yoMPPijt27c360VHdDuYHBMRALW+1q5dayxz48YNmTRpknh6eoqzs7M8+uijJj9k5s+fX2sdNTPwMTExtZYZP358vfHp9XqZN2+e+Pn5iVqtlsGDB8upU6dMyowfP77Wui395fX48eMSHR0tarVaAgMDZdmyZSb758yZIx06dBCNRiOenp4SGRkpmzdvrrdOsk0tvZ0nJydL3759xd3dXTQajXTp0kWWLFli8QeUtfF89dVX0q1bN1Gr1dK5c2d5//33LX6mZJtsva2vXbu21uPmz59vdXx1CQ0NrbXuar/++qv06NFDtFqt6HQ6iYuLMw5Lppanqdr6v/71L+natas4OzuLTqeTnj17SkJCgsVhW5bu6z///LMMGjRIvLy8RK1WS7t27SQ+Pr7WocLWXHvNmKdOnSohISGiUqnEz89Phg8fLkePHrX8oZLNaentXETk8OHDMmzYMPHy8hI3Nzfp16+ffPPNNxav3dJzekVFhSxYsEDCwsJEo9FIcHCwTJo0iQmDFsrW27ql55c9e/bUeQ31/RGurt+xNUcqJSUlSZcuXUStVou3t7eMHTtWLl261JCPl8gihcjNGU+JiIiIiIiIiIjsDJd3ICIiIiIiIiIiu8XkGBERERERERER2S0mx4iIiIiIiIiIyG4xOUZERERERERERHaLyTEiIiIiIiIiIrJbTI4REREREREREZHdYnKMiIiIiIiIiIjsFpNjRERERC3IwIEDMXXq1OYOg4iIiKjVYHKMiIiIqJVKSkqCQqFAXl5ec4dCREREZLOYHCMiIiIiIiIiIrvF5BgRERGRjSouLsa4cePg6uoKf39/vPnmmyb7169fjz59+sDNzQ1t27bF6NGjcfXqVQDAuXPnMGjQIACAp6cnFAoFnn32WQCAXq/H0qVL0b59e2i1Wtx33334/PPPm/TaiIiIiGwFk2NERERENmrGjBn4/vvv8eWXX2LXrl1ISkrC0aNHjfsrKiqwaNEiHD9+HFu3bsW5c+eMCbDg4GB88cUXAIBTp04hMzMTb7/9NgBg6dKlWLduHVavXo0TJ05g2rRpGDNmDL7//vsmv0YiIiKi5qYQEWnuIIiIiIjIVFFREby9vbFhwwY88cQTAICcnBwEBQVh4sSJWLlypdkxR44cwf3334/CwkK4uroiKSkJgwYNQm5uLjw8PAAAZWVl8PLywrfffovIyEjjsc8//zxKSkqwcePGprg8IiIiIpvh2NwBEBEREZG5jIwMlJeXo2/fvsZtXl5eCA8PN75PTk7GggULcPz4ceTm5kKv1wMALly4gIiIiFrrTU9PR0lJCYYOHWqyvby8HD179rwLV0JERERk25gcIyIiImqBiouLERsbi9jYWCQmJsLHxwcXLlxAbGwsysvL6zyuqKgIALB9+3YEBgaa7FOr1Xc1ZiIiIiJbxOQYERERkQ0KCwuDk5MTDh48iJCQEABAbm4u0tLSEBMTg5MnT+L69etYtmwZgoODARiGVdakUqkAAFVVVcZtERERUKvVuHDhAmJiYproaoiIiIhsF5NjRERERDbI1dUVzz33HGbMmAFvb2/4+vpizpw5UCoN6ymFhIRApVJh1apViI+PR2pqKhYtWmRSR2hoKBQKBb7++msMHz4cWq0Wbm5uePnllzFt2jTo9XpER0cjPz8fP/74I3Q6HcaPH98cl0tERETUbLhaJREREZGNeuONN/DAAw9gxIgRGDJkCKKjo9G7d28AgI+PDz7++GN89tlniIiIwLJly7B8+XKT4wMDA7Fw4UK8+uqr8PPzw4svvggAWLRoEebNm4elS5eiS5cueOihh7B9+3a0b9++ya+RiIiIqLlxtUoiIiIiIiIiIrJb7DlGRERERERERER2i8kxIiIiIiIiIiKyW0yOERERERERERGR3WJyjIiIiIiIiIiI7BaTY0REREREREREZLeYHCMiIiIiIiIiIrvF5BgREREREREREdktJseIiIiIiIiIiMhuMTlGRERERERERER2i8kxIiIiIiIiIiKyW0yOERERERERERGR3WJyjIiIiIiIiIiI7Nb/B8pS3RRfX3XiAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "# print(\"==============Compare to DJIA===========\")\n",
        "# %matplotlib inline\n",
        "# # S&P 500: ^GSPC\n",
        "# # Dow Jones Index: ^DJI\n",
        "# # NASDAQ 100: ^NDX\n",
        "# backtest_plot(df_account_value,\n",
        "#               baseline_ticker = '^DJI',\n",
        "#               baseline_start = df_account_value.loc[0,'date'],\n",
        "#               baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "df.to_csv(\"df.csv\")\n",
        "df_result_ensemble = pd.DataFrame({'date': df_account_value['date'], 'ensemble': df_account_value['account_value']})\n",
        "df_result_ensemble = df_result_ensemble.set_index('date')\n",
        "\n",
        "print(\"df_result_ensemble.columns: \", df_result_ensemble.columns)\n",
        "\n",
        "# df_result_ensemble.drop(df_result_ensemble.columns[0], axis = 1)\n",
        "print(\"df_trade_date: \", df_trade_date)\n",
        "# df_result_ensemble['date'] = df_trade_date['datadate']\n",
        "# df_result_ensemble['account_value'] = df_account_value['account_value']\n",
        "df_result_ensemble.to_csv(\"df_result_ensemble.csv\")\n",
        "print(\"df_result_ensemble: \", df_result_ensemble)\n",
        "print(\"==============Compare to DJIA===========\")\n",
        "result = pd.DataFrame()\n",
        "# result = pd.merge(result, df_result_ensemble, left_index=True, right_index=True)\n",
        "# result = pd.merge(result, df_dji, left_index=True, right_index=True)\n",
        "result = pd.merge(df_result_ensemble, df_dji, left_index=True, right_index=True)\n",
        "print(\"result: \", result)\n",
        "result.to_csv(\"result.csv\")\n",
        "result.columns = ['ensemble', 'dji']\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
        "plt.figure();\n",
        "result.plot();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBQx4bVQFi-a"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
